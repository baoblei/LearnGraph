{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl.data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import scipy.sparse as sp\n",
    "import itertools\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/sihua.qi/my_env/mypy36/lib/python3.7/site-packages/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.\n",
      "  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'\n"
     ]
    }
   ],
   "source": [
    "# Process Cora\n",
    "cora_dir = \"./datasets/cora/\"\n",
    "nodes_id_map = {}\n",
    "start = 0\n",
    "start_list, target_list = [], []\n",
    "with open(cora_dir+\"cora.cites\") as f:\n",
    "    for ln in f:\n",
    "        ln = ln.strip(\"\\n\").split(\"\\t\")\n",
    "        start_i, target_i = int(ln[0]), int(ln[1])\n",
    "        if start_i not in nodes_id_map:\n",
    "            nodes_id_map[start_i] = start\n",
    "            start += 1\n",
    "        if target_i not in nodes_id_map:\n",
    "            nodes_id_map[target_i] = start\n",
    "            start += 1 \n",
    "        start_list.append(nodes_id_map[start_i])\n",
    "        target_list.append(nodes_id_map[target_i])\n",
    "        start_list.append(nodes_id_map[target_i])\n",
    "        target_list.append(nodes_id_map[start_i])\n",
    "        \n",
    "\n",
    "feature_names = [\"w_{}\".format(ii) for ii in range(1433)]\n",
    "column_names =  feature_names + [\"subject\"]\n",
    "node_data = pd.read_csv(os.path.join(cora_dir+\"cora.content\"), sep='\\t', header=None, names=column_names)\n",
    "\n",
    "cora_label_map = {\n",
    "      'Case_Based': 0,\n",
    "      'Genetic_Algorithms': 1,\n",
    "      'Neural_Networks': 2,\n",
    "      'Probabilistic_Methods': 3,\n",
    "      'Reinforcement_Learning': 4,\n",
    "      'Rule_Learning': 5,\n",
    "      'Theory': 6,\n",
    "  }\n",
    "\n",
    "cora_features = [None for _ in range(len(nodes_id_map))]\n",
    "cora_labels = [None for _ in range(len(nodes_id_map))]\n",
    "for i in range(node_data.shape[0]):\n",
    "    feature_i, label_i = node_data.iloc[i][:-1], cora_label_map[node_data.iloc[i].tolist()[-1]]\n",
    "    node_index_i = nodes_id_map[node_data.index[i]]\n",
    "    cora_features[node_index_i] = feature_i\n",
    "    cora_labels[node_index_i] = label_i\n",
    "\n",
    "G_cora = dgl.DGLGraph()\n",
    "G_cora.add_edges(start_list, target_list)\n",
    "G_cora.ndata['feat'] = torch.Tensor(np.array(cora_features, dtype=np.float64))\n",
    "G_cora.ndata['label'] = torch.Tensor(np.array(cora_labels)).type(torch.int64)\n",
    "\n",
    "train_size = int(0.8*len(cora_labels))\n",
    "val_size = int((len(cora_labels)-train_size)/2)\n",
    "\n",
    "all_d = set([i for i in range(len(cora_labels))])\n",
    "train_mask = set(random.sample(all_d, train_size))\n",
    "val_mask = set(random.sample(all_d-train_mask, val_size))\n",
    "test_mask = all_d-train_mask-val_mask\n",
    "\n",
    "G_cora.ndata['train_mask'] = torch.Tensor(np.array([True if i in train_mask else False for i in range(len(all_d))])).type(torch.bool)\n",
    "G_cora.ndata['val_mask'] = torch.Tensor(np.array([True if i in val_mask else False for i in range(len(all_d))])).type(torch.bool)\n",
    "G_cora.ndata['test_mask'] = torch.Tensor(np.array([True if i in test_mask else False for i in range(len(all_d))])).type(torch.bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/sihua.qi/my_env/mypy36/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3457: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/data/sihua.qi/my_env/mypy36/lib/python3.7/site-packages/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.\n",
      "  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'\n"
     ]
    }
   ],
   "source": [
    "# Process CiteSeer\n",
    "citeseer_dir = \"./datasets/citeseer/\"\n",
    "nodes_id_map = {}\n",
    "start_list, target_list = [], []\n",
    "start = 0\n",
    "node_data = pd.read_csv(os.path.join(citeseer_dir+\"citeseer.content\"), sep='\\t', header=None)\n",
    "node_data_id_set = set([str(i) for i in node_data[0].tolist()])\n",
    "with open(citeseer_dir+\"citeseer.cites\") as f:\n",
    "    for ln in f:\n",
    "        ln = ln.strip(\"\\n\").split(\"\\t\")\n",
    "        start_i, target_i = ln[0], ln[1]\n",
    "        if start_i not in node_data_id_set or target_i not in node_data_id_set:\n",
    "            continue\n",
    "        if start_i not in nodes_id_map:\n",
    "            nodes_id_map[start_i] = start\n",
    "            start += 1\n",
    "        if target_i not in nodes_id_map:\n",
    "            nodes_id_map[target_i] = start\n",
    "            start += 1 \n",
    "        start_list.append(nodes_id_map[start_i])\n",
    "        target_list.append(nodes_id_map[target_i])\n",
    "        start_list.append(nodes_id_map[target_i])\n",
    "        target_list.append(nodes_id_map[start_i])\n",
    "\n",
    "citeseer_label_map = {\n",
    "    \"Agents\": 0,\n",
    "\t\"AI\": 1,\n",
    "\t\"DB\": 2,\n",
    "\t\"IR\": 3,\n",
    "\t\"ML\": 4,\n",
    "    \"HCI\": 5\n",
    "}\n",
    "\n",
    "\n",
    "citeseer_features = [None for _ in range(len(nodes_id_map))]\n",
    "citeseer_labels = [None for _ in range(len(nodes_id_map))]\n",
    "for i in range(node_data.shape[0]):\n",
    "    tmp_i = node_data.iloc[i].tolist()\n",
    "    feature_i, label_i = tmp_i[1:-1], citeseer_label_map[tmp_i[-1]]\n",
    "    node_index_i = nodes_id_map[str(tmp_i[0])]\n",
    "    citeseer_features[node_index_i] = feature_i\n",
    "    citeseer_labels[node_index_i] = label_i\n",
    "\n",
    "G_citeseer = dgl.DGLGraph()\n",
    "G_citeseer.add_edges(start_list, target_list)\n",
    "G_citeseer.ndata['feat'] = torch.Tensor(np.array(citeseer_features, dtype=np.float64))\n",
    "G_citeseer.ndata['label'] = torch.Tensor(np.array(citeseer_labels)).type(torch.int64)\n",
    "\n",
    "train_size = int(0.8*len(citeseer_labels))\n",
    "val_size = int((len(citeseer_labels)-train_size)/2)\n",
    "all_d = set([i for i in range(len(citeseer_labels))])\n",
    "train_mask = set(random.sample(all_d, train_size))\n",
    "val_mask = set(random.sample(all_d-train_mask, val_size))\n",
    "test_mask = all_d-train_mask-val_mask\n",
    "\n",
    "G_citeseer.ndata['train_mask'] = torch.Tensor(np.array([True if i in train_mask else False for i in range(len(all_d))])).type(torch.bool)\n",
    "G_citeseer.ndata['val_mask'] = torch.Tensor(np.array([True if i in val_mask else False for i in range(len(all_d))])).type(torch.bool)\n",
    "G_citeseer.ndata['test_mask'] = torch.Tensor(np.array([True if i in test_mask else False for i in range(len(all_d))])).type(torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process PPI\n",
    "ppi_dir = \"./datasets/ppi/\"\n",
    "\n",
    "ppi_class_map = json.load(open(ppi_dir+\"ppi-class_map.json\"))\n",
    "ppi_graph = json.load(open(ppi_dir+\"ppi-G.json\"))\n",
    "ppi_features = np.load(ppi_dir+\"ppi-feats.npy\")\n",
    "ppi_id_map = json.load(open(ppi_dir+\"ppi-id_map.json\"))\n",
    "\n",
    "ppi_labels = []\n",
    "start_list, target_list = [], []\n",
    "for i in ppi_graph[\"links\"]:\n",
    "    start_list.append(i[\"source\"])\n",
    "    target_list.append(i[\"target\"])\n",
    "for i in range(len(ppi_id_map)):\n",
    "    ppi_labels.append(ppi_class_map[str(i)])\n",
    "\n",
    "G_ppi = dgl.DGLGraph()\n",
    "G_ppi.add_edges(start_list, target_list)\n",
    "G_ppi.ndata['feat'] = torch.Tensor(np.array(ppi_features, dtype=np.float64))\n",
    "G_ppi.ndata['label'] = torch.Tensor(np.array(ppi_labels)).type(torch.float32)\n",
    "\n",
    "\n",
    "train_mask = [None for _ in range(len(ppi_id_map))]\n",
    "val_mask = [None for _ in range(len(ppi_id_map))]\n",
    "test_mask = [None for _ in range(len(ppi_id_map))]\n",
    "for i in ppi_graph[\"nodes\"]:\n",
    "    if i[\"test\"]:\n",
    "        test_mask[i[\"id\"]] = True\n",
    "    else:\n",
    "        test_mask[i[\"id\"]] = False\n",
    "    if i[\"val\"]:\n",
    "        val_mask[i[\"id\"]] = True\n",
    "    else:\n",
    "        val_mask[i[\"id\"]] = False\n",
    "    if not val_mask[i[\"id\"]] and not test_mask[i[\"id\"]]:\n",
    "        train_mask[i[\"id\"]] = True\n",
    "    else:\n",
    "        train_mask[i[\"id\"]] = False\n",
    "\n",
    "G_ppi.ndata['train_mask'] = torch.Tensor(np.array(train_mask)).type(torch.bool)\n",
    "G_ppi.ndata['val_mask'] = torch.Tensor(np.array(val_mask)).type(torch.bool)\n",
    "G_ppi.ndata['test_mask'] = torch.Tensor(np.array(test_mask)).type(torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_edge_data(input_g, if_ppi=False):\n",
    "    u, v = input_g.edges()\n",
    "    eids = np.arange(input_g.number_of_edges())\n",
    "    eids = np.random.permutation(eids)\n",
    "    test_size = int(len(eids) * 0.1)\n",
    "    val_size = test_size\n",
    "    train_size = input_g.number_of_edges() - test_size - val_size\n",
    "    test_pos_u, test_pos_v = u[eids[:test_size]], v[eids[:test_size]]\n",
    "    val_pos_u, val_pos_v = u[eids[test_size:test_size+val_size]], v[eids[test_size:test_size+val_size]]\n",
    "    train_pos_u, train_pos_v = u[eids[test_size+val_size:]], v[eids[test_size+val_size:]]\n",
    "\n",
    "    # Find all negative edges and split them for training and testing\n",
    "    adj = sp.coo_matrix((np.ones(len(u)), (u.numpy(), v.numpy())))\n",
    "    adj = adj.todense()\n",
    "    if if_ppi:\n",
    "        adj = np.pad(adj, [(0, adj.shape[1]-adj.shape[0]), (0, 0)], mode='constant', constant_values=0)\n",
    "\n",
    "    adj_neg = 1 - adj - np.eye(input_g.number_of_nodes())\n",
    "    neg_u, neg_v = np.where(adj_neg != 0)\n",
    "\n",
    "    neg_eids = np.random.choice(len(neg_u), input_g.number_of_edges())\n",
    "    test_neg_u, test_neg_v = neg_u[neg_eids[:test_size]], neg_v[neg_eids[:test_size]]\n",
    "    val_neg_u, val_neg_v = neg_u[neg_eids[test_size:test_size+val_size]], neg_v[neg_eids[test_size:test_size+val_size]]\n",
    "    train_neg_u, train_neg_v = neg_u[neg_eids[test_size+val_size:]], neg_v[neg_eids[test_size+val_size:]]\n",
    "\n",
    "    train_pos_g = dgl.graph((train_pos_u, train_pos_v), num_nodes=input_g.number_of_nodes())\n",
    "    train_neg_g = dgl.graph((train_neg_u, train_neg_v), num_nodes=input_g.number_of_nodes())\n",
    "\n",
    "    val_pos_g = dgl.graph((val_pos_u, val_pos_v), num_nodes=input_g.number_of_nodes())\n",
    "    val_neg_g = dgl.graph((val_neg_u, val_neg_v), num_nodes=input_g.number_of_nodes())\n",
    "\n",
    "    test_pos_g = dgl.graph((test_pos_u, test_pos_v), num_nodes=input_g.number_of_nodes())\n",
    "    test_neg_g = dgl.graph((test_neg_u, test_neg_v), num_nodes=input_g.number_of_nodes())\n",
    "\n",
    "    train_g = dgl.remove_edges(input_g, eids[:test_size+val_size])\n",
    "    return train_g, train_pos_g, train_neg_g, val_pos_g, val_neg_g, test_pos_g, test_neg_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.function import copy_src, sum as fn_sum, u_dot_v\n",
    "from dgl.utils import expand_as_pair\n",
    "\n",
    "class GraphConv(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats, activation=None,):\n",
    "        super(GraphConv, self).__init__()\n",
    "        self._in_feats = in_feats\n",
    "        self._out_feats = out_feats\n",
    "        self.weight = nn.Parameter(torch.Tensor(in_feats, out_feats))\n",
    "        self.bias = nn.Parameter(torch.Tensor(out_feats))\n",
    "        torch.nn.init.xavier_uniform_(self.weight)\n",
    "        torch.nn.init.zeros_(self.bias)\n",
    "\n",
    "    def forward(self, graph, feat, weight=None):\n",
    "        with graph.local_scope():\n",
    "            aggregate_fn = copy_src('h', 'm')\n",
    "            feat_src, feat_dst = expand_as_pair(feat, graph)\n",
    "            degs = graph.out_degrees().float().clamp(min=1)\n",
    "            norm = torch.pow(degs, -0.5)\n",
    "            shp = norm.shape + (1,) * (feat_src.dim() - 1)\n",
    "            norm = torch.reshape(norm, shp)\n",
    "            feat_src = feat_src * norm\n",
    "            weight = self.weight\n",
    "\n",
    "            feat_src = torch.matmul(feat_src, weight)\n",
    "            graph.srcdata['h'] = feat_src\n",
    "            graph.update_all(aggregate_fn, fn_sum(msg='m', out='h'))\n",
    "            rst = graph.dstdata['h']\n",
    "\n",
    "            degs = graph.in_degrees().float().clamp(min=1)\n",
    "            norm = torch.pow(degs, -0.5)\n",
    "            shp = norm.shape + (1,) * (feat_dst.dim() - 1)\n",
    "            norm = torch.reshape(norm, shp)\n",
    "            rst = rst * norm\n",
    "            rst = rst + self.bias\n",
    "\n",
    "            return rst \n",
    "\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, layers=2, if_ppi=False, \n",
    "                 if_activate=True, if_normal=True, if_dropout=False):\n",
    "        super(GCN, self).__init__()\n",
    "        self.if_ppi = if_ppi\n",
    "        self.layers = layers\n",
    "        self.if_activate = if_activate\n",
    "        self.if_dropout = if_dropout\n",
    "        self.if_normal = if_normal\n",
    "        if layers>2:\n",
    "            self.linears = torch.nn.ModuleList([GraphConv(h_feats, h_feats) for _ in range(layers-2)])\n",
    "        self.conv1 = GraphConv(in_feats, h_feats)\n",
    "        self.conv2 = GraphConv(h_feats, h_feats)\n",
    "        self.dropout = torch.nn.Dropout(p=0.5, inplace=False)\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        if self.if_activate:\n",
    "            h = F.relu(h)\n",
    "        if self.layers > 2:\n",
    "            for i, l in enumerate(self.linears):\n",
    "                h = l(g, h)\n",
    "        if self.if_activate:\n",
    "            h = F.relu(h)\n",
    "        if self.if_dropout:\n",
    "            h = self.dropout(h)\n",
    "        if self.if_normal:\n",
    "            h = torch.nn.functional.normalize(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h\n",
    "        \n",
    "\n",
    "# class GCN(nn.Module):\n",
    "#     def __init__(self, in_feats, h_feats):\n",
    "#         super(GCN, self).__init__()\n",
    "#         self.conv1 = GraphConv(in_feats, h_feats)\n",
    "#         self.conv2 = GraphConv(h_feats, h_feats)\n",
    "\n",
    "#     def forward(self, g, in_feat):\n",
    "#         h = self.conv1(g, in_feat)\n",
    "#         h = F.relu(h)\n",
    "#         h = self.conv2(g, h)\n",
    "#         return h\n",
    "\n",
    "class DotPredictor(nn.Module):\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            # Compute a new edge feature named 'score' by a dot-product between the\n",
    "            # source node feature 'h' and destination node feature 'h'.\n",
    "            g.apply_edges(u_dot_v('h', 'h', 'score'))\n",
    "            # u_dot_v returns a 1-element vector for each edge so you need to squeeze it.\n",
    "            return g.edata['score'][:, 0]\n",
    "\n",
    "def compute_loss(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score])\n",
    "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])])\n",
    "    return F.binary_cross_entropy_with_logits(scores, labels)\n",
    "\n",
    "def compute_auc(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score]).numpy()\n",
    "    labels = torch.cat(\n",
    "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).numpy()\n",
    "    return roc_auc_score(labels, scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_g, train_pos_g, train_neg_g, val_pos_g, val_neg_g, test_pos_g, test_neg_g, model, pred, epochs=200, print_epoch=20, lr=0.01,if_print=False):\n",
    "    best_val_auc = 0.0\n",
    "    best_test_auc = 0.0\n",
    "    all_loss = []\n",
    "    optimizer = torch.optim.Adam(itertools.chain(model.parameters(), pred.parameters()), lr=lr)\n",
    "    for e in range(epochs):\n",
    "        # forward\n",
    "        model.zero_grad()\n",
    "        model.train()\n",
    "        h = model(train_g, train_g.ndata['feat'])\n",
    "        pos_score = pred(train_pos_g, h)\n",
    "        neg_score = pred(train_neg_g, h)\n",
    "        loss = compute_loss(pos_score, neg_score)\n",
    "        all_loss.append(loss.detach().numpy())\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if e % print_epoch == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                h = model(train_g, train_g.ndata['feat'])\n",
    "                train_pos_score = pred(train_pos_g, h)\n",
    "                train_neg_score = pred(train_neg_g, h)\n",
    "                val_pos_score = pred(val_pos_g, h)\n",
    "                val_neg_score = pred(val_neg_g, h)\n",
    "                train_auc = compute_auc(train_pos_score, train_neg_score)\n",
    "                val_auc = compute_auc(val_pos_score, val_neg_score)\n",
    "                if val_auc > best_val_auc:\n",
    "                    best_val_auc = val_auc\n",
    "            print('In epoch {}, loss: {}, train_auc: {}, val_auc: {}'.format(e, loss, train_auc, val_auc))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        test_pos_score = pred(test_pos_g, h)\n",
    "        test_neg_score = pred(test_neg_g, h)\n",
    "        test_auc = compute_auc(test_pos_score, test_neg_score)\n",
    "        if test_auc > best_test_auc:\n",
    "            best_test_auc = test_auc\n",
    "        print('Test AUC', test_auc)\n",
    "    if if_print:\n",
    "        plt.plot(all_loss)\n",
    "        plt.show()  \n",
    "    return best_val_auc, best_test_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers 2 hidden_features 16 if_activate True if_normal True if_dropout True\n",
      "In epoch 0, loss: 0.6623340845108032, train_auc: 0.8028482706932193, val_auc: 0.6997689481619911\n",
      "In epoch 100, loss: 0.41800957918167114, train_auc: 0.9785337486836483, val_auc: 0.8909770859436387\n",
      "In epoch 200, loss: 0.4007638096809387, train_auc: 0.9873381891557202, val_auc: 0.890423241096647\n",
      "Test AUC 0.8820752192656459\n",
      "\n",
      "layers 2 hidden_features 16 if_activate True if_normal True if_dropout False\n",
      "In epoch 0, loss: 0.6413659453392029, train_auc: 0.8282591722267161, val_auc: 0.7277814351547071\n",
      "In epoch 100, loss: 0.2721709609031677, train_auc: 0.9908972474046038, val_auc: 0.8889460383529063\n",
      "In epoch 200, loss: 0.18328757584095, train_auc: 0.9955354862255764, val_auc: 0.8685021979655545\n",
      "Test AUC 0.8674119221049502\n",
      "\n",
      "layers 2 hidden_features 16 if_activate True if_normal False if_dropout True\n",
      "In epoch 0, loss: 0.6875519752502441, train_auc: 0.7581749405521979, val_auc: 0.6668618998067489\n",
      "In epoch 100, loss: 0.399715781211853, train_auc: 0.9847916261268479, val_auc: 0.8935390430886193\n",
      "In epoch 200, loss: 0.35620734095573425, train_auc: 0.9922482832314167, val_auc: 0.8828325086538258\n",
      "Test AUC 0.8773964195459661\n",
      "\n",
      "layers 2 hidden_features 16 if_activate True if_normal False if_dropout False\n",
      "In epoch 0, loss: 0.6868870854377747, train_auc: 0.745849590330559, val_auc: 0.6597290237635116\n",
      "In epoch 100, loss: 0.2908598482608795, train_auc: 0.9876835195197374, val_auc: 0.8635991420501603\n",
      "In epoch 200, loss: 0.1221330314874649, train_auc: 0.9977464034026741, val_auc: 0.8297220157573956\n",
      "Test AUC 0.822126611310497\n",
      "\n",
      "layers 2 hidden_features 16 if_activate False if_normal True if_dropout True\n",
      "In epoch 0, loss: 0.6530143022537231, train_auc: 0.8432282750556217, val_auc: 0.7412520970927392\n",
      "In epoch 100, loss: 0.3227277100086212, train_auc: 0.991639596401463, val_auc: 0.8774945316315912\n",
      "In epoch 200, loss: 0.2926020920276642, train_auc: 0.9959148647379676, val_auc: 0.8790456369852833\n",
      "Test AUC 0.8782008537025632\n",
      "\n",
      "layers 2 hidden_features 16 if_activate False if_normal True if_dropout False\n",
      "In epoch 0, loss: 0.6374455094337463, train_auc: 0.8343103495878398, val_auc: 0.731308798233133\n",
      "In epoch 100, loss: 0.19827702641487122, train_auc: 0.9959041998510254, val_auc: 0.8605929197901846\n",
      "In epoch 200, loss: 0.1044054850935936, train_auc: 0.9990805343900607, val_auc: 0.8565163838688442\n",
      "Test AUC 0.8510012954193124\n",
      "\n",
      "layers 2 hidden_features 16 if_activate False if_normal False if_dropout True\n",
      "In epoch 0, loss: 0.6834731698036194, train_auc: 0.7703554205394116, val_auc: 0.6706037503450913\n",
      "In epoch 100, loss: 0.33617252111434937, train_auc: 0.9917796839971478, val_auc: 0.8931228099980888\n",
      "In epoch 200, loss: 0.28026318550109863, train_auc: 0.9963401221366699, val_auc: 0.8831952260612883\n",
      "Test AUC 0.8730098324449448\n",
      "\n",
      "layers 2 hidden_features 16 if_activate False if_normal False if_dropout False\n",
      "In epoch 0, loss: 0.6829250454902649, train_auc: 0.7746558076655338, val_auc: 0.6763987343116227\n",
      "In epoch 100, loss: 0.16479283571243286, train_auc: 0.9971560985983503, val_auc: 0.8655104164454545\n",
      "In epoch 200, loss: 0.038528043776750565, train_auc: 0.9996664805014601, val_auc: 0.8318091273970567\n",
      "Test AUC 0.8414551169062839\n",
      "\n",
      "layers 5 hidden_features 16 if_activate True if_normal True if_dropout True\n",
      "In epoch 0, loss: 0.6467804312705994, train_auc: 0.7731977917616305, val_auc: 0.6733007708806727\n",
      "In epoch 100, loss: 0.4380713701248169, train_auc: 0.9639034315552197, val_auc: 0.8752400773004311\n",
      "In epoch 200, loss: 0.4020949900150299, train_auc: 0.972679162946542, val_auc: 0.8725396589437024\n",
      "Test AUC 0.8737242243411413\n",
      "\n",
      "layers 5 hidden_features 16 if_activate True if_normal True if_dropout False\n",
      "In epoch 0, loss: 0.6519008278846741, train_auc: 0.7801761783679952, val_auc: 0.6822268470343392\n",
      "In epoch 100, loss: 0.44002294540405273, train_auc: 0.9442978916750608, val_auc: 0.857070228715836\n",
      "In epoch 200, loss: 0.38411128520965576, train_auc: 0.9612406742519052, val_auc: 0.8658332094544372\n",
      "Test AUC 0.8634186328017159\n",
      "\n",
      "layers 5 hidden_features 16 if_activate True if_normal False if_dropout True\n",
      "In epoch 0, loss: 0.6916148662567139, train_auc: 0.7721494996167529, val_auc: 0.6750345091210261\n",
      "In epoch 100, loss: 0.4882138669490814, train_auc: 0.923586144677021, val_auc: 0.8370366752320074\n",
      "In epoch 200, loss: 0.45660164952278137, train_auc: 0.946042872527548, val_auc: 0.8376911805304849\n",
      "Test AUC 0.8569780628172186\n",
      "\n",
      "layers 5 hidden_features 16 if_activate True if_normal False if_dropout False\n",
      "In epoch 0, loss: 0.691635012626648, train_auc: 0.764835758621362, val_auc: 0.6710471660047994\n",
      "In epoch 100, loss: 0.38076019287109375, train_auc: 0.9672112952837723, val_auc: 0.8701620335959565\n",
      "In epoch 200, loss: 0.2996353507041931, train_auc: 0.9795675538050833, val_auc: 0.8599184522924674\n",
      "Test AUC 0.8625521884091827\n",
      "\n",
      "layers 5 hidden_features 16 if_activate False if_normal True if_dropout True\n",
      "In epoch 0, loss: 0.6420263648033142, train_auc: 0.8267034368121479, val_auc: 0.7210783834865891\n",
      "In epoch 100, loss: 0.3908122777938843, train_auc: 0.9778974060133323, val_auc: 0.8804582811272272\n",
      "In epoch 200, loss: 0.35010236501693726, train_auc: 0.9850677473363484, val_auc: 0.8711219180700376\n",
      "Test AUC 0.868037121196033\n",
      "\n",
      "layers 5 hidden_features 16 if_activate False if_normal True if_dropout False\n",
      "In epoch 0, loss: 0.6173206567764282, train_auc: 0.7873399352825515, val_auc: 0.688888275393404\n",
      "In epoch 100, loss: 0.41015422344207764, train_auc: 0.9644963661484351, val_auc: 0.869611586570112\n",
      "In epoch 200, loss: 0.3848019242286682, train_auc: 0.9818718847931485, val_auc: 0.8717734502750111\n",
      "Test AUC 0.8690547686296163\n",
      "\n",
      "layers 5 hidden_features 16 if_activate False if_normal False if_dropout True\n",
      "In epoch 0, loss: 0.6807195544242859, train_auc: 0.7720225079723011, val_auc: 0.6795782454501051\n",
      "In epoch 100, loss: 0.43379461765289307, train_auc: 0.9633132592339637, val_auc: 0.8864375968909936\n",
      "In epoch 200, loss: 0.37875938415527344, train_auc: 0.9813151247015423, val_auc: 0.8758389432776232\n",
      "Test AUC 0.8674968676336299\n",
      "\n",
      "layers 5 hidden_features 16 if_activate False if_normal False if_dropout False\n",
      "In epoch 0, loss: 0.6882714033126831, train_auc: 0.7714920258971542, val_auc: 0.6774112850134851\n",
      "In epoch 100, loss: 0.37403714656829834, train_auc: 0.9733634379907173, val_auc: 0.8665815795621058\n",
      "In epoch 200, loss: 0.31083741784095764, train_auc: 0.9862599889583313, val_auc: 0.8651910212576186\n",
      "Test AUC 0.8633311389071756\n",
      "\n",
      "layers 2 hidden_features 32 if_activate True if_normal True if_dropout True\n",
      "In epoch 0, loss: 0.6574797630310059, train_auc: 0.8072125279062334, val_auc: 0.7031574253010257\n",
      "In epoch 100, loss: 0.34468865394592285, train_auc: 0.9913051826422169, val_auc: 0.8978848563358748\n",
      "In epoch 200, loss: 0.2923385500907898, train_auc: 0.9963016490538378, val_auc: 0.8976444604897109\n",
      "Test AUC 0.8997515343286118\n",
      "\n",
      "layers 2 hidden_features 32 if_activate True if_normal True if_dropout False\n",
      "In epoch 0, loss: 0.6335412263870239, train_auc: 0.8926849196007957, val_auc: 0.8185576249230181\n",
      "In epoch 100, loss: 0.12645722925662994, train_auc: 0.9989319148848225, val_auc: 0.8744543311601435\n",
      "In epoch 200, loss: 0.06136780604720116, train_auc: 0.999661459393198, val_auc: 0.8544725944488097\n",
      "Test AUC 0.8553598504958695\n",
      "\n",
      "layers 2 hidden_features 32 if_activate True if_normal False if_dropout True\n",
      "In epoch 0, loss: 0.6819878816604614, train_auc: 0.7699892505888607, val_auc: 0.6758312981800421\n",
      "In epoch 100, loss: 0.41464346647262573, train_auc: 0.98303902087382, val_auc: 0.899107222493576\n",
      "In epoch 200, loss: 0.3534933030605316, train_auc: 0.9914704685173598, val_auc: 0.8975646116927519\n",
      "Test AUC 0.8958763193102421\n",
      "\n",
      "layers 2 hidden_features 32 if_activate True if_normal False if_dropout False\n",
      "In epoch 0, loss: 0.6789724826812744, train_auc: 0.7643318394012697, val_auc: 0.6732311155471554\n",
      "In epoch 100, loss: 0.32188084721565247, train_auc: 0.9824063479844769, val_auc: 0.8720750069018242\n",
      "In epoch 200, loss: 0.14992566406726837, train_auc: 0.9959845773281408, val_auc: 0.8297491983265731\n",
      "Test AUC 0.8242672386332265\n",
      "\n",
      "layers 2 hidden_features 32 if_activate False if_normal True if_dropout True\n",
      "In epoch 0, loss: 0.6552332043647766, train_auc: 0.8233227603896399, val_auc: 0.713807046231604\n",
      "In epoch 100, loss: 0.2529236674308777, train_auc: 0.9963007216723645, val_auc: 0.8892221113211153\n",
      "In epoch 200, loss: 0.19901436567306519, train_auc: 0.9985713887129513, val_auc: 0.8825131134659899\n",
      "Test AUC 0.8759982161438977\n",
      "\n",
      "layers 2 hidden_features 32 if_activate False if_normal True if_dropout False\n",
      "In epoch 0, loss: 0.6213209629058838, train_auc: 0.8817487338328264, val_auc: 0.7897653379770223\n",
      "In epoch 100, loss: 0.09734109044075012, train_auc: 0.9993286354307629, val_auc: 0.8693355136019029\n",
      "In epoch 200, loss: 0.060599446296691895, train_auc: 0.9996326708226074, val_auc: 0.8626681390558304\n",
      "Test AUC 0.8680056913504215\n",
      "\n",
      "layers 2 hidden_features 32 if_activate False if_normal False if_dropout True\n",
      "In epoch 0, loss: 0.6728018522262573, train_auc: 0.8101279370436222, val_auc: 0.7083917687782709\n",
      "In epoch 100, loss: 0.23610806465148926, train_auc: 0.9974887105878771, val_auc: 0.8960330438106564\n",
      "In epoch 200, loss: 0.19286800920963287, train_auc: 0.9988619373285139, val_auc: 0.8882027649769585\n",
      "Test AUC 0.8876714306950668\n",
      "\n",
      "layers 2 hidden_features 32 if_activate False if_normal False if_dropout False\n",
      "In epoch 0, loss: 0.6694840788841248, train_auc: 0.7868921690106632, val_auc: 0.6916651447259445\n",
      "In epoch 100, loss: 0.11319859325885773, train_auc: 0.9985714814510986, val_auc: 0.8670283930429612\n",
      "In epoch 200, loss: 0.028162116184830666, train_auc: 0.9997756200525523, val_auc: 0.8374461126802437\n",
      "Test AUC 0.844649068784642\n",
      "\n",
      "layers 5 hidden_features 32 if_activate True if_normal True if_dropout True\n",
      "In epoch 0, loss: 0.6484429240226746, train_auc: 0.8175319983703524, val_auc: 0.7201244451995159\n",
      "In epoch 100, loss: 0.3659360110759735, train_auc: 0.9768387735650284, val_auc: 0.8837142432415213\n",
      "In epoch 200, loss: 0.33834952116012573, train_auc: 0.9820480938972153, val_auc: 0.8808413854615728\n",
      "Test AUC 0.8652024889039902\n",
      "\n",
      "layers 5 hidden_features 32 if_activate True if_normal True if_dropout False\n",
      "In epoch 0, loss: 0.6616849303245544, train_auc: 0.7951886296566207, val_auc: 0.6905846376011382\n",
      "In epoch 100, loss: 0.32844990491867065, train_auc: 0.9836590283819004, val_auc: 0.8923803860774279\n",
      "In epoch 200, loss: 0.30131545662879944, train_auc: 0.9877151299796675, val_auc: 0.87350039287307\n",
      "Test AUC 0.8832432202849921\n",
      "\n",
      "layers 5 hidden_features 32 if_activate True if_normal False if_dropout True\n",
      "In epoch 0, loss: 0.6844314336776733, train_auc: 0.7691664512491987, val_auc: 0.6721557051540701\n",
      "In epoch 100, loss: 0.44208475947380066, train_auc: 0.9564606255553689, val_auc: 0.875303786446941\n",
      "In epoch 200, loss: 0.3750821650028229, train_auc: 0.9743062404930152, val_auc: 0.8680927605173182\n",
      "Test AUC 0.8699432988596062\n",
      "\n",
      "layers 5 hidden_features 32 if_activate True if_normal False if_dropout False\n",
      "In epoch 0, loss: 0.6865900754928589, train_auc: 0.7676326550306259, val_auc: 0.6737654229225509\n",
      "In epoch 100, loss: 0.3680904805660248, train_auc: 0.9695161164591876, val_auc: 0.8762186497908216\n",
      "In epoch 200, loss: 0.2615675628185272, train_auc: 0.9851393014411614, val_auc: 0.8526301259317463\n",
      "Test AUC 0.8536176177026482\n",
      "\n",
      "layers 5 hidden_features 32 if_activate False if_normal True if_dropout True\n",
      "In epoch 0, loss: 0.6170885562896729, train_auc: 0.8480733795625048, val_auc: 0.7534264902631188\n",
      "In epoch 100, loss: 0.3619721233844757, train_auc: 0.981361864727793, val_auc: 0.878518125252182\n",
      "In epoch 200, loss: 0.3252005875110626, train_auc: 0.9862334261032764, val_auc: 0.8680740725010087\n",
      "Test AUC 0.8716991229374165\n",
      "\n",
      "layers 5 hidden_features 32 if_activate False if_normal True if_dropout False\n",
      "In epoch 0, loss: 0.6007057428359985, train_auc: 0.8050367452386645, val_auc: 0.7097364564972711\n",
      "In epoch 100, loss: 0.3453214764595032, train_auc: 0.9832198867577132, val_auc: 0.8841466159825013\n",
      "In epoch 200, loss: 0.2805391550064087, train_auc: 0.9894480879937697, val_auc: 0.8707082333453673\n",
      "Test AUC 0.8614946165771199\n",
      "\n",
      "layers 5 hidden_features 32 if_activate False if_normal False if_dropout True\n",
      "In epoch 0, loss: 0.6728162169456482, train_auc: 0.7711422441020659, val_auc: 0.6732888785066576\n",
      "In epoch 100, loss: 0.3964309096336365, train_auc: 0.9760842559984093, val_auc: 0.8856713882223025\n",
      "In epoch 200, loss: 0.34818562865257263, train_auc: 0.986012338360059, val_auc: 0.8716281934209689\n",
      "Test AUC 0.8771279916753381\n",
      "\n",
      "layers 5 hidden_features 32 if_activate False if_normal False if_dropout False\n",
      "In epoch 0, loss: 0.6746909618377686, train_auc: 0.7853667722185762, val_auc: 0.6884703433922996\n",
      "In epoch 100, loss: 0.37640413641929626, train_auc: 0.9731219743517019, val_auc: 0.8705196542716982\n",
      "In epoch 200, loss: 0.3323645293712616, train_auc: 0.9818759255267102, val_auc: 0.8705026651659623\n",
      "Test AUC 0.8726037928178556\n",
      "\n",
      "layers 2 hidden_features 64 if_activate True if_normal True if_dropout True\n",
      "In epoch 0, loss: 0.6569505333900452, train_auc: 0.8003674855074123, val_auc: 0.6990214275096095\n",
      "In epoch 100, loss: 0.2798502445220947, train_auc: 0.9958895207271349, val_auc: 0.8943035528467369\n",
      "In epoch 200, loss: 0.22620674967765808, train_auc: 0.9981378776191373, val_auc: 0.8868844103718491\n",
      "Test AUC 0.8926602815944275\n",
      "\n",
      "layers 2 hidden_features 64 if_activate True if_normal True if_dropout False\n",
      "In epoch 0, loss: 0.6347795128822327, train_auc: 0.8247027437667247, val_auc: 0.7189938202127886\n",
      "In epoch 100, loss: 0.10548778623342514, train_auc: 0.9992676534747447, val_auc: 0.8696922848223577\n",
      "In epoch 200, loss: 0.04374486580491066, train_auc: 0.9997874640387963, val_auc: 0.8543672619932469\n",
      "Test AUC 0.8575905200789993\n",
      "\n",
      "layers 2 hidden_features 64 if_activate True if_normal False if_dropout True\n",
      "In epoch 0, loss: 0.6698316335678101, train_auc: 0.7639910863272387, val_auc: 0.6681768565907114\n",
      "In epoch 100, loss: 0.38269129395484924, train_auc: 0.9872821488181238, val_auc: 0.900717789717344\n",
      "In epoch 200, loss: 0.3407951295375824, train_auc: 0.9939208488391514, val_auc: 0.8863866295737858\n",
      "Test AUC 0.8867106967656989\n",
      "\n",
      "layers 2 hidden_features 64 if_activate True if_normal False if_dropout False\n",
      "In epoch 0, loss: 0.6677709817886353, train_auc: 0.7657732949217226, val_auc: 0.666806685213107\n",
      "In epoch 100, loss: 0.19247399270534515, train_auc: 0.9950024273547646, val_auc: 0.8639584616364755\n",
      "In epoch 200, loss: 0.048933934420347214, train_auc: 0.9992719061812146, val_auc: 0.8287910127630655\n",
      "Test AUC 0.8198755548004841\n",
      "\n",
      "layers 2 hidden_features 64 if_activate False if_normal True if_dropout True\n",
      "In epoch 0, loss: 0.6549840569496155, train_auc: 0.8212697762774336, val_auc: 0.7158423410987703\n",
      "In epoch 100, loss: 0.17783236503601074, train_auc: 0.9984813002269806, val_auc: 0.889228057508123\n",
      "In epoch 200, loss: 0.12762996554374695, train_auc: 0.9994702200851114, val_auc: 0.8777298307460341\n",
      "Test AUC 0.8786306780776827\n",
      "\n",
      "layers 2 hidden_features 64 if_activate False if_normal True if_dropout False\n",
      "In epoch 0, loss: 0.6280081868171692, train_auc: 0.8664887909256094, val_auc: 0.7688033298647243\n",
      "In epoch 100, loss: 0.06723718345165253, train_auc: 0.9996983029342986, val_auc: 0.8798305336702839\n",
      "In epoch 200, loss: 0.11434905976057053, train_auc: 0.9988882484657401, val_auc: 0.875462634585572\n",
      "Test AUC 0.8682792159527704\n",
      "\n",
      "layers 2 hidden_features 64 if_activate False if_normal False if_dropout True\n",
      "In epoch 0, loss: 0.6491351127624512, train_auc: 0.7995371346328968, val_auc: 0.6980097262630338\n",
      "In epoch 100, loss: 0.19705432653427124, train_auc: 0.9984604473921398, val_auc: 0.9051740321518826\n",
      "In epoch 200, loss: 0.12785257399082184, train_auc: 0.9994438692029648, val_auc: 0.8950238909299411\n",
      "Test AUC 0.8902733122385269\n",
      "\n",
      "layers 2 hidden_features 64 if_activate False if_normal False if_dropout False\n",
      "In epoch 0, loss: 0.6468323469161987, train_auc: 0.7910560323356193, val_auc: 0.695087600076451\n",
      "In epoch 100, loss: 0.0959358662366867, train_auc: 0.9989947648520937, val_auc: 0.8768200641338741\n",
      "In epoch 200, loss: 0.02256486751139164, train_auc: 0.9998398875886471, val_auc: 0.8514434368960904\n",
      "Test AUC 0.8491605258128225\n",
      "\n",
      "layers 5 hidden_features 64 if_activate True if_normal True if_dropout True\n",
      "In epoch 0, loss: 0.6464310884475708, train_auc: 0.8028288354272016, val_auc: 0.6949856654420354\n",
      "In epoch 100, loss: 0.33063387870788574, train_auc: 0.9877306040019639, val_auc: 0.8918333368727305\n",
      "In epoch 200, loss: 0.25809818506240845, train_auc: 0.9928365809172662, val_auc: 0.8759247382615898\n",
      "Test AUC 0.885894370235087\n",
      "\n",
      "layers 5 hidden_features 64 if_activate True if_normal True if_dropout False\n",
      "In epoch 0, loss: 0.6540172100067139, train_auc: 0.7812460785011989, val_auc: 0.6805729575909449\n",
      "In epoch 100, loss: 0.3407413065433502, train_auc: 0.9811199771429613, val_auc: 0.8896060651107477\n",
      "In epoch 200, loss: 0.24917462468147278, train_auc: 0.9917952772542047, val_auc: 0.8719416424217971\n",
      "Test AUC 0.8773157212937203\n",
      "\n",
      "layers 5 hidden_features 64 if_activate True if_normal False if_dropout True\n",
      "In epoch 0, loss: 0.6797613501548767, train_auc: 0.7683455464174035, val_auc: 0.6728743443267005\n",
      "In epoch 100, loss: 0.5042238235473633, train_auc: 0.9147780211756694, val_auc: 0.8587130752405021\n",
      "In epoch 200, loss: 0.40412142872810364, train_auc: 0.9690735700201629, val_auc: 0.883523115801992\n",
      "Test AUC 0.8686130518804817\n",
      "\n",
      "layers 5 hidden_features 64 if_activate True if_normal False if_dropout False\n",
      "In epoch 0, loss: 0.6826601624488831, train_auc: 0.7687043039403221, val_auc: 0.6718532990719701\n",
      "In epoch 100, loss: 0.3605910539627075, train_auc: 0.9741038991038633, val_auc: 0.8794126016691797\n",
      "In epoch 200, loss: 0.2466880828142166, train_auc: 0.986825559173933, val_auc: 0.8570761749028436\n",
      "Test AUC 0.8509826074030027\n",
      "\n",
      "layers 5 hidden_features 64 if_activate False if_normal True if_dropout True\n",
      "In epoch 0, loss: 0.6232808232307434, train_auc: 0.8045768700143971, val_auc: 0.7014780521990274\n",
      "In epoch 100, loss: 0.37193968892097473, train_auc: 0.9804912257524189, val_auc: 0.8827424663934252\n",
      "In epoch 200, loss: 0.299763560295105, train_auc: 0.9874924126947182, val_auc: 0.8646465204187814\n",
      "Test AUC 0.8686814330310688\n",
      "\n",
      "layers 5 hidden_features 64 if_activate False if_normal True if_dropout False\n",
      "In epoch 0, loss: 0.5902895331382751, train_auc: 0.8411697399028824, val_auc: 0.7443526088895496\n",
      "In epoch 100, loss: 0.34148654341697693, train_auc: 0.9847863003075303, val_auc: 0.8975085476438234\n",
      "In epoch 200, loss: 0.26685917377471924, train_auc: 0.9926180898421735, val_auc: 0.884211174584298\n",
      "Test AUC 0.8787946229480346\n",
      "\n",
      "layers 5 hidden_features 64 if_activate False if_normal False if_dropout True\n",
      "In epoch 0, loss: 0.6646897196769714, train_auc: 0.7790566964467406, val_auc: 0.6825819193442205\n",
      "In epoch 100, loss: 0.3922361731529236, train_auc: 0.9773121753104979, val_auc: 0.9047968740045443\n",
      "In epoch 200, loss: 0.3264090120792389, train_auc: 0.9880831281965514, val_auc: 0.8891367410647923\n",
      "Test AUC 0.8904483000276073\n",
      "\n",
      "layers 5 hidden_features 64 if_activate False if_normal False if_dropout False\n",
      "In epoch 0, loss: 0.6672477126121521, train_auc: 0.779980712850052, val_auc: 0.6860120197923082\n",
      "In epoch 100, loss: 0.38018184900283813, train_auc: 0.9765308034260756, val_auc: 0.8968748539998725\n",
      "In epoch 200, loss: 0.7012269496917725, train_auc: 0.9220522159753806, val_auc: 0.8197460128692475\n",
      "Test AUC 0.8136082736944934\n",
      "\n",
      "Best Parameter\n",
      "{'loop': None, 'layers': 2, 'if_activate': False, 'if_normal': False, 'if_dropout': True, 'auc': 0.9051740321518826, 'hidden_features': 64}\n",
      "In epoch 0, loss: 0.648439884185791, train_auc: 0.7910776535722522, val_auc: 0.6910815689439147\n",
      "In epoch 100, loss: 0.2053118795156479, train_auc: 0.9983121988394906, val_auc: 0.9074777548896771\n",
      "In epoch 200, loss: 0.13181059062480927, train_auc: 0.9994400669389247, val_auc: 0.8985329907197008\n",
      "Test AUC 0.885315041729491\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test auc 0.885315041729491\n"
     ]
    }
   ],
   "source": [
    "train_g, train_pos_g, train_neg_g, val_pos_g, val_neg_g, test_pos_g, test_neg_g = prepare_edge_data(G_cora)\n",
    "lr = 0.01\n",
    "layers = [2, 5]\n",
    "hidden_features = [16, 32, 64]\n",
    "if_activate = [True, False]\n",
    "if_normal = [True, False]\n",
    "if_dropout = [True, False]\n",
    "best_param_cora = {\"loop\": None, \"layers\": None, \"if_activate\": None, \"if_normal\": None, \"if_dropout\": None, \"auc\": 0.0}\n",
    "\n",
    "for h_f in hidden_features:\n",
    "    for l in layers:\n",
    "        for a in if_activate:\n",
    "            for n in if_normal:\n",
    "                for d in if_dropout:\n",
    "                    print(\"layers\", l, \"hidden_features\", h_f, \"if_activate\", a, \"if_normal\", n, \"if_dropout\", d)\n",
    "                    model = GCN(G_cora.ndata['feat'].shape[1], h_f, layers=l, if_activate=a, if_normal=n, if_dropout=d)\n",
    "                    pred = DotPredictor()\n",
    "                    best_val_auc, _ = train(train_g, train_pos_g, train_neg_g, val_pos_g, val_neg_g, test_pos_g, test_neg_g, model, pred, epochs=201, print_epoch=100, lr=lr)\n",
    "                    if best_val_auc > best_param_cora[\"auc\"]:\n",
    "                        best_param_cora[\"layers\"] = l\n",
    "                        best_param_cora[\"if_activate\"] = a\n",
    "                        best_param_cora[\"if_dropout\"] = d\n",
    "                        best_param_cora[\"if_normal\"] = n\n",
    "                        best_param_cora[\"hidden_features\"] = h_f\n",
    "                        best_param_cora[\"auc\"] = best_val_auc\n",
    "                    print()\n",
    "\n",
    "\n",
    "print(\"Best Parameter\")\n",
    "h_f = best_param_cora[\"hidden_features\"]\n",
    "l = best_param_cora[\"layers\"]\n",
    "a = best_param_cora[\"if_activate\"]\n",
    "n = best_param_cora[\"if_normal\"]\n",
    "d = best_param_cora[\"if_dropout\"]\n",
    "print(best_param_cora)\n",
    "model = GCN(G_cora.ndata['feat'].shape[1], h_f, layers=l, if_activate=a, if_normal=n, if_dropout=d)\n",
    "pred = DotPredictor()\n",
    "_, best_test_auc = train(train_g, train_pos_g, train_neg_g, val_pos_g, val_neg_g, test_pos_g, test_neg_g, model, pred, epochs=201, print_epoch=100, lr=lr, if_print=True)\n",
    "print(\"test auc\", best_test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers 2 hidden_features 16 if_activate True if_normal True if_dropout True\n",
      "In epoch 0, loss: 0.658103883266449, train_auc: 0.784961014153516, val_auc: 0.6229829890165746\n",
      "In epoch 200, loss: 0.3625699281692505, train_auc: 0.9908617587706031, val_auc: 0.8616686664814918\n",
      "Test AUC 0.859585447945401\n",
      "\n",
      "layers 2 hidden_features 16 if_activate True if_normal True if_dropout False\n",
      "In epoch 0, loss: 0.6382929086685181, train_auc: 0.8489106924775849, val_auc: 0.6816133613869682\n",
      "In epoch 200, loss: 0.12468383461236954, train_auc: 0.9967690345308233, val_auc: 0.8394071851641104\n",
      "Test AUC 0.8356146591112275\n",
      "\n",
      "layers 2 hidden_features 16 if_activate True if_normal False if_dropout True\n",
      "In epoch 0, loss: 0.6879550814628601, train_auc: 0.7675335275890105, val_auc: 0.5981148137360852\n",
      "In epoch 200, loss: 0.3829568326473236, train_auc: 0.9799593357709708, val_auc: 0.8419576519062715\n",
      "Test AUC 0.8363214352785326\n",
      "\n",
      "layers 2 hidden_features 16 if_activate True if_normal False if_dropout False\n",
      "In epoch 0, loss: 0.6876742243766785, train_auc: 0.7529153462640947, val_auc: 0.5807327306524944\n",
      "In epoch 200, loss: 0.06761963665485382, train_auc: 0.9976139715225995, val_auc: 0.7743314864565494\n",
      "Test AUC 0.7764231390757819\n",
      "\n",
      "layers 2 hidden_features 16 if_activate False if_normal True if_dropout True\n",
      "In epoch 0, loss: 0.6552472710609436, train_auc: 0.833747546384646, val_auc: 0.6438365407214401\n",
      "In epoch 200, loss: 0.23510326445102692, train_auc: 0.9965988505469222, val_auc: 0.8315207551540682\n",
      "Test AUC 0.8247684281905294\n",
      "\n",
      "layers 2 hidden_features 16 if_activate False if_normal True if_dropout False\n",
      "In epoch 0, loss: 0.6291752457618713, train_auc: 0.8607234166133446, val_auc: 0.691742132968381\n",
      "In epoch 200, loss: 0.28259915113449097, train_auc: 0.9959354747657855, val_auc: 0.8323844052678159\n",
      "Test AUC 0.8122522488077017\n",
      "\n",
      "layers 2 hidden_features 16 if_activate False if_normal False if_dropout True\n",
      "In epoch 0, loss: 0.6821903586387634, train_auc: 0.7656888618232913, val_auc: 0.6003639025739698\n",
      "In epoch 200, loss: 0.21330566704273224, train_auc: 0.9954010526016898, val_auc: 0.8336551404612207\n",
      "Test AUC 0.8033930878752745\n",
      "\n",
      "layers 2 hidden_features 16 if_activate False if_normal False if_dropout False\n",
      "In epoch 0, loss: 0.6809220314025879, train_auc: 0.8203553293284558, val_auc: 0.6493524310963521\n",
      "In epoch 200, loss: 0.027270231395959854, train_auc: 0.999648210877943, val_auc: 0.7865423520296341\n",
      "Test AUC 0.7640137914127538\n",
      "\n",
      "layers 5 hidden_features 16 if_activate True if_normal True if_dropout True\n",
      "In epoch 0, loss: 0.6516119241714478, train_auc: 0.8583414294674496, val_auc: 0.692212192535499\n",
      "In epoch 200, loss: 0.35660091042518616, train_auc: 0.9822792269797324, val_auc: 0.846741463864452\n",
      "Test AUC 0.846731905236891\n",
      "\n",
      "layers 5 hidden_features 16 if_activate True if_normal True if_dropout False\n",
      "In epoch 0, loss: 0.6691706776618958, train_auc: 0.8139324850941637, val_auc: 0.6503948837727115\n",
      "In epoch 200, loss: 0.2566949427127838, train_auc: 0.9814176151027442, val_auc: 0.8495843121555381\n",
      "Test AUC 0.831431916144972\n",
      "\n",
      "layers 5 hidden_features 16 if_activate True if_normal False if_dropout True\n",
      "In epoch 0, loss: 0.6913535594940186, train_auc: 0.7532772475004189, val_auc: 0.5744004210294305\n",
      "In epoch 200, loss: 0.32635194063186646, train_auc: 0.9702999999859433, val_auc: 0.8044299178295393\n",
      "Test AUC 0.8248657012827678\n",
      "\n",
      "layers 5 hidden_features 16 if_activate True if_normal False if_dropout False\n",
      "In epoch 0, loss: 0.6920208930969238, train_auc: 0.7617930533939312, val_auc: 0.5874743744440534\n",
      "In epoch 200, loss: 0.281144917011261, train_auc: 0.9763279446336177, val_auc: 0.8155049935394924\n",
      "Test AUC 0.8310917414582418\n",
      "\n",
      "layers 5 hidden_features 16 if_activate False if_normal True if_dropout True\n",
      "In epoch 0, loss: 0.6294113397598267, train_auc: 0.7747909594922231, val_auc: 0.6093962433469141\n",
      "In epoch 200, loss: 0.2941890358924866, train_auc: 0.9876329369642249, val_auc: 0.8211299647230416\n",
      "Test AUC 0.8149342872468791\n",
      "\n",
      "layers 5 hidden_features 16 if_activate False if_normal True if_dropout False\n",
      "In epoch 0, loss: 0.5986548066139221, train_auc: 0.7425711629279313, val_auc: 0.5821856420417678\n",
      "In epoch 200, loss: 0.23401519656181335, train_auc: 0.9899815304121793, val_auc: 0.8294808315781069\n",
      "Test AUC 0.8041004263147892\n",
      "\n",
      "layers 5 hidden_features 16 if_activate False if_normal False if_dropout True\n",
      "In epoch 0, loss: 0.6860799193382263, train_auc: 0.7935809019043035, val_auc: 0.6263959813280645\n",
      "In epoch 200, loss: 0.28938329219818115, train_auc: 0.9853722688330265, val_auc: 0.7811344179189407\n",
      "Test AUC 0.7774014927202617\n",
      "\n",
      "layers 5 hidden_features 16 if_activate False if_normal False if_dropout False\n",
      "In epoch 0, loss: 0.6835874319076538, train_auc: 0.7568528946195048, val_auc: 0.585241029228034\n",
      "In epoch 200, loss: 0.2483251392841339, train_auc: 0.986559770168423, val_auc: 0.8080301467867831\n",
      "Test AUC 0.8175724684537178\n",
      "\n",
      "layers 2 hidden_features 32 if_activate True if_normal True if_dropout True\n",
      "In epoch 0, loss: 0.6587910652160645, train_auc: 0.7715756673608855, val_auc: 0.6109537373671492\n",
      "In epoch 200, loss: 0.26347607374191284, train_auc: 0.9965268269910901, val_auc: 0.8826560389722113\n",
      "Test AUC 0.8607662195852905\n",
      "\n",
      "layers 2 hidden_features 32 if_activate True if_normal True if_dropout False\n",
      "In epoch 0, loss: 0.6351260542869568, train_auc: 0.8968718793892374, val_auc: 0.7315633753875461\n",
      "In epoch 200, loss: 0.05494268983602524, train_auc: 0.9993333735826524, val_auc: 0.8202798091423211\n",
      "Test AUC 0.8339334652049089\n",
      "\n",
      "layers 2 hidden_features 32 if_activate True if_normal False if_dropout True\n",
      "In epoch 0, loss: 0.6811932325363159, train_auc: 0.7665601465393832, val_auc: 0.5892432828150496\n",
      "In epoch 200, loss: 0.34715166687965393, train_auc: 0.988390906259102, val_auc: 0.8612329055191517\n",
      "Test AUC 0.8457777292974185\n",
      "\n",
      "layers 2 hidden_features 32 if_activate True if_normal False if_dropout False\n",
      "In epoch 0, loss: 0.6839215159416199, train_auc: 0.7682058294414725, val_auc: 0.5911977410151712\n",
      "In epoch 200, loss: 0.13839948177337646, train_auc: 0.9913393562995291, val_auc: 0.763634257671361\n",
      "Test AUC 0.7805097334942181\n",
      "\n",
      "layers 2 hidden_features 32 if_activate False if_normal True if_dropout True\n",
      "In epoch 0, loss: 0.6526487469673157, train_auc: 0.8183351907058654, val_auc: 0.6405123874190468\n",
      "In epoch 200, loss: 0.14515583217144012, train_auc: 0.9983049425695165, val_auc: 0.8465896503678948\n",
      "Test AUC 0.8273470085431638\n",
      "\n",
      "layers 2 hidden_features 32 if_activate False if_normal True if_dropout False\n",
      "In epoch 0, loss: 0.6264116168022156, train_auc: 0.8921577189010051, val_auc: 0.7271203003883052\n",
      "In epoch 200, loss: 0.0318620465695858, train_auc: 0.9996899595894962, val_auc: 0.7946851781671951\n",
      "Test AUC 0.8103236551292157\n",
      "\n",
      "layers 2 hidden_features 32 if_activate False if_normal False if_dropout True\n",
      "In epoch 0, loss: 0.670877993106842, train_auc: 0.7902889738279155, val_auc: 0.6140732235852949\n",
      "In epoch 200, loss: 0.13606545329093933, train_auc: 0.998553800735227, val_auc: 0.8345154169417115\n",
      "Test AUC 0.8268375899213831\n",
      "\n",
      "layers 2 hidden_features 32 if_activate False if_normal False if_dropout False\n",
      "In epoch 0, loss: 0.6689490079879761, train_auc: 0.7769674712875696, val_auc: 0.6025815041681238\n",
      "In epoch 200, loss: 0.031150732189416885, train_auc: 0.9995806152157607, val_auc: 0.8070742840306823\n",
      "Test AUC 0.7847593868534011\n",
      "\n",
      "layers 5 hidden_features 32 if_activate True if_normal True if_dropout True\n",
      "In epoch 0, loss: 0.6485486030578613, train_auc: 0.8601366943482648, val_auc: 0.6897258248252177\n",
      "In epoch 200, loss: 0.2266169786453247, train_auc: 0.9922996118072667, val_auc: 0.8427414593662742\n",
      "Test AUC 0.8355696773344699\n",
      "\n",
      "layers 5 hidden_features 32 if_activate True if_normal True if_dropout False\n",
      "In epoch 0, loss: 0.6427555084228516, train_auc: 0.8023584894388411, val_auc: 0.6345523019986528\n",
      "In epoch 200, loss: 0.1040119007229805, train_auc: 0.9974222015571567, val_auc: 0.8190191948486869\n",
      "Test AUC 0.8200014843986331\n",
      "\n",
      "layers 5 hidden_features 32 if_activate True if_normal False if_dropout True\n",
      "In epoch 0, loss: 0.689947247505188, train_auc: 0.7564649619369828, val_auc: 0.579785864251745\n",
      "In epoch 200, loss: 0.2538285553455353, train_auc: 0.9874237365602885, val_auc: 0.8453751423954371\n",
      "Test AUC 0.8419497800953388\n",
      "\n",
      "layers 5 hidden_features 32 if_activate True if_normal False if_dropout False\n",
      "In epoch 0, loss: 0.6899846196174622, train_auc: 0.7578046018325576, val_auc: 0.5772039102658536\n",
      "In epoch 200, loss: 0.14728431403636932, train_auc: 0.9924304191654981, val_auc: 0.8079053223562803\n",
      "Test AUC 0.8244355630425224\n",
      "\n",
      "layers 5 hidden_features 32 if_activate False if_normal True if_dropout True\n",
      "In epoch 0, loss: 0.6285533905029297, train_auc: 0.8726466711657814, val_auc: 0.7255346927575965\n",
      "In epoch 200, loss: 0.22608822584152222, train_auc: 0.9932965819331817, val_auc: 0.8200560248029517\n",
      "Test AUC 0.8264439993747533\n",
      "\n",
      "layers 5 hidden_features 32 if_activate False if_normal True if_dropout False\n",
      "In epoch 0, loss: 0.5868657231330872, train_auc: 0.8028892656190786, val_auc: 0.6476071381581536\n",
      "In epoch 200, loss: 0.17488746345043182, train_auc: 0.9946815989531614, val_auc: 0.8173503709309766\n",
      "Test AUC 0.8154763176568093\n",
      "\n",
      "layers 5 hidden_features 32 if_activate False if_normal False if_dropout True\n",
      "In epoch 0, loss: 0.6760764122009277, train_auc: 0.7726520408653819, val_auc: 0.5915598443180706\n",
      "In epoch 200, loss: 0.20923356711864471, train_auc: 0.9940602705906894, val_auc: 0.7979306133602624\n",
      "Test AUC 0.7933171698815518\n",
      "\n",
      "layers 5 hidden_features 32 if_activate False if_normal False if_dropout False\n",
      "In epoch 0, loss: 0.6778185963630676, train_auc: 0.7754988074909278, val_auc: 0.5971150937476455\n",
      "In epoch 200, loss: 0.1881273090839386, train_auc: 0.9923320215288406, val_auc: 0.8132289156355532\n",
      "Test AUC 0.7943360071251135\n",
      "\n",
      "layers 2 hidden_features 64 if_activate True if_normal True if_dropout True\n",
      "In epoch 0, loss: 0.6517120599746704, train_auc: 0.7829092652901494, val_auc: 0.6164572577534526\n",
      "In epoch 200, loss: 0.16591449081897736, train_auc: 0.9980577712204343, val_auc: 0.8694505138605724\n",
      "Test AUC 0.857111450223728\n",
      "\n",
      "layers 2 hidden_features 64 if_activate True if_normal True if_dropout False\n",
      "In epoch 0, loss: 0.6350082159042358, train_auc: 0.9047325151616701, val_auc: 0.7386153934387332\n",
      "In epoch 200, loss: 0.03492114692926407, train_auc: 0.9996183928798346, val_auc: 0.8152362274233651\n",
      "Test AUC 0.8114122141267519\n",
      "\n",
      "layers 2 hidden_features 64 if_activate True if_normal False if_dropout True\n",
      "In epoch 0, loss: 0.6758067011833191, train_auc: 0.7750670702890866, val_auc: 0.5979854911279068\n",
      "In epoch 200, loss: 0.3276692032814026, train_auc: 0.9878801610263268, val_auc: 0.8437265602772677\n",
      "Test AUC 0.8417704152605175\n",
      "\n",
      "layers 2 hidden_features 64 if_activate True if_normal False if_dropout False\n",
      "In epoch 0, loss: 0.6760063767433167, train_auc: 0.7750481199585268, val_auc: 0.5932455364020651\n",
      "In epoch 200, loss: 0.031351830810308456, train_auc: 0.9995376013917361, val_auc: 0.7796432720194231\n",
      "Test AUC 0.7789117558749012\n",
      "\n",
      "layers 2 hidden_features 64 if_activate False if_normal True if_dropout True\n",
      "In epoch 0, loss: 0.6506274342536926, train_auc: 0.8400185156238579, val_auc: 0.6565787535324752\n",
      "In epoch 200, loss: 0.09193030744791031, train_auc: 0.999250526286788, val_auc: 0.8472362634087867\n",
      "Test AUC 0.8378401325163143\n",
      "\n",
      "layers 2 hidden_features 64 if_activate False if_normal True if_dropout False\n",
      "In epoch 0, loss: 0.6217727065086365, train_auc: 0.8747267796337135, val_auc: 0.6908110101894969\n",
      "In epoch 200, loss: 0.026773804798722267, train_auc: 0.9997467842246659, val_auc: 0.8128386987221803\n",
      "Test AUC 0.808059947213885\n",
      "\n",
      "layers 2 hidden_features 64 if_activate False if_normal False if_dropout True\n",
      "In epoch 0, loss: 0.6506121158599854, train_auc: 0.8137730545662689, val_auc: 0.6358972571237078\n",
      "In epoch 200, loss: 0.0822017565369606, train_auc: 0.999308387611344, val_auc: 0.8449905482041588\n",
      "Test AUC 0.8351749622434211\n",
      "\n",
      "layers 2 hidden_features 64 if_activate False if_normal False if_dropout False\n",
      "In epoch 0, loss: 0.652672529220581, train_auc: 0.8056703254656458, val_auc: 0.628683304676193\n",
      "In epoch 200, loss: 0.027329711243510246, train_auc: 0.9996521994964289, val_auc: 0.8127925924010035\n",
      "Test AUC 0.796759400347934\n",
      "\n",
      "layers 5 hidden_features 64 if_activate True if_normal True if_dropout True\n",
      "In epoch 0, loss: 0.6404768228530884, train_auc: 0.7720450504442511, val_auc: 0.5955553506385726\n",
      "In epoch 200, loss: 0.171173557639122, train_auc: 0.9943671130780016, val_auc: 0.8329039447893674\n",
      "Test AUC 0.8317203617884303\n",
      "\n",
      "layers 5 hidden_features 64 if_activate True if_normal True if_dropout False\n",
      "In epoch 0, loss: 0.6456157565116882, train_auc: 0.7740009494669097, val_auc: 0.6053681252382628\n",
      "In epoch 200, loss: 0.09054618328809738, train_auc: 0.9976785976846756, val_auc: 0.8252795336289386\n",
      "Test AUC 0.8211080361068722\n",
      "\n",
      "layers 5 hidden_features 64 if_activate True if_normal False if_dropout True\n",
      "In epoch 0, loss: 0.6837430000305176, train_auc: 0.7590384115557061, val_auc: 0.5823307082718114\n",
      "In epoch 200, loss: 0.18894270062446594, train_auc: 0.9909325084284605, val_auc: 0.8636771028137227\n",
      "Test AUC 0.843456107344512\n",
      "\n",
      "layers 5 hidden_features 64 if_activate True if_normal False if_dropout False\n",
      "In epoch 0, loss: 0.6832350492477417, train_auc: 0.7608831388199481, val_auc: 0.5809070350374305\n",
      "In epoch 200, loss: 0.09362276643514633, train_auc: 0.9961306622920014, val_auc: 0.8091670611943336\n",
      "Test AUC 0.8100728817237918\n",
      "\n",
      "layers 5 hidden_features 64 if_activate False if_normal True if_dropout True\n",
      "In epoch 0, loss: 0.6200225353240967, train_auc: 0.7995696983493938, val_auc: 0.6164842468195072\n",
      "In epoch 200, loss: 0.16940809786319733, train_auc: 0.9968002406384487, val_auc: 0.8243562826609869\n",
      "Test AUC 0.8308623343967775\n",
      "\n",
      "layers 5 hidden_features 64 if_activate False if_normal True if_dropout False\n",
      "In epoch 0, loss: 0.5864675641059875, train_auc: 0.8388450710936981, val_auc: 0.6614986353653477\n",
      "In epoch 200, loss: 0.10668479651212692, train_auc: 0.9977810190818319, val_auc: 0.8124586027085777\n",
      "Test AUC 0.8217265355372904\n",
      "\n",
      "layers 5 hidden_features 64 if_activate False if_normal False if_dropout True\n",
      "In epoch 0, loss: 0.6604313850402832, train_auc: 0.8274108703664553, val_auc: 0.6659090985764393\n",
      "In epoch 200, loss: 0.17865896224975586, train_auc: 0.9957835294866793, val_auc: 0.7928825334636306\n",
      "Test AUC 0.8048077647543039\n",
      "\n",
      "layers 5 hidden_features 64 if_activate False if_normal False if_dropout False\n",
      "In epoch 0, loss: 0.6615409255027771, train_auc: 0.7711428495421417, val_auc: 0.5947715431785698\n",
      "In epoch 200, loss: 0.17683066427707672, train_auc: 0.993131678036748, val_auc: 0.7990439123350154\n",
      "Test AUC 0.8102708015415256\n",
      "\n",
      "Best Parameter\n",
      "{'loop': None, 'layers': 2, 'if_activate': True, 'if_normal': True, 'if_dropout': True, 'auc': 0.8826560389722113, 'hidden_features': 32}\n",
      "In epoch 0, loss: 0.654634416103363, train_auc: 0.7816190438504851, val_auc: 0.6216987592901426\n",
      "In epoch 200, loss: 0.26236918568611145, train_auc: 0.9960166528160279, val_auc: 0.8664727202392132\n",
      "Test AUC 0.8575106634924526\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test auc 0.8575106634924526\n"
     ]
    }
   ],
   "source": [
    "train_g, train_pos_g, train_neg_g, val_pos_g, val_neg_g, test_pos_g, test_neg_g = prepare_edge_data(G_citeseer)\n",
    "lr = 0.01\n",
    "layers = [2, 5]\n",
    "hidden_features = [16, 32, 64]\n",
    "if_activate = [True, False]\n",
    "if_normal = [True, False]\n",
    "if_dropout = [True, False]\n",
    "best_param_citeseer = {\"loop\": None, \"layers\": None, \"if_activate\": None, \"if_normal\": None, \"if_dropout\": None, \"auc\": 0.0}\n",
    "\n",
    "for h_f in hidden_features:\n",
    "    for l in layers:\n",
    "        for a in if_activate:\n",
    "            for n in if_normal:\n",
    "                for d in if_dropout:\n",
    "                    print(\"layers\", l, \"hidden_features\", h_f, \"if_activate\", a, \"if_normal\", n, \"if_dropout\", d)\n",
    "                    model = GCN(G_citeseer.ndata['feat'].shape[1], h_f, layers=l, if_activate=a, if_normal=n, if_dropout=d)\n",
    "                    pred = DotPredictor()\n",
    "                    best_val_auc, _ = train(train_g, train_pos_g, train_neg_g, val_pos_g, val_neg_g, test_pos_g, test_neg_g, model, pred, epochs=201, print_epoch=200, lr=lr)\n",
    "                    if best_val_auc > best_param_citeseer[\"auc\"]:\n",
    "                        best_param_citeseer[\"layers\"] = l\n",
    "                        best_param_citeseer[\"if_activate\"] = a\n",
    "                        best_param_citeseer[\"if_dropout\"] = d\n",
    "                        best_param_citeseer[\"if_normal\"] = n\n",
    "                        best_param_citeseer[\"hidden_features\"] = h_f\n",
    "                        best_param_citeseer[\"auc\"] = best_val_auc\n",
    "                    print()\n",
    "    \n",
    "print(\"Best Parameter\")\n",
    "h_f = best_param_citeseer[\"hidden_features\"]\n",
    "l = best_param_citeseer[\"layers\"]\n",
    "a = best_param_citeseer[\"if_activate\"]\n",
    "n = best_param_citeseer[\"if_normal\"]\n",
    "d = best_param_citeseer[\"if_dropout\"]\n",
    "print(best_param_citeseer)\n",
    "model = GCN(G_citeseer.ndata['feat'].shape[1], h_f, layers=l, if_activate=a, if_normal=n, if_dropout=d)\n",
    "pred = DotPredictor()\n",
    "_, best_test_auc = train(train_g, train_pos_g, train_neg_g, val_pos_g, val_neg_g, test_pos_g, test_neg_g, model, pred, epochs=201, print_epoch=200, lr=lr, if_print=True)\n",
    "print(\"test auc\", best_test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers 2 hidden_features 16 if_activate True if_normal True if_dropout True\n",
      "In epoch 0, loss: 0.6615186333656311, train_auc: 0.7527437753385775, val_auc: 0.740675834229984\n",
      "In epoch 20, loss: 0.6389572620391846, train_auc: 0.7485553492924035, val_auc: 0.7393189959355444\n",
      "In epoch 40, loss: 0.6318160891532898, train_auc: 0.7643517629645004, val_auc: 0.7541156378190618\n",
      "In epoch 60, loss: 0.6280354857444763, train_auc: 0.7694762801210534, val_auc: 0.7578141757758798\n",
      "In epoch 80, loss: 0.6236305236816406, train_auc: 0.776364263619828, val_auc: 0.7625042139079137\n",
      "In epoch 100, loss: 0.6200175285339355, train_auc: 0.78054973161286, val_auc: 0.7639596377966826\n",
      "In epoch 120, loss: 0.6170827746391296, train_auc: 0.7859380874808357, val_auc: 0.7677543890771159\n",
      "In epoch 140, loss: 0.6151933670043945, train_auc: 0.7898268622889263, val_auc: 0.7701085954145528\n",
      "In epoch 160, loss: 0.6136417984962463, train_auc: 0.791951645991966, val_auc: 0.7715414271582497\n",
      "In epoch 180, loss: 0.6140868663787842, train_auc: 0.7944187323127919, val_auc: 0.7734580057935594\n",
      "Test AUC 0.7574570481809305\n",
      "\n",
      "layers 2 hidden_features 16 if_activate True if_normal True if_dropout False\n",
      "In epoch 0, loss: 0.658690333366394, train_auc: 0.751593283206454, val_auc: 0.7389405357323764\n",
      "In epoch 20, loss: 0.6380649209022522, train_auc: 0.7462515934894428, val_auc: 0.7373547798783782\n",
      "In epoch 40, loss: 0.6294628977775574, train_auc: 0.7576169487084061, val_auc: 0.7483629639884081\n",
      "In epoch 60, loss: 0.6231546998023987, train_auc: 0.7670272683229383, val_auc: 0.7550339457370794\n",
      "In epoch 80, loss: 0.6162575483322144, train_auc: 0.7760682248111761, val_auc: 0.7616719424646025\n",
      "In epoch 100, loss: 0.6095920205116272, train_auc: 0.7838261119841682, val_auc: 0.7670593312876846\n",
      "In epoch 120, loss: 0.6041319966316223, train_auc: 0.7901109201441059, val_auc: 0.7722170190797496\n",
      "In epoch 140, loss: 0.6004278063774109, train_auc: 0.7916388625872895, val_auc: 0.7724710704603772\n",
      "In epoch 160, loss: 0.598970353603363, train_auc: 0.7879651661287661, val_auc: 0.7674008969448899\n",
      "In epoch 180, loss: 0.6017183661460876, train_auc: 0.7866756274030107, val_auc: 0.7651989015893967\n",
      "Test AUC 0.7734498947044423\n",
      "\n",
      "layers 2 hidden_features 16 if_activate True if_normal False if_dropout True\n",
      "In epoch 0, loss: 0.691493570804596, train_auc: 0.6984218946951812, val_auc: 0.6887523278137628\n",
      "In epoch 20, loss: 0.6526079773902893, train_auc: 0.7206302585815776, val_auc: 0.7118128391802857\n",
      "In epoch 40, loss: 0.6418103575706482, train_auc: 0.7368479159592293, val_auc: 0.7291853547727668\n",
      "In epoch 60, loss: 0.6370174884796143, train_auc: 0.750375443471478, val_auc: 0.7428284822220579\n",
      "In epoch 80, loss: 0.6344906091690063, train_auc: 0.7545987808248147, val_auc: 0.7461173060811067\n",
      "In epoch 100, loss: 0.6330578327178955, train_auc: 0.7578208375839198, val_auc: 0.7481342939351139\n",
      "In epoch 120, loss: 0.6323184967041016, train_auc: 0.7593974694748736, val_auc: 0.7492397466510299\n",
      "In epoch 140, loss: 0.6319053173065186, train_auc: 0.7601492129394134, val_auc: 0.7498598779237249\n",
      "In epoch 160, loss: 0.6312758922576904, train_auc: 0.7615232683112381, val_auc: 0.7509886102523848\n",
      "In epoch 180, loss: 0.6306678056716919, train_auc: 0.7629057743859946, val_auc: 0.7521343514383235\n",
      "Test AUC 0.7441319166014867\n",
      "\n",
      "layers 2 hidden_features 16 if_activate True if_normal False if_dropout False\n",
      "In epoch 0, loss: 0.6924629211425781, train_auc: 0.7011375229883201, val_auc: 0.6908835059427875\n",
      "In epoch 20, loss: 0.6518896222114563, train_auc: 0.7212303530208548, val_auc: 0.7123677482257236\n",
      "In epoch 40, loss: 0.6403073072433472, train_auc: 0.740283934200494, val_auc: 0.732575742282988\n",
      "In epoch 60, loss: 0.6344119906425476, train_auc: 0.751289983354026, val_auc: 0.7441841371411558\n",
      "In epoch 80, loss: 0.6303818225860596, train_auc: 0.7577967000520557, val_auc: 0.7490654972428211\n",
      "In epoch 100, loss: 0.6270087957382202, train_auc: 0.7610630051406713, val_auc: 0.7508018141115937\n",
      "In epoch 120, loss: 0.6241108179092407, train_auc: 0.7644450018973251, val_auc: 0.7531435548758263\n",
      "In epoch 140, loss: 0.6217848062515259, train_auc: 0.766245137586165, val_auc: 0.7542117415625977\n",
      "In epoch 160, loss: 0.6197774410247803, train_auc: 0.7687271349235033, val_auc: 0.7562756063422683\n",
      "In epoch 180, loss: 0.6178747415542603, train_auc: 0.7717520015837529, val_auc: 0.7586622424901464\n",
      "Test AUC 0.7594882879350019\n",
      "\n",
      "layers 2 hidden_features 16 if_activate False if_normal True if_dropout True\n",
      "In epoch 0, loss: 0.6782064437866211, train_auc: 0.7542045047318662, val_auc: 0.7405901987780861\n",
      "In epoch 20, loss: 0.6414555907249451, train_auc: 0.7388354466239946, val_auc: 0.7294982194752153\n",
      "In epoch 40, loss: 0.6338220834732056, train_auc: 0.7641767222925886, val_auc: 0.7532350816929361\n",
      "In epoch 60, loss: 0.6291561126708984, train_auc: 0.7669873500790403, val_auc: 0.7558442573026783\n",
      "In epoch 80, loss: 0.6264755129814148, train_auc: 0.7716558313267886, val_auc: 0.7588592960424642\n",
      "In epoch 100, loss: 0.6235141158103943, train_auc: 0.7772493726337892, val_auc: 0.7621145305115408\n",
      "In epoch 120, loss: 0.6200515031814575, train_auc: 0.7809231919294051, val_auc: 0.7636131204476879\n",
      "In epoch 140, loss: 0.6181818246841431, train_auc: 0.7845821892570096, val_auc: 0.7662164995770795\n",
      "In epoch 160, loss: 0.6163716912269592, train_auc: 0.7876761695515783, val_auc: 0.7685504714941306\n",
      "In epoch 180, loss: 0.6150074005126953, train_auc: 0.7899399794597076, val_auc: 0.7699460965863157\n",
      "Test AUC 0.7523453174087855\n",
      "\n",
      "layers 2 hidden_features 16 if_activate False if_normal True if_dropout False\n",
      "In epoch 0, loss: 0.6696197986602783, train_auc: 0.7582693977218024, val_auc: 0.7438892637123529\n",
      "In epoch 20, loss: 0.6375579833984375, train_auc: 0.7457848069060609, val_auc: 0.736158368460998\n",
      "In epoch 40, loss: 0.6294271349906921, train_auc: 0.7569806842092773, val_auc: 0.7463149587805968\n",
      "In epoch 60, loss: 0.6233689785003662, train_auc: 0.7663399812615022, val_auc: 0.7521335286552916\n",
      "In epoch 80, loss: 0.6165674924850464, train_auc: 0.7717691533620362, val_auc: 0.7541991643952487\n",
      "In epoch 100, loss: 0.6125451326370239, train_auc: 0.7766008251211969, val_auc: 0.7577339979937678\n",
      "In epoch 120, loss: 0.6098541021347046, train_auc: 0.7790656169471821, val_auc: 0.7591957896115239\n",
      "In epoch 140, loss: 0.6075324416160583, train_auc: 0.7820110173593888, val_auc: 0.7610615903001884\n",
      "In epoch 160, loss: 0.605440616607666, train_auc: 0.7854158697443794, val_auc: 0.7632445452777242\n",
      "In epoch 180, loss: 0.6037371754646301, train_auc: 0.7864910443827372, val_auc: 0.7627636702196505\n",
      "Test AUC 0.7615538629546155\n",
      "\n",
      "layers 2 hidden_features 16 if_activate False if_normal False if_dropout True\n",
      "In epoch 0, loss: 0.6906930804252625, train_auc: 0.7005426596921446, val_auc: 0.6900669126562555\n",
      "In epoch 20, loss: 0.6508319973945618, train_auc: 0.7152089142092809, val_auc: 0.7071173647872355\n",
      "In epoch 40, loss: 0.6408511996269226, train_auc: 0.740799350041564, val_auc: 0.7328218960654354\n",
      "In epoch 60, loss: 0.6378122568130493, train_auc: 0.7482090511555107, val_auc: 0.740820076002532\n",
      "In epoch 80, loss: 0.6363512873649597, train_auc: 0.7508861009847925, val_auc: 0.7429670587268891\n",
      "In epoch 100, loss: 0.6352532505989075, train_auc: 0.7519288484546927, val_auc: 0.7438309174299303\n",
      "In epoch 120, loss: 0.6349300742149353, train_auc: 0.7528783810400617, val_auc: 0.7441805045130433\n",
      "In epoch 140, loss: 0.6347411274909973, train_auc: 0.7533389421574798, val_auc: 0.7439457952472147\n",
      "In epoch 160, loss: 0.6337130665779114, train_auc: 0.7534855050683442, val_auc: 0.7436319960929947\n",
      "In epoch 180, loss: 0.6337000131607056, train_auc: 0.753682284840353, val_auc: 0.7435988882138539\n",
      "Test AUC 0.7407477177922132\n",
      "\n",
      "layers 2 hidden_features 16 if_activate False if_normal False if_dropout False\n",
      "In epoch 0, loss: 0.6908025741577148, train_auc: 0.7004217733433132, val_auc: 0.6898965707587952\n",
      "In epoch 20, loss: 0.6519737839698792, train_auc: 0.7177521308405709, val_auc: 0.7090210490025911\n",
      "In epoch 40, loss: 0.6411978006362915, train_auc: 0.7383354813236506, val_auc: 0.7302379836991154\n",
      "In epoch 60, loss: 0.63706374168396, train_auc: 0.7474319645881939, val_auc: 0.7404340386613745\n",
      "In epoch 80, loss: 0.6353625655174255, train_auc: 0.7506178081886353, val_auc: 0.7429257562122125\n",
      "In epoch 100, loss: 0.6342782974243164, train_auc: 0.7520166661716368, val_auc: 0.7438492413973493\n",
      "In epoch 120, loss: 0.6334397196769714, train_auc: 0.7527022805252559, val_auc: 0.7434301436194816\n",
      "In epoch 140, loss: 0.6329260468482971, train_auc: 0.7521384708125872, val_auc: 0.7422120621260281\n",
      "In epoch 160, loss: 0.6324155330657959, train_auc: 0.7530363866179725, val_auc: 0.7426645953297539\n",
      "In epoch 180, loss: 0.6315922737121582, train_auc: 0.7546850113916923, val_auc: 0.743788680165102\n",
      "Test AUC 0.746635999768207\n",
      "\n",
      "layers 5 hidden_features 16 if_activate True if_normal True if_dropout True\n",
      "In epoch 0, loss: 0.6585691571235657, train_auc: 0.7480898700466524, val_auc: 0.7366040075187055\n",
      "In epoch 20, loss: 0.637496292591095, train_auc: 0.7597012070032108, val_auc: 0.74988008452017\n",
      "In epoch 40, loss: 0.6291680335998535, train_auc: 0.7750390568856151, val_auc: 0.7634490309553192\n",
      "In epoch 60, loss: 0.6257805824279785, train_auc: 0.780488517309689, val_auc: 0.7689398030258109\n",
      "In epoch 80, loss: 0.6240145564079285, train_auc: 0.782712960921473, val_auc: 0.7713701032173973\n",
      "In epoch 100, loss: 0.6205080151557922, train_auc: 0.7870469945308316, val_auc: 0.7737850275858063\n",
      "In epoch 120, loss: 0.6195878386497498, train_auc: 0.7904098452200015, val_auc: 0.7774968113797012\n",
      "In epoch 140, loss: 0.6168556213378906, train_auc: 0.7929380983499882, val_auc: 0.7794341960570086\n",
      "In epoch 160, loss: 0.6142035126686096, train_auc: 0.7945104821547302, val_auc: 0.7801655341024418\n",
      "In epoch 180, loss: 0.6120626330375671, train_auc: 0.7984013248666294, val_auc: 0.7839621746508574\n",
      "Test AUC 0.7630768167420714\n",
      "\n",
      "layers 5 hidden_features 16 if_activate True if_normal True if_dropout False\n",
      "In epoch 0, loss: 0.6534866094589233, train_auc: 0.7492128595502089, val_auc: 0.7390476763307662\n",
      "In epoch 20, loss: 0.6371542811393738, train_auc: 0.7691679971027884, val_auc: 0.7587933929864915\n",
      "In epoch 40, loss: 0.62579745054245, train_auc: 0.7717671567604328, val_auc: 0.7607126746468188\n",
      "In epoch 60, loss: 0.6226428151130676, train_auc: 0.7746116086714153, val_auc: 0.7644807537331582\n",
      "In epoch 80, loss: 0.6185789704322815, train_auc: 0.7792155408276227, val_auc: 0.7681143488210559\n",
      "In epoch 100, loss: 0.6176880598068237, train_auc: 0.780280675415966, val_auc: 0.76736856261607\n",
      "In epoch 120, loss: 0.6132414937019348, train_auc: 0.7824483685146472, val_auc: 0.7691825726561454\n",
      "In epoch 140, loss: 0.6092844605445862, train_auc: 0.7847894538308485, val_auc: 0.7709388570443352\n",
      "In epoch 160, loss: 0.6073530912399292, train_auc: 0.7849600929051485, val_auc: 0.770102209782762\n",
      "In epoch 180, loss: 0.6029637455940247, train_auc: 0.793145793279069, val_auc: 0.7786700932695104\n",
      "Test AUC 0.7754800714049337\n",
      "\n",
      "layers 5 hidden_features 16 if_activate True if_normal False if_dropout True\n",
      "In epoch 0, loss: 0.6931139826774597, train_auc: 0.676074544287517, val_auc: 0.6676477455202399\n",
      "In epoch 20, loss: 0.6396955251693726, train_auc: 0.7530818962992942, val_auc: 0.7432937657281662\n",
      "In epoch 40, loss: 0.626990556716919, train_auc: 0.7681020763882869, val_auc: 0.7610674595852753\n",
      "In epoch 60, loss: 0.6218513250350952, train_auc: 0.7751690799751756, val_auc: 0.7660247356319757\n",
      "In epoch 80, loss: 0.618154764175415, train_auc: 0.7762382708776157, val_auc: 0.7653844924985067\n",
      "In epoch 100, loss: 0.6166101694107056, train_auc: 0.7770763094372026, val_auc: 0.7651839695319722\n",
      "In epoch 120, loss: 0.6158779859542847, train_auc: 0.7761702642596808, val_auc: 0.7638204869102245\n",
      "In epoch 140, loss: 0.6148455739021301, train_auc: 0.7755457529108448, val_auc: 0.7631293166400772\n",
      "In epoch 160, loss: 0.6148366332054138, train_auc: 0.7769897301555014, val_auc: 0.7645354664923281\n",
      "In epoch 180, loss: 0.6138526797294617, train_auc: 0.775956933436527, val_auc: 0.7633357012830069\n",
      "Test AUC 0.7590029796950989\n",
      "\n",
      "layers 5 hidden_features 16 if_activate True if_normal False if_dropout False\n",
      "In epoch 0, loss: 0.6931403875350952, train_auc: 0.6891616428907024, val_auc: 0.6804610753207512\n",
      "In epoch 20, loss: 0.6416978240013123, train_auc: 0.7555555117684875, val_auc: 0.7453498145911998\n",
      "In epoch 40, loss: 0.624848484992981, train_auc: 0.7662569852524395, val_auc: 0.7588046251310987\n",
      "In epoch 60, loss: 0.6193549633026123, train_auc: 0.7756975987980739, val_auc: 0.7651723030205844\n",
      "In epoch 80, loss: 0.6171166896820068, train_auc: 0.7732553926122063, val_auc: 0.7620257455088569\n",
      "In epoch 100, loss: 0.615440845489502, train_auc: 0.7743439446880707, val_auc: 0.7624449185530963\n",
      "In epoch 120, loss: 0.6142328977584839, train_auc: 0.7732629132943327, val_auc: 0.7609881071224258\n",
      "In epoch 140, loss: 0.6134353876113892, train_auc: 0.773493041575933, val_auc: 0.7608561602496846\n",
      "In epoch 160, loss: 0.6121478080749512, train_auc: 0.7743411354096319, val_auc: 0.7614017602100405\n",
      "In epoch 180, loss: 0.6116881370544434, train_auc: 0.7738128152727481, val_auc: 0.7604797311942204\n",
      "Test AUC 0.7610558995955709\n",
      "\n",
      "layers 5 hidden_features 16 if_activate False if_normal True if_dropout True\n",
      "In epoch 0, loss: 0.6668699979782104, train_auc: 0.7579739395046655, val_auc: 0.7457852457684716\n",
      "In epoch 20, loss: 0.6310336589813232, train_auc: 0.7677309588391631, val_auc: 0.7572304508993596\n",
      "In epoch 40, loss: 0.6268596053123474, train_auc: 0.7764638370826907, val_auc: 0.765867117331882\n",
      "In epoch 60, loss: 0.6253042817115784, train_auc: 0.7796250156925771, val_auc: 0.7685124997961299\n",
      "In epoch 80, loss: 0.6236410140991211, train_auc: 0.7807560459615043, val_auc: 0.7694388104913011\n",
      "In epoch 100, loss: 0.6222412586212158, train_auc: 0.7823145494696353, val_auc: 0.7708402661537597\n",
      "In epoch 120, loss: 0.6210886836051941, train_auc: 0.7837910044409265, val_auc: 0.7720320022538866\n",
      "In epoch 140, loss: 0.6196115612983704, train_auc: 0.7852217028364052, val_auc: 0.7731567246528406\n",
      "In epoch 160, loss: 0.6171640753746033, train_auc: 0.7857871729128076, val_auc: 0.7730616172003448\n",
      "In epoch 180, loss: 0.6147310733795166, train_auc: 0.7884982762036307, val_auc: 0.7755163925390046\n",
      "Test AUC 0.7581499471159899\n",
      "\n",
      "layers 5 hidden_features 16 if_activate False if_normal True if_dropout False\n",
      "In epoch 0, loss: 0.6562169194221497, train_auc: 0.7680618237328981, val_auc: 0.7533141530817633\n",
      "In epoch 20, loss: 0.6293020844459534, train_auc: 0.762994391975308, val_auc: 0.7539292116695523\n",
      "In epoch 40, loss: 0.624336302280426, train_auc: 0.7705729642928885, val_auc: 0.7601332529330144\n",
      "In epoch 60, loss: 0.6205394268035889, train_auc: 0.7722246302788498, val_auc: 0.7607425286913406\n",
      "In epoch 80, loss: 0.6173027753829956, train_auc: 0.7757574399032482, val_auc: 0.7634931142976153\n",
      "In epoch 100, loss: 0.614774227142334, train_auc: 0.7778218459571488, val_auc: 0.7648998471099199\n",
      "In epoch 120, loss: 0.6127579212188721, train_auc: 0.7782056152571263, val_auc: 0.764370325508607\n",
      "In epoch 140, loss: 0.6108100414276123, train_auc: 0.7796908853562946, val_auc: 0.7647723946615169\n",
      "In epoch 160, loss: 0.608302652835846, train_auc: 0.7843864099979706, val_auc: 0.7690197760446024\n",
      "In epoch 180, loss: 0.6059882044792175, train_auc: 0.7884977392202631, val_auc: 0.7736901361604782\n",
      "Test AUC 0.7749016505324655\n",
      "\n",
      "layers 5 hidden_features 16 if_activate False if_normal False if_dropout True\n",
      "In epoch 0, loss: 0.6930731534957886, train_auc: 0.6750739822877148, val_auc: 0.6664008581914362\n",
      "In epoch 20, loss: 0.6386983394622803, train_auc: 0.75610913790247, val_auc: 0.7463728588356311\n",
      "In epoch 40, loss: 0.6337496042251587, train_auc: 0.7493358838894102, val_auc: 0.7415338763866148\n",
      "In epoch 60, loss: 0.6330981850624084, train_auc: 0.75406400911929, val_auc: 0.7447879825314722\n",
      "In epoch 80, loss: 0.6318075060844421, train_auc: 0.7510068818873409, val_auc: 0.7418171943760093\n",
      "In epoch 100, loss: 0.6312228441238403, train_auc: 0.7523852721059507, val_auc: 0.7428937037779599\n",
      "In epoch 120, loss: 0.6313681602478027, train_auc: 0.7513789405915376, val_auc: 0.7418478066788738\n",
      "In epoch 140, loss: 0.6298726201057434, train_auc: 0.7552289083108963, val_auc: 0.7455466825511167\n",
      "In epoch 160, loss: 0.6299077272415161, train_auc: 0.7576717402279263, val_auc: 0.7478154691654434\n",
      "In epoch 180, loss: 0.6284937858581543, train_auc: 0.7562385435897148, val_auc: 0.7463980263736472\n",
      "Test AUC 0.7462295682241382\n",
      "\n",
      "layers 5 hidden_features 16 if_activate False if_normal False if_dropout False\n",
      "In epoch 0, loss: 0.6930609345436096, train_auc: 0.6675096008374057, val_auc: 0.6594104697573706\n",
      "In epoch 20, loss: 0.6363508105278015, train_auc: 0.7473151237898288, val_auc: 0.7389946603098413\n",
      "In epoch 40, loss: 0.6325440406799316, train_auc: 0.7499579826068785, val_auc: 0.7408758468174156\n",
      "In epoch 60, loss: 0.6319482326507568, train_auc: 0.749637850063325, val_auc: 0.7405921928520669\n",
      "In epoch 80, loss: 0.6311365962028503, train_auc: 0.7506911314876086, val_auc: 0.7411907226015085\n",
      "In epoch 100, loss: 0.6310006976127625, train_auc: 0.7524092735580181, val_auc: 0.7427423696604347\n",
      "In epoch 120, loss: 0.6299019455909729, train_auc: 0.7538164784981708, val_auc: 0.7440053292314898\n",
      "In epoch 140, loss: 0.630375862121582, train_auc: 0.7524088848120466, val_auc: 0.742743285239667\n",
      "In epoch 160, loss: 0.6292422413825989, train_auc: 0.7558889797218538, val_auc: 0.7460637740864529\n",
      "In epoch 180, loss: 0.6326874494552612, train_auc: 0.7366410612343717, val_auc: 0.7277093651125485\n",
      "Test AUC 0.7436339054270366\n",
      "\n",
      "layers 2 hidden_features 32 if_activate True if_normal True if_dropout True\n",
      "In epoch 0, loss: 0.6665069460868835, train_auc: 0.7517620282489156, val_auc: 0.7394584112613359\n",
      "In epoch 20, loss: 0.6365792155265808, train_auc: 0.7558519513303568, val_auc: 0.746346325462863\n",
      "In epoch 40, loss: 0.6277215480804443, train_auc: 0.7696740945571026, val_auc: 0.7583013298694657\n",
      "In epoch 60, loss: 0.6208043098449707, train_auc: 0.779115921750743, val_auc: 0.7645522485061613\n",
      "In epoch 80, loss: 0.6151832938194275, train_auc: 0.7862927701887275, val_auc: 0.7709732068559054\n",
      "In epoch 100, loss: 0.6118255257606506, train_auc: 0.7915580172938074, val_auc: 0.774731411650723\n",
      "In epoch 120, loss: 0.6093869209289551, train_auc: 0.7961751430281618, val_auc: 0.7776124294779293\n",
      "In epoch 140, loss: 0.6063702702522278, train_auc: 0.8019592365887156, val_auc: 0.783286521859824\n",
      "In epoch 160, loss: 0.6040414571762085, train_auc: 0.8026580957045457, val_auc: 0.7825718405831914\n",
      "In epoch 180, loss: 0.6028726696968079, train_auc: 0.8049039724297788, val_auc: 0.784289481470662\n",
      "Test AUC 0.7651430026202748\n",
      "\n",
      "layers 2 hidden_features 32 if_activate True if_normal True if_dropout False\n",
      "In epoch 0, loss: 0.6520566940307617, train_auc: 0.75386152331886, val_auc: 0.7416831010316689\n",
      "In epoch 20, loss: 0.6381388902664185, train_auc: 0.7452447725521071, val_auc: 0.7362161393174637\n",
      "In epoch 40, loss: 0.6266584396362305, train_auc: 0.7664489028809807, val_auc: 0.7557843013343951\n",
      "In epoch 60, loss: 0.6172946095466614, train_auc: 0.7749611651545046, val_auc: 0.7605765899885133\n",
      "In epoch 80, loss: 0.609318196773529, train_auc: 0.7844497097566022, val_auc: 0.7680815946714832\n",
      "In epoch 100, loss: 0.603101372718811, train_auc: 0.7910288845709995, val_auc: 0.773313024411423\n",
      "In epoch 120, loss: 0.5988494157791138, train_auc: 0.7928068320255497, val_auc: 0.7728460177604339\n",
      "In epoch 140, loss: 0.5961442589759827, train_auc: 0.7917635844903106, val_auc: 0.7700875767767584\n",
      "In epoch 160, loss: 0.5948280692100525, train_auc: 0.7926038416188925, val_auc: 0.7696177050057813\n",
      "In epoch 180, loss: 0.5906218886375427, train_auc: 0.8032945761114973, val_auc: 0.7812840808545761\n",
      "Test AUC 0.7747552727316206\n",
      "\n",
      "layers 2 hidden_features 32 if_activate True if_normal False if_dropout True\n",
      "In epoch 0, loss: 0.6896750330924988, train_auc: 0.6972153755862126, val_auc: 0.6877355650664795\n",
      "In epoch 20, loss: 0.648497998714447, train_auc: 0.7137278544472758, val_auc: 0.7071112775355104\n",
      "In epoch 40, loss: 0.6349839568138123, train_auc: 0.7538905208403001, val_auc: 0.7462604956909472\n",
      "In epoch 60, loss: 0.6311178207397461, train_auc: 0.7618474185317089, val_auc: 0.752370024024195\n",
      "In epoch 80, loss: 0.6279348134994507, train_auc: 0.7654784313592651, val_auc: 0.7545435114768336\n",
      "In epoch 100, loss: 0.6262266039848328, train_auc: 0.7687082229110787, val_auc: 0.7568255248319132\n",
      "In epoch 120, loss: 0.6247798800468445, train_auc: 0.7715431729780514, val_auc: 0.7591224980683586\n",
      "In epoch 140, loss: 0.6239510178565979, train_auc: 0.7752583787746784, val_auc: 0.7622165519523293\n",
      "In epoch 160, loss: 0.6215863823890686, train_auc: 0.7781627872245086, val_auc: 0.7643034826300217\n",
      "In epoch 180, loss: 0.6207093000411987, train_auc: 0.7814870895658422, val_auc: 0.7670724870139816\n",
      "Test AUC 0.7539032975100161\n",
      "\n",
      "layers 2 hidden_features 32 if_activate True if_normal False if_dropout False\n",
      "In epoch 0, loss: 0.6915050148963928, train_auc: 0.7021950482504739, val_auc: 0.6924400729160259\n",
      "In epoch 20, loss: 0.648899257183075, train_auc: 0.7153974656338692, val_auc: 0.7086980961447085\n",
      "In epoch 40, loss: 0.6379101276397705, train_auc: 0.7453046620021254, val_auc: 0.7385581155035684\n",
      "In epoch 60, loss: 0.6323277354240417, train_auc: 0.75422275588185, val_auc: 0.7463148794114993\n",
      "In epoch 80, loss: 0.6277278065681458, train_auc: 0.7596423567453003, val_auc: 0.7501697174252799\n",
      "In epoch 100, loss: 0.6241185665130615, train_auc: 0.7645576857943879, val_auc: 0.7542113377797734\n",
      "In epoch 120, loss: 0.6218535900115967, train_auc: 0.766959148969523, val_auc: 0.7556778898276963\n",
      "In epoch 140, loss: 0.6201462745666504, train_auc: 0.7682824992566069, val_auc: 0.7563692209992942\n",
      "In epoch 160, loss: 0.6190313100814819, train_auc: 0.7715205140706518, val_auc: 0.7590616574777748\n",
      "In epoch 180, loss: 0.6173082590103149, train_auc: 0.7721557318227343, val_auc: 0.7588871854780369\n",
      "Test AUC 0.7594946614078053\n",
      "\n",
      "layers 2 hidden_features 32 if_activate False if_normal True if_dropout True\n",
      "In epoch 0, loss: 0.6773187518119812, train_auc: 0.7566367220506186, val_auc: 0.7434963102196473\n",
      "In epoch 20, loss: 0.6387098431587219, train_auc: 0.7491112035375407, val_auc: 0.7397073490043935\n",
      "In epoch 40, loss: 0.6320415735244751, train_auc: 0.7633727184412333, val_auc: 0.7529528225052053\n",
      "In epoch 60, loss: 0.626419723033905, train_auc: 0.7695869732313211, val_auc: 0.7573009623608553\n",
      "In epoch 80, loss: 0.620830237865448, train_auc: 0.7756532705810953, val_auc: 0.7595740965219331\n",
      "In epoch 100, loss: 0.6180856227874756, train_auc: 0.7806615705048987, val_auc: 0.763378399321252\n",
      "In epoch 120, loss: 0.6156476736068726, train_auc: 0.7847291843180254, val_auc: 0.766369354612396\n",
      "In epoch 140, loss: 0.6136216521263123, train_auc: 0.7879475164973123, val_auc: 0.7686671911369669\n",
      "In epoch 160, loss: 0.6118163466453552, train_auc: 0.7907610253807356, val_auc: 0.7701201615210487\n",
      "In epoch 180, loss: 0.6100905537605286, train_auc: 0.7924414873081225, val_auc: 0.7704229077078912\n",
      "Test AUC 0.7554600144938326\n",
      "\n",
      "layers 2 hidden_features 32 if_activate False if_normal True if_dropout False\n",
      "In epoch 0, loss: 0.6620110869407654, train_auc: 0.7573556404991388, val_auc: 0.7443046820910326\n",
      "In epoch 20, loss: 0.6378524899482727, train_auc: 0.7535286151896697, val_auc: 0.7433646054077345\n",
      "In epoch 40, loss: 0.632493793964386, train_auc: 0.7564952903227027, val_auc: 0.7468116927391747\n",
      "In epoch 60, loss: 0.6268824934959412, train_auc: 0.7640269547546102, val_auc: 0.7519181893282032\n",
      "In epoch 80, loss: 0.6207183599472046, train_auc: 0.7669942928515271, val_auc: 0.751852310217231\n",
      "In epoch 100, loss: 0.6173108220100403, train_auc: 0.769652523424422, val_auc: 0.7524367459842585\n",
      "In epoch 120, loss: 0.6146495938301086, train_auc: 0.773604269945756, val_auc: 0.7555192624808147\n",
      "In epoch 140, loss: 0.6121602654457092, train_auc: 0.77668980216915, val_auc: 0.7575741792152828\n",
      "In epoch 160, loss: 0.6096333861351013, train_auc: 0.7798002745019628, val_auc: 0.7594683874765047\n",
      "In epoch 180, loss: 0.6070128083229065, train_auc: 0.7828210866849843, val_auc: 0.7611507580499017\n",
      "Test AUC 0.7626861601791133\n",
      "\n",
      "layers 2 hidden_features 32 if_activate False if_normal False if_dropout True\n",
      "In epoch 0, loss: 0.6898759007453918, train_auc: 0.7018774923149445, val_auc: 0.6920805106889286\n",
      "In epoch 20, loss: 0.6474859714508057, train_auc: 0.7196853168763722, val_auc: 0.7119646737557765\n",
      "In epoch 40, loss: 0.6379595994949341, train_auc: 0.7483458936536473, val_auc: 0.7408385561719155\n",
      "In epoch 60, loss: 0.6355405449867249, train_auc: 0.7514185323483545, val_auc: 0.743118808189466\n",
      "In epoch 80, loss: 0.6341866254806519, train_auc: 0.7526452602733564, val_auc: 0.7434696464547905\n",
      "In epoch 100, loss: 0.6333921551704407, train_auc: 0.7533508361965288, val_auc: 0.7433444069421464\n",
      "In epoch 120, loss: 0.6327522397041321, train_auc: 0.7546586405725741, val_auc: 0.7441989538000899\n",
      "In epoch 140, loss: 0.6311794519424438, train_auc: 0.7572562453663819, val_auc: 0.7460600776050059\n",
      "In epoch 160, loss: 0.6296564340591431, train_auc: 0.7619395666466264, val_auc: 0.749367927519769\n",
      "In epoch 180, loss: 0.6283827424049377, train_auc: 0.76429867566978, val_auc: 0.7507504043451588\n",
      "Test AUC 0.7482448995466143\n",
      "\n",
      "layers 2 hidden_features 32 if_activate False if_normal False if_dropout False\n",
      "In epoch 0, loss: 0.6910915970802307, train_auc: 0.703141340930595, val_auc: 0.6924003462210725\n",
      "In epoch 20, loss: 0.647550106048584, train_auc: 0.7184095644091113, val_auc: 0.7107135865037597\n",
      "In epoch 40, loss: 0.6376587152481079, train_auc: 0.7478230092819015, val_auc: 0.740580467708996\n",
      "In epoch 60, loss: 0.6351105570793152, train_auc: 0.7521448213266462, val_auc: 0.7438466503394517\n",
      "In epoch 80, loss: 0.6336604952812195, train_auc: 0.7526524210026602, val_auc: 0.7433993275230321\n",
      "In epoch 100, loss: 0.6329455375671387, train_auc: 0.7522009704447652, val_auc: 0.7419442094738308\n",
      "In epoch 120, loss: 0.6322910785675049, train_auc: 0.7533394934476763, val_auc: 0.7425851226197379\n",
      "In epoch 140, loss: 0.6310267448425293, train_auc: 0.7560487073909092, val_auc: 0.744515790314191\n",
      "In epoch 160, loss: 0.6292378306388855, train_auc: 0.7599766851539003, val_auc: 0.747399871236559\n",
      "In epoch 180, loss: 0.6280432343482971, train_auc: 0.7617979136541313, val_auc: 0.7485194227835658\n",
      "Test AUC 0.748850430635113\n",
      "\n",
      "layers 5 hidden_features 32 if_activate True if_normal True if_dropout True\n",
      "In epoch 0, loss: 0.6556394696235657, train_auc: 0.7500677123926074, val_auc: 0.7382808310574871\n",
      "In epoch 20, loss: 0.6301762461662292, train_auc: 0.7756510689460249, val_auc: 0.7651125007180348\n",
      "In epoch 40, loss: 0.6250914931297302, train_auc: 0.7796443190699097, val_auc: 0.7687394516278143\n",
      "In epoch 60, loss: 0.6222296357154846, train_auc: 0.7830819278634102, val_auc: 0.7715069444929551\n",
      "In epoch 80, loss: 0.6187621355056763, train_auc: 0.7867417543332329, val_auc: 0.7747430041638546\n",
      "In epoch 100, loss: 0.6145596504211426, train_auc: 0.7910937289042064, val_auc: 0.7779378192058103\n",
      "In epoch 120, loss: 0.6089138388633728, train_auc: 0.7963525067899234, val_auc: 0.7806686223629037\n",
      "In epoch 140, loss: 0.606556236743927, train_auc: 0.8014311716437009, val_auc: 0.786111462883389\n",
      "In epoch 160, loss: 0.5964332222938538, train_auc: 0.8158367404996814, val_auc: 0.7988397720441284\n",
      "In epoch 180, loss: 0.5884279608726501, train_auc: 0.8263705647440326, val_auc: 0.8087329322262722\n",
      "Test AUC 0.8073536071149238\n",
      "\n",
      "layers 5 hidden_features 32 if_activate True if_normal True if_dropout False\n",
      "In epoch 0, loss: 0.654325544834137, train_auc: 0.7527326587938028, val_auc: 0.7421310479099963\n",
      "In epoch 20, loss: 0.6252033114433289, train_auc: 0.7679100493238687, val_auc: 0.7585297047502796\n",
      "In epoch 40, loss: 0.6182446479797363, train_auc: 0.778146863059562, val_auc: 0.7668828391803051\n",
      "In epoch 60, loss: 0.6116690635681152, train_auc: 0.779385147465202, val_auc: 0.7656619281486864\n",
      "In epoch 80, loss: 0.6106621026992798, train_auc: 0.7858280566631085, val_auc: 0.7710693253692547\n",
      "In epoch 100, loss: 0.604455292224884, train_auc: 0.7902428339693979, val_auc: 0.775376867782324\n",
      "In epoch 120, loss: 0.6049730181694031, train_auc: 0.7884431694746569, val_auc: 0.7712158032020168\n",
      "In epoch 140, loss: 0.5993358492851257, train_auc: 0.7974220524516034, val_auc: 0.7815521772832872\n",
      "In epoch 160, loss: 0.5959421396255493, train_auc: 0.8027083586470828, val_auc: 0.7866211146101613\n",
      "In epoch 180, loss: 0.6015559434890747, train_auc: 0.8078780050678331, val_auc: 0.7888494945959597\n",
      "Test AUC 0.8069253824130043\n",
      "\n",
      "layers 5 hidden_features 32 if_activate True if_normal False if_dropout True\n",
      "In epoch 0, loss: 0.6930837035179138, train_auc: 0.670549089987096, val_auc: 0.6623166242402563\n",
      "In epoch 20, loss: 0.6304821968078613, train_auc: 0.763574256916297, val_auc: 0.7547835206439883\n",
      "In epoch 40, loss: 0.62140291929245, train_auc: 0.7760703736351088, val_auc: 0.7663378834971066\n",
      "In epoch 60, loss: 0.6180063486099243, train_auc: 0.7753138778720776, val_auc: 0.76336997351576\n",
      "In epoch 80, loss: 0.6156702637672424, train_auc: 0.7760429132253818, val_auc: 0.7635361519669703\n",
      "In epoch 100, loss: 0.6137298941612244, train_auc: 0.7787648458754278, val_auc: 0.7658719902513336\n",
      "In epoch 120, loss: 0.6119543313980103, train_auc: 0.7815335702105581, val_auc: 0.7681764966147087\n",
      "In epoch 140, loss: 0.6120126843452454, train_auc: 0.7848775982248546, val_auc: 0.7715621469684081\n",
      "In epoch 160, loss: 0.6095868349075317, train_auc: 0.7807633551554817, val_auc: 0.7667936703116666\n",
      "In epoch 180, loss: 0.6090633869171143, train_auc: 0.7832008198729237, val_auc: 0.7688252473098076\n",
      "Test AUC 0.7639832143721874\n",
      "\n",
      "layers 5 hidden_features 32 if_activate True if_normal False if_dropout False\n",
      "In epoch 0, loss: 0.6931285858154297, train_auc: 0.6756537067350609, val_auc: 0.6673205902775087\n",
      "In epoch 20, loss: 0.6379732489585876, train_auc: 0.7586061523576284, val_auc: 0.7474101131323222\n",
      "In epoch 40, loss: 0.6272603273391724, train_auc: 0.7643418419962549, val_auc: 0.7556645262050885\n",
      "In epoch 60, loss: 0.6209579110145569, train_auc: 0.7756752388585257, val_auc: 0.7660076468834346\n",
      "In epoch 80, loss: 0.616034209728241, train_auc: 0.7774323884414803, val_auc: 0.7661179732111932\n",
      "In epoch 100, loss: 0.6139862537384033, train_auc: 0.7763207601860009, val_auc: 0.7644167030206349\n",
      "In epoch 120, loss: 0.6137076616287231, train_auc: 0.7762546182379793, val_auc: 0.7636476524948834\n",
      "In epoch 140, loss: 0.6127185225486755, train_auc: 0.7824721534446599, val_auc: 0.7697125556276354\n",
      "In epoch 160, loss: 0.6106671094894409, train_auc: 0.7769362548747324, val_auc: 0.7629108969863782\n",
      "In epoch 180, loss: 0.608452320098877, train_auc: 0.7861180140554582, val_auc: 0.7722591772738603\n",
      "Test AUC 0.7659930243953285\n",
      "\n",
      "layers 5 hidden_features 32 if_activate False if_normal True if_dropout True\n",
      "In epoch 0, loss: 0.6641758680343628, train_auc: 0.7531690109326266, val_auc: 0.7411690010548737\n",
      "In epoch 20, loss: 0.6288223266601562, train_auc: 0.7714028742845518, val_auc: 0.760462025619488\n",
      "In epoch 40, loss: 0.6246241331100464, train_auc: 0.7801317880341037, val_auc: 0.7691898876672467\n",
      "In epoch 60, loss: 0.6222082376480103, train_auc: 0.781507529201435, val_auc: 0.7700497555369061\n",
      "In epoch 80, loss: 0.6201918721199036, train_auc: 0.7836830607476939, val_auc: 0.7716221937188266\n",
      "In epoch 100, loss: 0.6176405549049377, train_auc: 0.7865145537195171, val_auc: 0.773691991413133\n",
      "In epoch 120, loss: 0.6158338189125061, train_auc: 0.7876670249388881, val_auc: 0.773944288617353\n",
      "In epoch 140, loss: 0.6133636832237244, train_auc: 0.7913277575770308, val_auc: 0.7777451244640907\n",
      "In epoch 160, loss: 0.6127170324325562, train_auc: 0.7920600705857969, val_auc: 0.7778266835221228\n",
      "In epoch 180, loss: 0.6091471314430237, train_auc: 0.7928686921990026, val_auc: 0.7778469095878671\n",
      "Test AUC 0.7737660973846883\n",
      "\n",
      "layers 5 hidden_features 32 if_activate False if_normal True if_dropout False\n",
      "In epoch 0, loss: 0.652997612953186, train_auc: 0.7197988791404684, val_auc: 0.7065934778696825\n",
      "In epoch 20, loss: 0.6232590675354004, train_auc: 0.7664868273018887, val_auc: 0.7567248358819043\n",
      "In epoch 40, loss: 0.6172641515731812, train_auc: 0.7749263580336913, val_auc: 0.7626698692988685\n",
      "In epoch 60, loss: 0.6148961186408997, train_auc: 0.7802079691323536, val_auc: 0.7669666298974454\n",
      "In epoch 80, loss: 0.6134169101715088, train_auc: 0.7814582914658621, val_auc: 0.7679478364825517\n",
      "In epoch 100, loss: 0.6120756268501282, train_auc: 0.7818501652796428, val_auc: 0.7679220239960229\n",
      "In epoch 120, loss: 0.6105351448059082, train_auc: 0.784128481179414, val_auc: 0.7699387814260242\n",
      "In epoch 140, loss: 0.6087118983268738, train_auc: 0.7867483509492255, val_auc: 0.7724251446211741\n",
      "In epoch 160, loss: 0.6065317392349243, train_auc: 0.7892098975236963, val_auc: 0.7747767780273026\n",
      "In epoch 180, loss: 0.6039381623268127, train_auc: 0.7895437397157348, val_auc: 0.7747089734697648\n",
      "Test AUC 0.7794443963287525\n",
      "\n",
      "layers 5 hidden_features 32 if_activate False if_normal False if_dropout True\n",
      "In epoch 0, loss: 0.6930457353591919, train_auc: 0.6718137808757776, val_auc: 0.6631810250998773\n",
      "In epoch 20, loss: 0.6364524364471436, train_auc: 0.745175625956719, val_auc: 0.7365311899522752\n",
      "In epoch 40, loss: 0.632901668548584, train_auc: 0.751664759535189, val_auc: 0.7426868106208029\n",
      "In epoch 60, loss: 0.6319600343704224, train_auc: 0.7509910122095584, val_auc: 0.7419412075465824\n",
      "In epoch 80, loss: 0.6304125785827637, train_auc: 0.754403052986442, val_auc: 0.7445964367767913\n",
      "In epoch 100, loss: 0.6298454403877258, train_auc: 0.7541803638794191, val_auc: 0.7445307725740617\n",
      "In epoch 120, loss: 0.63100266456604, train_auc: 0.7573156146422453, val_auc: 0.7472735339836524\n",
      "In epoch 140, loss: 0.6286016702651978, train_auc: 0.7548396685026225, val_auc: 0.7452858038616053\n",
      "In epoch 160, loss: 0.627385139465332, train_auc: 0.7547900787631131, val_auc: 0.7450311640008928\n",
      "In epoch 180, loss: 0.6269977688789368, train_auc: 0.7549008677996487, val_auc: 0.7451602858111697\n",
      "Test AUC 0.7444280988744488\n",
      "\n",
      "layers 5 hidden_features 32 if_activate False if_normal False if_dropout False\n",
      "In epoch 0, loss: 0.693090558052063, train_auc: 0.6695370922994153, val_auc: 0.6611375018590365\n",
      "In epoch 20, loss: 0.6344907879829407, train_auc: 0.7446653675940247, val_auc: 0.7371155810368877\n",
      "In epoch 40, loss: 0.6328091025352478, train_auc: 0.752869574744539, val_auc: 0.743860834731026\n",
      "In epoch 60, loss: 0.6314629316329956, train_auc: 0.7506182737765557, val_auc: 0.7413333829597069\n",
      "In epoch 80, loss: 0.6312525868415833, train_auc: 0.7504104627482866, val_auc: 0.7410587324636576\n",
      "In epoch 100, loss: 0.6303461194038391, train_auc: 0.7533133955539018, val_auc: 0.7437087971079004\n",
      "In epoch 120, loss: 0.6317110657691956, train_auc: 0.7428035124200173, val_auc: 0.7340052312002111\n",
      "In epoch 140, loss: 0.6306209564208984, train_auc: 0.7554017468523888, val_auc: 0.7457159384197319\n",
      "In epoch 160, loss: 0.6292775869369507, train_auc: 0.7558368763849751, val_auc: 0.745899571582634\n",
      "In epoch 180, loss: 0.6286140084266663, train_auc: 0.7567788275922973, val_auc: 0.7467569480533377\n",
      "Test AUC 0.7462561357614238\n",
      "\n",
      "layers 2 hidden_features 64 if_activate True if_normal True if_dropout True\n",
      "In epoch 0, loss: 0.6633550524711609, train_auc: 0.7529012255026615, val_auc: 0.7408321306317907\n",
      "In epoch 20, loss: 0.637021541595459, train_auc: 0.7538075226050835, val_auc: 0.7444304783062846\n",
      "In epoch 40, loss: 0.6253046989440918, train_auc: 0.7714717608406488, val_auc: 0.7594281348866849\n",
      "In epoch 60, loss: 0.618277907371521, train_auc: 0.7789673185100789, val_auc: 0.7618444721593012\n",
      "In epoch 80, loss: 0.6126065850257874, train_auc: 0.7900125763086081, val_auc: 0.7740361314189526\n",
      "In epoch 100, loss: 0.6087074279785156, train_auc: 0.7931726992143826, val_auc: 0.7741905077450348\n",
      "In epoch 120, loss: 0.6033453941345215, train_auc: 0.8024099894022723, val_auc: 0.7818804354133371\n",
      "In epoch 140, loss: 0.59844970703125, train_auc: 0.8050422377236952, val_auc: 0.7822474517712414\n",
      "In epoch 160, loss: 0.6011795401573181, train_auc: 0.8032353738997677, val_auc: 0.7775529129488878\n",
      "In epoch 180, loss: 0.5940069556236267, train_auc: 0.8137168873110174, val_auc: 0.7893483438454199\n",
      "Test AUC 0.7648136912085921\n",
      "\n",
      "layers 2 hidden_features 64 if_activate True if_normal True if_dropout False\n",
      "In epoch 0, loss: 0.6558873653411865, train_auc: 0.7536856692463212, val_auc: 0.7414424891367811\n",
      "In epoch 20, loss: 0.6388071179389954, train_auc: 0.748138651612918, val_auc: 0.7387421517033447\n",
      "In epoch 40, loss: 0.6250530481338501, train_auc: 0.7636978666279999, val_auc: 0.7525150070474217\n",
      "In epoch 60, loss: 0.616823673248291, train_auc: 0.7753187578282762, val_auc: 0.7582726186951915\n",
      "In epoch 80, loss: 0.6084975600242615, train_auc: 0.7842091831120593, val_auc: 0.7675871778579024\n",
      "In epoch 100, loss: 0.602564811706543, train_auc: 0.7907238922003124, val_auc: 0.7718465535974732\n",
      "In epoch 120, loss: 0.5984493494033813, train_auc: 0.795729276906377, val_auc: 0.7743511834710692\n",
      "In epoch 140, loss: 0.5941557884216309, train_auc: 0.7987773551267228, val_auc: 0.7750546749730644\n",
      "In epoch 160, loss: 0.5903962254524231, train_auc: 0.806427257012363, val_auc: 0.7829128587875709\n",
      "In epoch 180, loss: 0.5884683728218079, train_auc: 0.810172365848387, val_auc: 0.7861410571134684\n",
      "Test AUC 0.7798176898572938\n",
      "\n",
      "layers 2 hidden_features 64 if_activate True if_normal False if_dropout True\n",
      "In epoch 0, loss: 0.6893208026885986, train_auc: 0.7009434914083785, val_auc: 0.6913594117792431\n",
      "In epoch 20, loss: 0.6426196694374084, train_auc: 0.7313889567529819, val_auc: 0.7247539189887209\n",
      "In epoch 40, loss: 0.6328364014625549, train_auc: 0.7583817187580557, val_auc: 0.7501706668706496\n",
      "In epoch 60, loss: 0.6276114583015442, train_auc: 0.7653655982317781, val_auc: 0.7545014553287055\n",
      "In epoch 80, loss: 0.6243482232093811, train_auc: 0.7706541225277106, val_auc: 0.7584310158418525\n",
      "In epoch 100, loss: 0.6229838132858276, train_auc: 0.7736792776474318, val_auc: 0.7605297923573524\n",
      "In epoch 120, loss: 0.6208704710006714, train_auc: 0.7759361092287104, val_auc: 0.7612450111656737\n",
      "In epoch 140, loss: 0.6175431609153748, train_auc: 0.7810374979994187, val_auc: 0.7654855072049528\n",
      "In epoch 160, loss: 0.6153790354728699, train_auc: 0.785188347130857, val_auc: 0.7685752600894631\n",
      "In epoch 180, loss: 0.6132254600524902, train_auc: 0.7881026087689466, val_auc: 0.770655658705347\n",
      "Test AUC 0.7569536486354648\n",
      "\n",
      "layers 2 hidden_features 64 if_activate True if_normal False if_dropout False\n",
      "In epoch 0, loss: 0.6914154291152954, train_auc: 0.705499853755844, val_auc: 0.6955298894300852\n",
      "In epoch 20, loss: 0.6484426856040955, train_auc: 0.7234936707204548, val_auc: 0.7156588174693636\n",
      "In epoch 40, loss: 0.6345560550689697, train_auc: 0.754116417410161, val_auc: 0.7468282997530994\n",
      "In epoch 60, loss: 0.6267729997634888, train_auc: 0.7620434515257096, val_auc: 0.7525214960679055\n",
      "In epoch 80, loss: 0.6219654083251953, train_auc: 0.7677164500339416, val_auc: 0.756132752335407\n",
      "In epoch 100, loss: 0.6189299821853638, train_auc: 0.7717265332883554, val_auc: 0.7591560753739383\n",
      "In epoch 120, loss: 0.6161848306655884, train_auc: 0.7738771428129906, val_auc: 0.7603288086174012\n",
      "In epoch 140, loss: 0.6138924360275269, train_auc: 0.7788117456024204, val_auc: 0.764575010429491\n",
      "In epoch 160, loss: 0.6120565533638, train_auc: 0.7831281217316742, val_auc: 0.7677402389992491\n",
      "In epoch 180, loss: 0.6095080971717834, train_auc: 0.786821002159414, val_auc: 0.7700758434282359\n",
      "Test AUC 0.7700398952692473\n",
      "\n",
      "layers 2 hidden_features 64 if_activate False if_normal True if_dropout True\n",
      "In epoch 0, loss: 0.6716740131378174, train_auc: 0.7548238045440754, val_auc: 0.7425731829413997\n",
      "In epoch 20, loss: 0.6375982761383057, train_auc: 0.7514940066134964, val_auc: 0.7424697053312942\n",
      "In epoch 40, loss: 0.631700336933136, train_auc: 0.7640727506272901, val_auc: 0.753601105041981\n",
      "In epoch 60, loss: 0.6266299486160278, train_auc: 0.7670358999411123, val_auc: 0.7553868539395163\n",
      "In epoch 80, loss: 0.6210220456123352, train_auc: 0.7753416524131467, val_auc: 0.7604533637953641\n",
      "In epoch 100, loss: 0.616442859172821, train_auc: 0.7807210385252719, val_auc: 0.7630151218147636\n",
      "In epoch 120, loss: 0.6137979626655579, train_auc: 0.7847449571592641, val_auc: 0.7659051855558338\n",
      "In epoch 140, loss: 0.6111721396446228, train_auc: 0.7880071741172603, val_auc: 0.7681557095198452\n",
      "In epoch 160, loss: 0.6095677614212036, train_auc: 0.7920254923509358, val_auc: 0.7707885513683023\n",
      "In epoch 180, loss: 0.6074576377868652, train_auc: 0.7944779060891891, val_auc: 0.7712258882990553\n",
      "Test AUC 0.7589258453896595\n",
      "\n",
      "layers 2 hidden_features 64 if_activate False if_normal True if_dropout False\n",
      "In epoch 0, loss: 0.662014365196228, train_auc: 0.7567665474238819, val_auc: 0.7441154959259132\n",
      "In epoch 20, loss: 0.6413980722427368, train_auc: 0.7553442042479667, val_auc: 0.745107795386731\n",
      "In epoch 40, loss: 0.6344501972198486, train_auc: 0.7508834759992897, val_auc: 0.7423713208451294\n",
      "In epoch 60, loss: 0.629182755947113, train_auc: 0.7612764043242434, val_auc: 0.7500966147566963\n",
      "In epoch 80, loss: 0.624452531337738, train_auc: 0.763220727990346, val_auc: 0.7497247983586713\n",
      "In epoch 100, loss: 0.6190980672836304, train_auc: 0.7690220778768453, val_auc: 0.75208181707742\n",
      "In epoch 120, loss: 0.615516722202301, train_auc: 0.7735128028172467, val_auc: 0.7550809403736789\n",
      "In epoch 140, loss: 0.6120145320892334, train_auc: 0.7777724720427098, val_auc: 0.7576845635033695\n",
      "In epoch 160, loss: 0.6089270114898682, train_auc: 0.7804411688331269, val_auc: 0.7584655275992034\n",
      "In epoch 180, loss: 0.6066358089447021, train_auc: 0.7823773745142798, val_auc: 0.758774925796641\n",
      "Test AUC 0.7605095901620134\n",
      "\n",
      "layers 2 hidden_features 64 if_activate False if_normal False if_dropout True\n",
      "In epoch 0, loss: 0.6888070702552795, train_auc: 0.7052844891286694, val_auc: 0.6950428253726841\n",
      "In epoch 20, loss: 0.6436949968338013, train_auc: 0.7288857642069859, val_auc: 0.7213400887264545\n",
      "In epoch 40, loss: 0.6360422968864441, train_auc: 0.7502743096598137, val_auc: 0.7423270185664599\n",
      "In epoch 60, loss: 0.633702278137207, train_auc: 0.7528781170601282, val_auc: 0.7437265849609359\n",
      "In epoch 80, loss: 0.6327467560768127, train_auc: 0.7541182805322557, val_auc: 0.7436855010096577\n",
      "In epoch 100, loss: 0.6316318511962891, train_auc: 0.7554241658677763, val_auc: 0.7442863311948127\n",
      "In epoch 120, loss: 0.6298948526382446, train_auc: 0.7603253732165535, val_auc: 0.7474875643173916\n",
      "In epoch 140, loss: 0.6281647682189941, train_auc: 0.7632496550813946, val_auc: 0.7493923640266237\n",
      "In epoch 160, loss: 0.6261754035949707, train_auc: 0.7667511540061343, val_auc: 0.7517005347955883\n",
      "In epoch 180, loss: 0.6245261430740356, train_auc: 0.7694593536155927, val_auc: 0.7528770648507953\n",
      "Test AUC 0.7503768822574869\n",
      "\n",
      "layers 2 hidden_features 64 if_activate False if_normal False if_dropout False\n",
      "In epoch 0, loss: 0.6901834011077881, train_auc: 0.7051771926775429, val_auc: 0.6947442468094124\n",
      "In epoch 20, loss: 0.6404107213020325, train_auc: 0.7401356295174167, val_auc: 0.7322345076784657\n",
      "In epoch 40, loss: 0.6351094841957092, train_auc: 0.7522654910671739, val_auc: 0.7435101900397694\n",
      "In epoch 60, loss: 0.6332136988639832, train_auc: 0.7522794092725107, val_auc: 0.7422477478597486\n",
      "In epoch 80, loss: 0.6319860816001892, train_auc: 0.7544279665358589, val_auc: 0.743205906524232\n",
      "In epoch 100, loss: 0.6297462582588196, train_auc: 0.7594024503551147, val_auc: 0.746346253254887\n",
      "In epoch 120, loss: 0.6271179914474487, train_auc: 0.763964495983435, val_auc: 0.7489548365801986\n",
      "In epoch 140, loss: 0.6241922378540039, train_auc: 0.7687044941866505, val_auc: 0.7505435763094511\n",
      "In epoch 160, loss: 0.6227240562438965, train_auc: 0.7711112732246252, val_auc: 0.7517548567514668\n",
      "In epoch 180, loss: 0.6216222643852234, train_auc: 0.7728019732866289, val_auc: 0.7518927586935639\n",
      "Test AUC 0.7525836783244558\n",
      "\n",
      "layers 5 hidden_features 64 if_activate True if_normal True if_dropout True\n",
      "In epoch 0, loss: 0.6547448635101318, train_auc: 0.7493454470237587, val_auc: 0.7376782867534482\n",
      "In epoch 20, loss: 0.6272915005683899, train_auc: 0.7805757333122951, val_auc: 0.7698066601501345\n",
      "In epoch 40, loss: 0.6209828853607178, train_auc: 0.7843290150505126, val_auc: 0.7728811392574497\n",
      "In epoch 60, loss: 0.6150306463241577, train_auc: 0.7886411847133149, val_auc: 0.7746373053379434\n",
      "In epoch 80, loss: 0.6106526851654053, train_auc: 0.7920692923516314, val_auc: 0.7767555700998796\n",
      "In epoch 100, loss: 0.6074870824813843, train_auc: 0.7986681561004537, val_auc: 0.7835694922364418\n",
      "In epoch 120, loss: 0.6039605736732483, train_auc: 0.8020000200222132, val_auc: 0.7867508481741685\n",
      "In epoch 140, loss: 0.5984945297241211, train_auc: 0.8075482426064693, val_auc: 0.7922301740869507\n",
      "In epoch 160, loss: 0.5902599096298218, train_auc: 0.8239060055977865, val_auc: 0.8064603369395935\n",
      "In epoch 180, loss: 0.5715242624282837, train_auc: 0.8419440431465658, val_auc: 0.8253353960786904\n",
      "Test AUC 0.8239123110690375\n",
      "\n",
      "layers 5 hidden_features 64 if_activate True if_normal True if_dropout False\n",
      "In epoch 0, loss: 0.6526815295219421, train_auc: 0.7410414369055346, val_auc: 0.731239791562899\n",
      "In epoch 20, loss: 0.6271363496780396, train_auc: 0.7719156068894719, val_auc: 0.7609980472067523\n",
      "In epoch 40, loss: 0.6201691031455994, train_auc: 0.7767537769397053, val_auc: 0.7661726344252068\n",
      "In epoch 60, loss: 0.6139264702796936, train_auc: 0.779876386116228, val_auc: 0.7668784923795047\n",
      "In epoch 80, loss: 0.6097856760025024, train_auc: 0.7809882802957374, val_auc: 0.7662530444961999\n",
      "In epoch 100, loss: 0.6078575849533081, train_auc: 0.7908546852175533, val_auc: 0.7766724442481214\n",
      "In epoch 120, loss: 0.6024662256240845, train_auc: 0.788596300049854, val_auc: 0.7730623940328465\n",
      "In epoch 140, loss: 0.6065025925636292, train_auc: 0.7972991226924881, val_auc: 0.7816214972385848\n",
      "In epoch 160, loss: 0.5890548825263977, train_auc: 0.8043439479019384, val_auc: 0.7871972933802189\n",
      "In epoch 180, loss: 0.5833576321601868, train_auc: 0.8373676959376797, val_auc: 0.8197619599741878\n",
      "Test AUC 0.8245160996179511\n",
      "\n",
      "layers 5 hidden_features 64 if_activate True if_normal False if_dropout True\n",
      "In epoch 0, loss: 0.6930867433547974, train_auc: 0.6684206023422026, val_auc: 0.6602400507076274\n",
      "In epoch 20, loss: 0.6433575749397278, train_auc: 0.7669662368686174, val_auc: 0.7554598698540955\n",
      "In epoch 40, loss: 0.623016893863678, train_auc: 0.7710643607153113, val_auc: 0.7628210675788687\n",
      "In epoch 60, loss: 0.6179839968681335, train_auc: 0.7793271034690727, val_auc: 0.768801174080683\n",
      "In epoch 80, loss: 0.615520715713501, train_auc: 0.7795723002949878, val_auc: 0.7682343010389316\n",
      "In epoch 100, loss: 0.618876576423645, train_auc: 0.7829832229596814, val_auc: 0.7712035212817429\n",
      "In epoch 120, loss: 0.6119628548622131, train_auc: 0.7855873449622105, val_auc: 0.772924662092792\n",
      "In epoch 140, loss: 0.6100002527236938, train_auc: 0.7811470662048122, val_auc: 0.7678591609107572\n",
      "In epoch 160, loss: 0.6063685417175293, train_auc: 0.785145491768991, val_auc: 0.7708343425635007\n",
      "In epoch 180, loss: 0.6051317453384399, train_auc: 0.792690054053686, val_auc: 0.778850370701001\n",
      "Test AUC 0.7681073836605817\n",
      "\n",
      "layers 5 hidden_features 64 if_activate True if_normal False if_dropout False\n",
      "In epoch 0, loss: 0.6931163668632507, train_auc: 0.6715434299767187, val_auc: 0.6633036911590475\n",
      "In epoch 20, loss: 0.6365147233009338, train_auc: 0.7599134770044293, val_auc: 0.7490804486203549\n",
      "In epoch 40, loss: 0.6247819662094116, train_auc: 0.7665901067742481, val_auc: 0.7592436394053922\n",
      "In epoch 60, loss: 0.6175351738929749, train_auc: 0.7782187545147786, val_auc: 0.7675808212435726\n",
      "In epoch 80, loss: 0.6171295642852783, train_auc: 0.7828087606741093, val_auc: 0.7716486915843668\n",
      "In epoch 100, loss: 0.6134411692619324, train_auc: 0.7768105162579335, val_auc: 0.764986882188112\n",
      "In epoch 120, loss: 0.6102050542831421, train_auc: 0.7768819875527622, val_auc: 0.7642384557671129\n",
      "In epoch 140, loss: 0.6071739792823792, train_auc: 0.7862142402634872, val_auc: 0.773071084874432\n",
      "In epoch 160, loss: 0.6092852354049683, train_auc: 0.7936729465707995, val_auc: 0.7791689876489556\n",
      "In epoch 180, loss: 0.6029276251792908, train_auc: 0.7956884287465714, val_auc: 0.7809853758527515\n",
      "Test AUC 0.7821596828272772\n",
      "\n",
      "layers 5 hidden_features 64 if_activate False if_normal True if_dropout True\n",
      "In epoch 0, loss: 0.6650675535202026, train_auc: 0.7559463521816575, val_auc: 0.7436968293072409\n",
      "In epoch 20, loss: 0.627403974533081, train_auc: 0.7751287431175424, val_auc: 0.7646768466508538\n",
      "In epoch 40, loss: 0.6235560178756714, train_auc: 0.7814958825463978, val_auc: 0.7697664309831502\n",
      "In epoch 60, loss: 0.6206909418106079, train_auc: 0.7831515971085298, val_auc: 0.7711835446617336\n",
      "In epoch 80, loss: 0.6175732016563416, train_auc: 0.7876535681826897, val_auc: 0.7748377163373581\n",
      "In epoch 100, loss: 0.6156672239303589, train_auc: 0.7910884855277461, val_auc: 0.777734242020921\n",
      "In epoch 120, loss: 0.6135644316673279, train_auc: 0.7907060906693801, val_auc: 0.7767277742810527\n",
      "In epoch 140, loss: 0.6124798655509949, train_auc: 0.7906020448906288, val_auc: 0.7760798401775991\n",
      "In epoch 160, loss: 0.6111664175987244, train_auc: 0.7911476723405491, val_auc: 0.7763170860469631\n",
      "In epoch 180, loss: 0.6103481650352478, train_auc: 0.7922512037350676, val_auc: 0.7774048054388006\n",
      "Test AUC 0.7605492989541627\n",
      "\n",
      "layers 5 hidden_features 64 if_activate False if_normal True if_dropout False\n",
      "In epoch 0, loss: 0.6546687483787537, train_auc: 0.7655539780699925, val_auc: 0.749653035341989\n",
      "In epoch 20, loss: 0.6271171569824219, train_auc: 0.7621413430835917, val_auc: 0.7530857333693447\n",
      "In epoch 40, loss: 0.6199179291725159, train_auc: 0.7768422381329421, val_auc: 0.7645290729534653\n",
      "In epoch 60, loss: 0.6157472729682922, train_auc: 0.7777727258452722, val_auc: 0.7651872758068878\n",
      "In epoch 80, loss: 0.6146895289421082, train_auc: 0.7812951047074433, val_auc: 0.7679107070368822\n",
      "In epoch 100, loss: 0.6132381558418274, train_auc: 0.7793782441760667, val_auc: 0.7657479379183769\n",
      "In epoch 120, loss: 0.6124069690704346, train_auc: 0.7809708019044964, val_auc: 0.7672500388181649\n",
      "In epoch 140, loss: 0.6114764213562012, train_auc: 0.7814768816160118, val_auc: 0.7675330276197517\n",
      "In epoch 160, loss: 0.6125847101211548, train_auc: 0.784779303836788, val_auc: 0.770786124344846\n",
      "In epoch 180, loss: 0.6092769503593445, train_auc: 0.7833326283405125, val_auc: 0.7689905695594187\n",
      "Test AUC 0.7588114745201071\n",
      "\n",
      "layers 5 hidden_features 64 if_activate False if_normal False if_dropout True\n",
      "In epoch 0, loss: 0.6930195689201355, train_auc: 0.6642467424684289, val_auc: 0.6558999435417323\n",
      "In epoch 20, loss: 0.6382111310958862, train_auc: 0.7356264105594317, val_auc: 0.7278208181234362\n",
      "In epoch 40, loss: 0.633580207824707, train_auc: 0.7500656107922831, val_auc: 0.7412541796122954\n",
      "In epoch 60, loss: 0.6318832635879517, train_auc: 0.7527334144006682, val_auc: 0.7436752834318698\n",
      "In epoch 80, loss: 0.630586564540863, train_auc: 0.753443860391718, val_auc: 0.7439169525619262\n",
      "In epoch 100, loss: 0.6300509572029114, train_auc: 0.7517653894457691, val_auc: 0.7422838073145015\n",
      "In epoch 120, loss: 0.6290081739425659, train_auc: 0.7533885618440085, val_auc: 0.7437769618847727\n",
      "In epoch 140, loss: 0.629334568977356, train_auc: 0.7576177064015629, val_auc: 0.7476672395433143\n",
      "In epoch 160, loss: 0.6347121596336365, train_auc: 0.7526212831551362, val_auc: 0.7429379042344317\n",
      "In epoch 180, loss: 0.6282464861869812, train_auc: 0.7565683924829737, val_auc: 0.746570162579634\n",
      "Test AUC 0.7402500611678763\n",
      "\n",
      "layers 5 hidden_features 64 if_activate False if_normal False if_dropout False\n",
      "In epoch 0, loss: 0.693049430847168, train_auc: 0.6669464650480595, val_auc: 0.6584802183566687\n",
      "In epoch 20, loss: 0.6335085034370422, train_auc: 0.7458659261691976, val_auc: 0.7373537738153909\n",
      "In epoch 40, loss: 0.6333820819854736, train_auc: 0.7514905785853946, val_auc: 0.7427278004331702\n",
      "In epoch 60, loss: 0.6316810846328735, train_auc: 0.7528028955264306, val_auc: 0.7435475136562667\n",
      "In epoch 80, loss: 0.631523072719574, train_auc: 0.7513395303525394, val_auc: 0.7414678942599249\n",
      "In epoch 100, loss: 0.634436845779419, train_auc: 0.7548743815014017, val_auc: 0.7454114633441921\n",
      "In epoch 120, loss: 0.6308258175849915, train_auc: 0.7544307498953354, val_auc: 0.7450789940270818\n",
      "In epoch 140, loss: 0.6292642951011658, train_auc: 0.7577473200151099, val_auc: 0.7477127703273101\n",
      "In epoch 160, loss: 0.6298600435256958, train_auc: 0.7554628701699552, val_auc: 0.7454670685581392\n",
      "In epoch 180, loss: 0.6287040710449219, train_auc: 0.7588189590147018, val_auc: 0.7484765328123432\n",
      "Test AUC 0.7459670909634238\n",
      "\n",
      "Best Parameter\n",
      "{'loop': None, 'layers': 5, 'if_activate': True, 'if_normal': True, 'if_dropout': True, 'auc': 0.8253353960786904, 'hidden_features': 64}\n",
      "In epoch 0, loss: 0.6551886796951294, train_auc: 0.7474239666092747, val_auc: 0.7358491065486558\n",
      "In epoch 20, loss: 0.6286708116531372, train_auc: 0.7803742533711014, val_auc: 0.7688955833238247\n",
      "In epoch 40, loss: 0.6228764057159424, train_auc: 0.7831307306958596, val_auc: 0.7722317938908796\n",
      "In epoch 60, loss: 0.6181821227073669, train_auc: 0.7872015331823832, val_auc: 0.774118494312882\n",
      "In epoch 80, loss: 0.6133245229721069, train_auc: 0.7929094688910989, val_auc: 0.7788651107508532\n",
      "In epoch 100, loss: 0.6088657975196838, train_auc: 0.792095584782148, val_auc: 0.7760985793408799\n",
      "In epoch 120, loss: 0.6058306097984314, train_auc: 0.7973696469836358, val_auc: 0.7815768093036801\n",
      "In epoch 140, loss: 0.6033571362495422, train_auc: 0.8017689367600729, val_auc: 0.7856970302778521\n",
      "In epoch 160, loss: 0.6006920337677002, train_auc: 0.8034544679996384, val_auc: 0.7865068936765919\n",
      "In epoch 180, loss: 0.5970883369445801, train_auc: 0.8114140377404804, val_auc: 0.7939332421665963\n",
      "Test AUC 0.7725148094720773\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test auc 0.7725148094720773\n"
     ]
    }
   ],
   "source": [
    "train_g, train_pos_g, train_neg_g, val_pos_g, val_neg_g, test_pos_g, test_neg_g = prepare_edge_data(G_ppi, if_ppi=True)\n",
    "lr = 0.01\n",
    "layers = [2, 5]\n",
    "hidden_features = [16, 32, 64]\n",
    "if_activate = [True, False]\n",
    "if_normal = [True, False]\n",
    "if_dropout = [True, False]\n",
    "best_param_ppi = {\"loop\": None, \"layers\": None, \"if_activate\": None, \"if_normal\": None, \"if_dropout\": None, \"auc\": 0.0}\n",
    "\n",
    "for h_f in hidden_features:\n",
    "    for l in layers:\n",
    "        for a in if_activate:\n",
    "            for n in if_normal:\n",
    "                for d in if_dropout:\n",
    "                    print(\"layers\", l, \"hidden_features\", h_f, \"if_activate\", a, \"if_normal\", n, \"if_dropout\", d)\n",
    "                    model = GCN(G_ppi.ndata['feat'].shape[1], h_f, layers=l, if_activate=a, if_normal=n, if_dropout=d)\n",
    "                    pred = DotPredictor()\n",
    "                    best_val_auc, _ = train(train_g, train_pos_g, train_neg_g, val_pos_g, val_neg_g, test_pos_g, test_neg_g, model, pred, epochs=200, print_epoch=20, lr=lr)\n",
    "                    if best_val_auc > best_param_ppi[\"auc\"]:\n",
    "                        best_param_ppi[\"layers\"] = l\n",
    "                        best_param_ppi[\"if_activate\"] = a\n",
    "                        best_param_ppi[\"if_dropout\"] = d\n",
    "                        best_param_ppi[\"if_normal\"] = n\n",
    "                        best_param_ppi[\"hidden_features\"] = h_f\n",
    "                        best_param_ppi[\"auc\"] = best_val_auc\n",
    "                    print()\n",
    "    \n",
    "print(\"Best Parameter\")\n",
    "h_f = best_param_ppi[\"hidden_features\"]\n",
    "l = best_param_ppi[\"layers\"]\n",
    "a = best_param_ppi[\"if_activate\"]\n",
    "n = best_param_ppi[\"if_normal\"]\n",
    "d = best_param_ppi[\"if_dropout\"]\n",
    "print(best_param_ppi)\n",
    "model = GCN(G_ppi.ndata['feat'].shape[1], h_f, layers=l, if_activate=a, if_normal=n, if_dropout=d)\n",
    "pred = DotPredictor()\n",
    "_, best_test_auc = train(train_g, train_pos_g, train_neg_g, val_pos_g, val_neg_g, test_pos_g, test_neg_g, model, pred, epochs=200, print_epoch=20, lr=lr, if_print=True)\n",
    "print(\"test auc\", best_test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "acaec859acc9572497702a231b5e190bd1ea4c9a49755c602d23324810c022c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
