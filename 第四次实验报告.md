# USTC深度学习课程实验报告-作业四

姓名：鲍丙雷     学号：SA22218107

------

### 数据集介绍

#### cora

![](https://cdn.jsdelivr.net/gh/baoblei/imgs_md/20230215141253.png)

- `cora.cites`:Cora数据集的边列表文件`cora.cites`是一个文本文件，其中每一行表示一条边。该文件的格式为：

```php
<target_id>  <source_id>
<target_id>  <source_id>
<target_id>  <source_id>
...

```

其中每行的两个整数表示一条边连接的两个顶点的唯一标识符。顶点的唯一标识符在节点列表文件`cora.content`中给出。两个节点之间的一条边，表示为从源节点到目标节点的有向边。

- `cora.content`:Cora数据集的`cora.content`文件是一个文本文件，每一行表示一个节点的信息。该文件的格式为：

```php
<paper_id> <word_attributes> <class_label>

```

其中，`<paper_id>`是一个唯一的整数标识符，表示一篇论文；`<word_attributes>`是该论文的词属性列表，即该论文在文本中出现的单词列表及其在该论文中的出现次数；`<class_label>`表示该论文所属的类别标签。

在处理Cora数据集时，通常需要将`<paper_id>`这一列的节点标识符映射到连续的整数值，以便于在代码中使用。此外，需要将`<word_attributes>`和`<class_label>`提取出来作为节点的特征向量。在Cora数据集中，`<word_attributes>`是一个包含1433个二进制值的向量，表示论文中所有单词是否出现过，`<class_label>`是一个长度为7的向量，表示论文所属的7个类别之一。

#### citeseer

Citeseer是一个基于学术论文引用关系的图数据集，由Cornell大学收集和维护。该数据集包含了3025篇论文和Citeseer引用网络中的3327个引用关系，每篇论文被分配到一类中，一共有6个类别。数据集结构和cora类似，不再详细说明。

#### ppi

PPI（Protein-Protein Interaction）数据集是一个基于蛋白质相互作用关系的图分类任务数据集。PPI数据集共24张图，每张图对应不同的人体组织，平均每张图有2371个节点，共56944个节点818716条边，每个节点特征长度为50，其中包含位置基因集，基序集和免疫学特征。基因本体基作为label(总共121个)，label不是one-hot编码。

![](https://cdn.jsdelivr.net/gh/baoblei/imgs_md/20230217151142.png)

- `ppi-feats.npy`文件保存节点的特征，shape为(56944, 50)(节点数目，特征维度)，值为0或1，且1的数目稀少

- `ppi-class_map.json`为节点的label文件，shape为(121, 56944),每个节点的label为121维
- `ppi-G.json`文件为节点和链接的描述信息，节点(nodes):[...{"test": true, "id": 56708, "val": false}...], 表示节点id为56708的节点是否为test集或者val集，链接(links): [...{"source": 0, "target": 1101...}, 表示节点id为0的节点和为1101的节点之间有links
- `ppi-id_map.json`文件为节点id信息

### 数据处理

#### cora

##### 构建图

```py
# 将节点ID映射成连续整数序号，并按序号生成连接信息
cora_dir = "./datasets/cora/"
nodes_id_map = {}               # 定义一个字典 nodes_id_map，用于记录节点的ID和其在图中的序号
start = 0                       # 定义一个变量 start，表示从0开始标记节点序号
start_list, target_list = [], []
with open(cora_dir+"cora.cites") as f:          # 打开边列表文件 cora.cites
    for ln in f:                # 对文件中的每一行执行
        ln = ln.strip("\n").split("\t")    # 去除行末的换行符，并将该行按制表符分割为两个元素，即边的起点和终点节点的ID。
        start_i, target_i = int(ln[1]), int(ln[0])  # 获取边两端节点的ID
        if start_i not in nodes_id_map:      # 起点节点是否在nodes_id_map 中已有记录
            nodes_id_map[start_i] = start
            start += 1
        if target_i not in nodes_id_map:   # 终点节点是否在nodes_id_map 中已有记录
            nodes_id_map[target_i] = start
            start += 1 
        start_list.append(nodes_id_map[start_i])
        target_list.append(nodes_id_map[target_i])

feature_names = ["w_{}".format(ii) for ii in range(1433)]
column_names =  feature_names + ["subject"]    # cora.content文件列名（特征+类别）
node_data = pd.read_csv(os.path.join(cora_dir+"cora.content"), sep='\t', header=None, names=column_names)   

# 将Cora数据集中的7种类别字符串映射到数字标签
cora_label_map = {
      'Case_Based': 0,
      'Genetic_Algorithms': 1,
      'Neural_Networks': 2,
      'Probabilistic_Methods': 3,
      'Reinforcement_Learning': 4,
      'Rule_Learning': 5,
      'Theory': 6,
  }

# 构造cora_features和cora_labels 列表，可以按节点序号(连续的整数)为索引获取各个节点的特征和类别
cora_features = [None for _ in range(len(nodes_id_map))]   
cora_labels = [None for _ in range(len(nodes_id_map))]    
for i in range(node_data.shape[0]):
    feature_i, label_i = node_data.iloc[i][:-1], cora_label_map[node_data.iloc[i].tolist()[-1]]
    node_index_i = nodes_id_map[node_data.index[i]]
    cora_features[node_index_i] = feature_i
    cora_labels[node_index_i] = label_i

# 根据边列表和节点特征构建图
G_cora = dgl.DGLGraph()
G_cora.add_edges(start_list, target_list)
G_cora.ndata['feat'] = torch.Tensor(np.array(cora_features, dtype=np.float64))
G_cora.ndata['label'] = torch.Tensor(np.array(cora_labels)).type(torch.int64)
```

##### 划分数据集

```py
# 数据集划分(8:1:1)
train_size = int(0.8*len(cora_labels))
val_size = int((len(cora_labels)-train_size)/2)

all_d = set([i for i in range(len(cora_labels))])
train_mask = set(random.sample(all_d, train_size))
val_mask = set(random.sample(all_d-train_mask, val_size))
test_mask = all_d-train_mask-val_mask

G_cora.ndata['train_mask'] = torch.Tensor(np.array([True if i in train_mask else False for i in range(len(all_d))])).type(torch.bool)
G_cora.ndata['val_mask'] = torch.Tensor(np.array([True if i in val_mask else False for i in range(len(all_d))])).type(torch.bool)
G_cora.ndata['test_mask'] = torch.Tensor(np.array([True if i in test_mask else False for i in range(len(all_d))])).type(torch.bool)
```

#### citeseer

##### 构建图

```py
# Process CiteSeer
# 将节点ID映射成连续整数序号，并按序号生成连接信息
citeseer_dir = "./datasets/citeseer/"
nodes_id_map = {}
start_list, target_list = [], []
start = 0
node_data = pd.read_csv(os.path.join(citeseer_dir+"citeseer.content"), sep='\t', header=None)
node_data_id_set = set([str(i) for i in node_data[0].tolist()])
with open(citeseer_dir+"citeseer.cites") as f:
    for ln in f:
        ln = ln.strip("\n").split("\t")
        start_i, target_i = ln[1], ln[0]
        if start_i not in node_data_id_set or target_i not in node_data_id_set:
            continue
        if start_i not in nodes_id_map:
            nodes_id_map[start_i] = start
            start += 1
        if target_i not in nodes_id_map:
            nodes_id_map[target_i] = start
            start += 1 
        start_list.append(nodes_id_map[start_i])
        target_list.append(nodes_id_map[target_i])
        
# 将citeseer数据集中的6种类别字符串映射到数字标签
citeseer_label_map = {
  "Agents": 0,
	"AI": 1,
	"DB": 2,
	"IR": 3,
	"ML": 4,
  "HCI": 5
}

# 构造citeseer_features和citeseer_labels 列表，可以按节点序号为索引获取各个节点的特征和类别
citeseer_features = [None for _ in range(len(nodes_id_map))]
citeseer_labels = [None for _ in range(len(nodes_id_map))]
for i in range(node_data.shape[0]):
    tmp_i = node_data.iloc[i].tolist()
    feature_i, label_i = tmp_i[1:-1], citeseer_label_map[tmp_i[-1]]
    node_index_i = nodes_id_map[str(tmp_i[0])]
    citeseer_features[node_index_i] = feature_i
    citeseer_labels[node_index_i] = label_i
    
# 根据边列表和节点特征构建图
G_citeseer = dgl.DGLGraph()
G_citeseer.add_edges(start_list, target_list)
G_citeseer.ndata['feat'] = torch.Tensor(np.array(citeseer_features, dtype=np.float64))
G_citeseer.ndata['label'] = torch.Tensor(np.array(citeseer_labels)).type(torch.int64)
```

##### 划分数据集

```py
# 数据集划分(8:1:1)
train_size = int(0.8*len(citeseer_labels))
val_size = int((len(citeseer_labels)-train_size)/2)
all_d = set([i for i in range(len(citeseer_labels))])
train_mask = set(random.sample(all_d, train_size))
val_mask = set(random.sample(all_d-train_mask, val_size))
test_mask = all_d-train_mask-val_mask

G_citeseer.ndata['train_mask'] = torch.Tensor(np.array([True if i in train_mask else False for i in range(len(all_d))])).type(torch.bool)
G_citeseer.ndata['val_mask'] = torch.Tensor(np.array([True if i in val_mask else False for i in range(len(all_d))])).type(torch.bool)
G_citeseer.ndata['test_mask'] = torch.Tensor(np.array([True if i in test_mask else False for i in range(len(all_d))])).type(torch.bool)
```

#### PPI

##### 构建图

```py
ppi_dir = "./datasets/ppi/"

ppi_class_map = json.load(open(ppi_dir+"ppi-class_map.json"))  #  label文件
ppi_graph = json.load(open(ppi_dir+"ppi-G.json"))    # 图信息，包括节点的数据集标签（训练/验证/测试）和连接的描述信息
ppi_features = np.load(ppi_dir+"ppi-feats.npy")      # 节点特征
ppi_id_map = json.load(open(ppi_dir+"ppi-id_map.json"))  # 节点ID


ppi_labels = []
start_list, target_list = [], []
for i in ppi_graph["links"]:
    start_list.append(i["source"])
    target_list.append(i["target"])
for i in range(len(ppi_id_map)):
    ppi_labels.append(ppi_class_map[str(i)])

G_ppi = dgl.DGLGraph()
G_ppi.add_edges(start_list, target_list)
G_ppi.ndata['feat'] = torch.Tensor(np.array(ppi_features, dtype=np.float64))
G_ppi.ndata['label'] = torch.Tensor(np.array(ppi_labels)).type(torch.float32)

```

##### 划分数据集

PPI数据集的`ppi-G.json`文件已经给出各个节点的数据集划分描述信息，按照该文件划分数据集。

```py
train_mask = [None for _ in range(len(ppi_id_map))]
val_mask = [None for _ in range(len(ppi_id_map))]
test_mask = [None for _ in range(len(ppi_id_map))]
for i in ppi_graph["nodes"]:
    if i["test"]:
        test_mask[i["id"]] = True
    else:
        test_mask[i["id"]] = False
    if i["val"]:
        val_mask[i["id"]] = True
    else:
        val_mask[i["id"]] = False
    if not val_mask[i["id"]] and not test_mask[i["id"]]:
        train_mask[i["id"]] = True
    else:
        train_mask[i["id"]] = False

G_ppi.ndata['train_mask'] = torch.Tensor(np.array(train_mask)).type(torch.bool)
G_ppi.ndata['val_mask'] = torch.Tensor(np.array(val_mask)).type(torch.bool)
G_ppi.ndata['test_mask'] = torch.Tensor(np.array(test_mask)).type(torch.bool)
```

#### 链路预测数据集划分采样

```py
def prepare_edge_data(input_g, if_ppi=False):
    u, v = input_g.edges()
    eids = np.arange(input_g.number_of_edges())
    eids = np.random.permutation(eids)
    test_size = int(len(eids) * 0.1)
    val_size = test_size
    train_size = input_g.number_of_edges() - test_size - val_size
    test_pos_u, test_pos_v = u[eids[:test_size]], v[eids[:test_size]]
    val_pos_u, val_pos_v = u[eids[test_size:test_size+val_size]], v[eids[test_size:test_size+val_size]]
    train_pos_u, train_pos_v = u[eids[test_size+val_size:]], v[eids[test_size+val_size:]]

    # Find all negative edges and split them for training and testing
    adj = sp.coo_matrix((np.ones(len(u)), (u.numpy(), v.numpy())))
    adj = adj.todense()    # 转化为密集矩阵
    if if_ppi:
        adj = np.pad(adj, [(0, adj.shape[1]-adj.shape[0]), (0, 0)], mode='constant', constant_values=0)

    adj_neg = 1 - adj - np.eye(input_g.number_of_nodes())  
    neg_u, neg_v = np.where(adj_neg != 0)     

    neg_eids = np.random.choice(len(neg_u), input_g.number_of_edges())
    test_neg_u, test_neg_v = neg_u[neg_eids[:test_size]], neg_v[neg_eids[:test_size]]
    val_neg_u, val_neg_v = neg_u[neg_eids[test_size:test_size+val_size]], neg_v[neg_eids[test_size:test_size+val_size]]
    train_neg_u, train_neg_v = neg_u[neg_eids[test_size+val_size:]], neg_v[neg_eids[test_size+val_size:]]

    train_pos_g = dgl.graph((train_pos_u, train_pos_v), num_nodes=input_g.number_of_nodes())
    train_neg_g = dgl.graph((train_neg_u, train_neg_v), num_nodes=input_g.number_of_nodes())

    val_pos_g = dgl.graph((val_pos_u, val_pos_v), num_nodes=input_g.number_of_nodes())
    val_neg_g = dgl.graph((val_neg_u, val_neg_v), num_nodes=input_g.number_of_nodes())

    test_pos_g = dgl.graph((test_pos_u, test_pos_v), num_nodes=input_g.number_of_nodes())
    test_neg_g = dgl.graph((test_neg_u, test_neg_v), num_nodes=input_g.number_of_nodes())

    train_g = dgl.remove_edges(input_g, eids[:test_size+val_size])
    return train_g, train_pos_g, train_neg_g, val_pos_g, val_neg_g, test_pos_g, test_neg_g
```



### 定义GCN网络结构

#### 定义GraphConv层

```py
class GraphConv(nn.Module):
    def __init__(self, in_feats, out_feats, activation=None,):
        super(GraphConv, self).__init__()
        self._in_feats = in_feats
        self._out_feats = out_feats
        self.weight = nn.Parameter(torch.Tensor(in_feats, out_feats))
        self.bias = nn.Parameter(torch.Tensor(out_feats))
        torch.nn.init.xavier_uniform_(self.weight)
        torch.nn.init.zeros_(self.bias)

    def forward(self, graph, feat, weight=None):
        with graph.local_scope():
            aggregate_fn = copy_src('h', 'm')
            feat_src, feat_dst = expand_as_pair(feat, graph) # 获取 source 节点特征/target 节点特征
            degs = graph.out_degrees().float().clamp(min=1)   # 计算每个节点的出度，最小为1避免出现除0
            norm = torch.pow(degs, -0.5)      # normalized
            shp = norm.shape + (1,) * (feat_src.dim() - 1)
            norm = torch.reshape(norm, shp)
            feat_src = feat_src * norm
            weight = self.weight

            #按图结构进行卷积汇聚
            feat_src = torch.matmul(feat_src, weight)
            graph.srcdata['h'] = feat_src   
            graph.update_all(aggregate_fn, fn_sum(msg='m', out='h'))  # 聚合
            rst = graph.dstdata['h']

            degs = graph.in_degrees().float().clamp(min=1)
            norm = torch.pow(degs, -0.5)
            shp = norm.shape + (1,) * (feat_dst.dim() - 1)
            norm = torch.reshape(norm, shp)
            rst = rst * norm
            rst = rst + self.bias

            return rst 

```



#### 定义GCN网络

```py
class GCN(nn.Module):
    def __init__(self, in_feats, h_feats, num_classes, layers=2, if_ppi=False, 
                 if_activate=True, if_normal=True, if_dropout=False):
        super(GCN, self).__init__()
        self.if_ppi = if_ppi
        self.layers = layers
        self.if_activate = if_activate
        self.if_dropout = if_dropout
        self.if_normal = if_normal
        if layers>2:
            self.linears = torch.nn.ModuleList([GraphConv(h_feats, h_feats) for _ in range(layers-2)])
        self.conv1 = GraphConv(in_feats, h_feats)
        self.conv2 = GraphConv(h_feats, num_classes)
        self.dropout = torch.nn.Dropout(p=0.5, inplace=False)

    def forward(self, g, in_feat):
        h = self.conv1(g, in_feat)
        if self.if_activate:
            h = F.relu(h)
        if self.layers > 2:
            for i, l in enumerate(self.linears):
                h = l(g, h)
        if self.if_activate:
            h = F.relu(h)
        if self.if_dropout:
            h = self.dropout(h)
        if self.if_normal:
            h = torch.nn.functional.normalize(h)
        h = self.conv2(g, h)
        return h
```

#### 链路预测函数

```py
class DotPredictor(nn.Module):
    def forward(self, g, h):
        with g.local_scope():
            g.ndata['h'] = h
            # Compute a new edge feature named 'score' by a dot-product between the
            # source node feature 'h' and destination node feature 'h'.
            g.apply_edges(u_dot_v('h', 'h', 'score'))
            # u_dot_v returns a 1-element vector for each edge so you need to squeeze it.
            return g.edata['score'][:, 0]
```

#### 评价指标

```py
def compute_loss(pos_score, neg_score):
    scores = torch.cat([pos_score, neg_score])
    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])])
    return F.binary_cross_entropy_with_logits(scores, labels)

def compute_auc(pos_score, neg_score):
    scores = torch.cat([pos_score, neg_score]).numpy()
    labels = torch.cat(
        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).numpy()
    return roc_auc_score(labels, scores)
```



### 模型训练和测试

#### 链路预测



```py
def train(train_g, train_pos_g, train_neg_g, val_pos_g, val_neg_g, test_pos_g, test_neg_g, model, pred, epochs=200, print_epoch=20, lr=0.01,if_print=False):
    best_val_auc = 0.0
    best_test_auc = 0.0
    all_loss = []
    optimizer = torch.optim.Adam(itertools.chain(model.parameters(), pred.parameters()), lr=lr)
    for e in range(epochs):
        # forward
        model.zero_grad()
        model.train()
        h = model(train_g, train_g.ndata['feat'])
        pos_score = pred(train_pos_g, h)
        neg_score = pred(train_neg_g, h)
        loss = compute_loss(pos_score, neg_score)
        all_loss.append(loss.detach().numpy())

        # backward
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        if e % print_epoch == 0:
            model.eval()
            with torch.no_grad():
                h = model(train_g, train_g.ndata['feat'])
                train_pos_score = pred(train_pos_g, h)
                train_neg_score = pred(train_neg_g, h)
                val_pos_score = pred(val_pos_g, h)
                val_neg_score = pred(val_neg_g, h)
                train_auc = compute_auc(train_pos_score, train_neg_score)
                val_auc = compute_auc(val_pos_score, val_neg_score)
                if val_auc > best_val_auc:
                    best_val_auc = val_auc
            print('In epoch {}, loss: {}, train_auc: {}, val_auc: {}'.format(e, loss, train_auc, val_auc))
 
    with torch.no_grad():
        test_pos_score = pred(test_pos_g, h)
        test_neg_score = pred(test_neg_g, h)
        test_auc = compute_auc(test_pos_score, test_neg_score)
        if test_auc > best_test_auc:
            best_test_auc = test_auc
        print('Test AUC', test_auc)
    if if_print:
        plt.plot(all_loss)
        plt.show()  
    return best_val_auc, best_test_auc
```

##### cora

```py
train_g, train_pos_g, train_neg_g, val_pos_g, val_neg_g, test_pos_g, test_neg_g = prepare_edge_data(G_cora)
lr = 0.01
layers = [2, 5]
hidden_features = [16, 32, 64]
if_activate = [True, False]
if_normal = [True, False]
if_dropout = [True, False]
best_param_cora = {"loop": None, "layers": None, "if_activate": None, "if_normal": None, "if_dropout": None, "auc": 0.0}

for h_f in hidden_features:
    for l in layers:
        for a in if_activate:
            for n in if_normal:
                for d in if_dropout:
                    print("layers", l, "hidden_features", h_f, "if_activate", a, "if_normal", n, "if_dropout", d)
                    model = GCN(G_cora.ndata['feat'].shape[1], h_f, layers=l, if_activate=a, if_normal=n, if_dropout=d)
                    pred = DotPredictor()
                    best_val_auc, _ = train(train_g, train_pos_g, train_neg_g, val_pos_g, val_neg_g, test_pos_g, test_neg_g, model, pred, epochs=201, print_epoch=100, lr=lr)
                    if best_val_auc > best_param_cora["auc"]:
                        best_param_cora["layers"] = l
                        best_param_cora["if_activate"] = a
                        best_param_cora["if_dropout"] = d
                        best_param_cora["if_normal"] = n
                        best_param_cora["hidden_features"] = h_f
                        best_param_cora["auc"] = best_val_auc
                    print()


print("Best Parameter")
h_f = best_param_cora["hidden_features"]
l = best_param_cora["layers"]
a = best_param_cora["if_activate"]
n = best_param_cora["if_normal"]
d = best_param_cora["if_dropout"]
print(best_param_cora)
model = GCN(G_cora.ndata['feat'].shape[1], h_f, layers=l, if_activate=a, if_normal=n, if_dropout=d)
pred = DotPredictor()
_, best_test_auc = train(train_g, train_pos_g, train_neg_g, val_pos_g, val_neg_g, test_pos_g, test_neg_g, model, pred, epochs=201, print_epoch=100, lr=lr, if_print=True)
print("test auc", best_test_auc)
```

- 输出结果

![](https://cdn.jsdelivr.net/gh/baoblei/imgs_md/20230217200328.png)

- 验证集上最好的超参数

![](https://cdn.jsdelivr.net/gh/baoblei/imgs_md/20230217200618.png)

使用DropEdge在测试集上可以得到较好效果，更多深的层数会导致模型过拟合，因为Cora数据集本身样本偏少测试集合上AUC达到88.53%

##### citeseer

```py
train_g, train_pos_g, train_neg_g, val_pos_g, val_neg_g, test_pos_g, test_neg_g = prepare_edge_data(G_citeseer)
lr = 0.01
layers = [2, 5]
hidden_features = [16, 32, 64]
if_activate = [True, False]
if_normal = [True, False]
if_dropout = [True, False]
best_param_citeseer = {"loop": None, "layers": None, "if_activate": None, "if_normal": None, "if_dropout": None, "auc": 0.0}

for h_f in hidden_features:
    for l in layers:
        for a in if_activate:
            for n in if_normal:
                for d in if_dropout:
                    print("layers", l, "hidden_features", h_f, "if_activate", a, "if_normal", n, "if_dropout", d)
                    model = GCN(G_citeseer.ndata['feat'].shape[1], h_f, layers=l, if_activate=a, if_normal=n, if_dropout=d)
                    pred = DotPredictor()
                    best_val_auc, _ = train(train_g, train_pos_g, train_neg_g, val_pos_g, val_neg_g, test_pos_g, test_neg_g, model, pred, epochs=201, print_epoch=200, lr=lr)
                    if best_val_auc > best_param_citeseer["auc"]:
                        best_param_citeseer["layers"] = l
                        best_param_citeseer["if_activate"] = a
                        best_param_citeseer["if_dropout"] = d
                        best_param_citeseer["if_normal"] = n
                        best_param_citeseer["hidden_features"] = h_f
                        best_param_citeseer["auc"] = best_val_auc
                    print()
    
print("Best Parameter")
h_f = best_param_citeseer["hidden_features"]
l = best_param_citeseer["layers"]
a = best_param_citeseer["if_activate"]
n = best_param_citeseer["if_normal"]
d = best_param_citeseer["if_dropout"]
print(best_param_citeseer)
model = GCN(G_citeseer.ndata['feat'].shape[1], h_f, layers=l, if_activate=a, if_normal=n, if_dropout=d)
pred = DotPredictor()
_, best_test_auc = train(train_g, train_pos_g, train_neg_g, val_pos_g, val_neg_g, test_pos_g, test_neg_g, model, pred, epochs=201, print_epoch=200, lr=lr, if_print=True)
print("test auc", best_test_auc)
```

- 输出结果

![](https://cdn.jsdelivr.net/gh/baoblei/imgs_md/20230217200729.png)

- 验证集上最好的超参数

![](https://cdn.jsdelivr.net/gh/baoblei/imgs_md/20230217200920.png)

使用激活函数/使用PairNorm/使用DropEdge以及最大的隐层单元可以在Citeseer上带来最好的效果

测试集合上AUC达到 85.75%

##### ppi

```py
train_g, train_pos_g, train_neg_g, val_pos_g, val_neg_g, test_pos_g, test_neg_g = prepare_edge_data(G_ppi, if_ppi=True)
lr = 0.01
layers = [2, 5]
hidden_features = [16, 32, 64]
if_activate = [True, False]
if_normal = [True, False]
if_dropout = [True, False]
best_param_ppi = {"loop": None, "layers": None, "if_activate": None, "if_normal": None, "if_dropout": None, "auc": 0.0}

for h_f in hidden_features:
    for l in layers:
        for a in if_activate:
            for n in if_normal:
                for d in if_dropout:
                    print("layers", l, "hidden_features", h_f, "if_activate", a, "if_normal", n, "if_dropout", d)
                    model = GCN(G_ppi.ndata['feat'].shape[1], h_f, layers=l, if_activate=a, if_normal=n, if_dropout=d)
                    pred = DotPredictor()
                    best_val_auc, _ = train(train_g, train_pos_g, train_neg_g, val_pos_g, val_neg_g, test_pos_g, test_neg_g, model, pred, epochs=200, print_epoch=20, lr=lr)
                    if best_val_auc > best_param_ppi["auc"]:
                        best_param_ppi["layers"] = l
                        best_param_ppi["if_activate"] = a
                        best_param_ppi["if_dropout"] = d
                        best_param_ppi["if_normal"] = n
                        best_param_ppi["hidden_features"] = h_f
                        best_param_ppi["auc"] = best_val_auc
                    print()
    
print("Best Parameter")
h_f = best_param_ppi["hidden_features"]
l = best_param_ppi["layers"]
a = best_param_ppi["if_activate"]
n = best_param_ppi["if_normal"]
d = best_param_ppi["if_dropout"]
print(best_param_ppi)
model = GCN(G_ppi.ndata['feat'].shape[1], h_f, layers=l, if_activate=a, if_normal=n, if_dropout=d)
pred = DotPredictor()
_, best_test_auc = train(train_g, train_pos_g, train_neg_g, val_pos_g, val_neg_g, test_pos_g, test_neg_g, model, pred, epochs=200, print_epoch=20, lr=lr, if_print=True)
print("test auc", best_test_auc)
```

- 输出结果：

![](https://cdn.jsdelivr.net/gh/baoblei/imgs_md/20230217201027.png)

- 验证集上最好的超参数

![](https://cdn.jsdelivr.net/gh/baoblei/imgs_md/20230217201109.png)

使用PairNorm 对于准确率提升有帮助

测试集合上AUC为 77.25% 

##### 总结

对于3个数据集来说，更大的数据集结合更多的参数以及更深的网络对于AUC提升有显著效果，小数据上不适合多层GCN，EdgeDrop/PairNorm等技术对于大数据集合也是有明显效果。

#### 节点分类

```py
def train(g, model, epochs=50, print_epoch=5, lr=0.01, if_ppi=False, print_loss=True):
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)
    best_val_acc = 0
    best_test_acc = 0
    all_loss = []
    all_acc = []
    features = g.ndata['feat']
    labels = g.ndata['label']
    train_mask = g.ndata['train_mask']
    val_mask = g.ndata['val_mask']
    test_mask = g.ndata['test_mask']
    for e in range(epochs):
        # Forward
        logits = model(g, features)

        # Compute prediction
        if not if_ppi:
            pred = logits.argmax(1)
            # Compute loss
            # Note that you should only compute the losses of the nodes in the training set.
            loss = F.cross_entropy(logits[train_mask], labels[train_mask])

            # Compute accuracy on training/validation/test
        else:
            loss = F.binary_cross_entropy(logits[train_mask], labels[train_mask])
            pred = (logits>=0.5) * 1.0

        all_loss.append(loss.detach().numpy())
        train_acc = (pred[train_mask] == labels[train_mask]).float().mean()
        val_acc = (pred[val_mask] == labels[val_mask]).float().mean()
        test_acc = (pred[test_mask] == labels[test_mask]).float().mean()
        all_acc.append(train_acc)  
        # Save the best validation accuracy and the corresponding test accuracy.
        if best_val_acc < val_acc:
            best_val_acc = val_acc
            best_test_acc = test_acc

        # Backward
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        if e % print_epoch == 0:
            print('In epoch {}, loss: {:.3f}, val acc: {:.3f} (best {:.3f}), test acc: {:.3f} (best {:.3f})'.format(
                e, loss, val_acc, best_val_acc, test_acc, best_test_acc))
    if print_loss:
        plt.plot(all_loss, color="blue")
        plt.plot(all_acc, color="red")
        plt.show()  
    return best_val_acc, best_test_acc
```

##### cora

```py
# Train Cora
lr = 0.01
layers = [2, 5]
best_param_cora = {"loop": None, "layers": None, "if_activate": None, "if_normal": None, "if_dropout": None, "acc": 0.0}
hidden_features = [16, 32, 64]
if_activate = [True, False]
if_normal = [True, False]
if_dropout = [True, False]

for h_f in hidden_features:
    for l in layers:
        for a in if_activate:
            for n in if_normal:
                for d in if_dropout:
                    print("layers", l, "hidden_features", h_f, "if_activate", a, "if_normal", n, "if_dropout", d)
                    model = GCN(G_cora.ndata['feat'].shape[1], h_f, len(cora_label_map), layers=l, if_activate=a, if_normal=n, if_dropout=d)
                    best_val_acc, _ = train(G_cora, model, epochs=101, print_epoch=50, lr=lr, print_loss=False)
                    if best_val_acc > best_param_cora["acc"]:
                        best_param_cora["layers"] = l
                        best_param_cora["if_activate"] = a
                        best_param_cora["if_dropout"] = d
                        best_param_cora["if_normal"] = n
                        best_param_cora["acc"] = best_val_acc
                    print()


# Best Param
print("Best Parameter")
print(best_param_cora)
l = best_param_cora["layers"]
a = best_param_cora["if_activate"]
n = best_param_cora["if_normal"]
d = best_param_cora["if_dropout"]

model = GCN(G_cora.ndata['feat'].shape[1], h_f, len(cora_label_map), layers=l, if_activate=a, if_normal=n, if_dropout=d)
_, best_test_acc = train(G_cora, model, epochs=101, print_epoch=25, lr=lr)
print("best test acc", best_test_acc)
```

- 输出结果

  ![](https://cdn.jsdelivr.net/gh/baoblei/imgs_md/20230217201408.png)

- 验证集上最好的超参数

![](https://cdn.jsdelivr.net/gh/baoblei/imgs_md/20230217201508.png)

##### citeseer

```py
# Train Citeseer
lr = 0.01
layers = [2, 5]
Gs = [G_citeseer, G_citeseer_no_loop]
hidden_features = [16, 32, 64]
if_activate = [True, False]
if_normal = [True, False]
if_dropout = [True, False]
best_param_citeseer = {"loop": None, "layers": None, "if_activate": None, "if_normal": None, "if_dropout": None, "acc": 0.0}


for h_f in hidden_features:
    for g_tmp in Gs:
        if g_tmp == G_citeseer:
            loop = True
        else:
            loop = False             
        for l in layers:
            for a in if_activate:
                for n in if_normal:
                    for d in if_dropout:
                        print("layers", l, "hidden_features", h_f, "if_activate", a, "if_normal", n, "if_dropout", d, "loop", loop)
                        model = GCN(g_tmp.ndata['feat'].shape[1], h_f, len(citeseer_label_map), layers=l, if_activate=a, if_normal=n, if_dropout=d)
                        best_val_acc, _ = train(g_tmp, model, epochs=101, print_epoch=50, lr=lr, print_loss=False)
                        if best_val_acc > best_param_citeseer["acc"]:
                            best_param_citeseer["layers"] = l
                            best_param_citeseer["if_activate"] = a
                            best_param_citeseer["if_dropout"] = d
                            best_param_citeseer["if_normal"] = n
                            best_param_citeseer["acc"] = best_val_acc
                            best_param_citeseer["loop"] = loop
                            best_g = g_tmp
                        print()

# Best Param
print("Best Parameter")
print(best_param_citeseer)
l = best_param_citeseer["layers"]
a = best_param_citeseer["if_activate"]
n = best_param_citeseer["if_normal"]
d = best_param_citeseer["if_dropout"]
model = GCN(best_g.ndata['feat'].shape[1], h_f, len(citeseer_label_map), layers=l, if_activate=a, if_normal=n, if_dropout=d)
_, best_test_acc = train(best_g, model, epochs=101, print_epoch=50, lr=lr, print_loss=True)
print("best test acc", best_test_acc)
```

- 输出结果

  ![](https://cdn.jsdelivr.net/gh/baoblei/imgs_md/20230217201616.png)

- 验证集上最好的超参数

![](https://cdn.jsdelivr.net/gh/baoblei/imgs_md/20230217201653.png)

##### ppi

```py
# Train PPI
lr = 0.01
layers = [2, 5]
hidden_features = [16, 32, 64]
if_activate = [True, False]
if_normal = [True, False]
if_dropout = [True, False]
best_param_ppi = {"loop": None, "layers": None, "if_activate": None, "if_normal": None, "if_dropout": None, "acc": 0.0}


for h_f in hidden_features:
    for l in layers:
        for a in if_activate:
            for n in if_normal:
                for d in if_dropout:
                    print("layers", l, "hidden_features", h_f, "if_activate", a, "if_normal", n, "if_dropout", d)
                    model = GCN(G_ppi.ndata['feat'].shape[1], h_f, len(ppi_labels[0]), layers=l, if_activate=a, if_normal=n, if_dropout=d, if_ppi=True)
                    best_val_acc, _ = train(G_ppi, model, epochs=101, print_epoch=50, lr=lr, print_loss=False, if_ppi=True)
                    if best_val_acc > best_param_ppi["acc"]:
                        best_param_ppi["layers"] = l
                        best_param_ppi["if_activate"] = a
                        best_param_ppi["if_dropout"] = d
                        best_param_ppi["if_normal"] = n
                        best_param_ppi["acc"] = best_val_acc
                        best_param_ppi["loop"] = loop
                    print()
                        
# Best Param
print("Best Parameter")
print(best_param_ppi)
l = best_param_ppi["layers"]
a = best_param_ppi["if_activate"]
n = best_param_ppi["if_normal"]
d = best_param_ppi["if_dropout"]
model = GCN(G_ppi.ndata['feat'].shape[1], h_f, len(ppi_labels[0]), layers=l, if_activate=a, if_normal=n, if_dropout=d, if_ppi=True)
_, best_test_acc = train(G_ppi, model, epochs=101, print_epoch=50, lr=lr, print_loss=True, if_ppi=True)
print("best test acc", best_test_acc)
```

- 输出结果

  ![](https://cdn.jsdelivr.net/gh/baoblei/imgs_md/20230217201817.png)

- 验证集上最好的超参数

![](https://cdn.jsdelivr.net/gh/baoblei/imgs_md/20230217201852.png)

##### 总结

对于3个数据集来说，更多的层数并不会带来额外的效果，相同层数下更多的隐层单元会对于效果提升更大，平均可提升1-2%左右，其他的参数在各个数据集上效果不一。

