{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/sihua.qi/my_env/mypy36/lib/python3.7/site-packages/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.\n",
      "  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'\n"
     ]
    }
   ],
   "source": [
    "# Process Cora\n",
    "# 将节点ID映射成连续整数序号，并按序号生成连接信息\n",
    "cora_dir = \"./datasets/cora/\"\n",
    "nodes_id_map = {}               # 定义一个字典 nodes_id_map，用于记录节点的ID和其在图中的序号\n",
    "start = 0                       # 定义一个变量 start，表示从0开始标记节点序号\n",
    "start_list, target_list = [], []\n",
    "with open(cora_dir+\"cora.cites\") as f:          # 打开边列表文件 cora.cites\n",
    "    for ln in f:                # 对文件中的每一行执行\n",
    "        ln = ln.strip(\"\\n\").split(\"\\t\")    # 去除行末的换行符，并将该行按制表符分割为两个元素，即边的起点和终点节点的ID。\n",
    "        start_i, target_i = int(ln[1]), int(ln[0])  # 获取节点ID\n",
    "        if start_i not in nodes_id_map:      # 起点节点是否在nodes_id_map 中已有记录\n",
    "            nodes_id_map[start_i] = start\n",
    "            start += 1\n",
    "        if target_i not in nodes_id_map:     # 终点节点是否在nodes_id_map 中已有记录\n",
    "            nodes_id_map[target_i] = start\n",
    "            start += 1 \n",
    "        start_list.append(nodes_id_map[start_i])\n",
    "        target_list.append(nodes_id_map[target_i])\n",
    "        \n",
    "\n",
    "feature_names = [\"w_{}\".format(ii) for ii in range(1433)]\n",
    "column_names =  feature_names + [\"subject\"]    # cora.content文件列名（特征+类别）\n",
    "node_data = pd.read_csv(os.path.join(cora_dir+\"cora.content\"), sep='\\t', header=None, names=column_names)   \n",
    "\n",
    "# 将Cora数据集中的7种类别字符串映射到数字标签\n",
    "cora_label_map = {\n",
    "      'Case_Based': 0,\n",
    "      'Genetic_Algorithms': 1,\n",
    "      'Neural_Networks': 2,\n",
    "      'Probabilistic_Methods': 3,\n",
    "      'Reinforcement_Learning': 4,\n",
    "      'Rule_Learning': 5,\n",
    "      'Theory': 6,\n",
    "  }\n",
    "\n",
    "# 构造cora_features和cora_labels 列表，可以按节点序号为索引获取各个节点的特征和类别\n",
    "cora_features = [None for _ in range(len(nodes_id_map))]  \n",
    "cora_labels = [None for _ in range(len(nodes_id_map))]    \n",
    "for i in range(node_data.shape[0]):\n",
    "    feature_i, label_i = node_data.iloc[i][:-1], cora_label_map[node_data.iloc[i].tolist()[-1]]\n",
    "    node_index_i = nodes_id_map[node_data.index[i]]\n",
    "    cora_features[node_index_i] = feature_i\n",
    "    cora_labels[node_index_i] = label_i\n",
    "\n",
    "# 根据边列表和节点特征构建图\n",
    "G_cora = dgl.DGLGraph()\n",
    "G_cora.add_edges(start_list, target_list)\n",
    "G_cora.ndata['feat'] = torch.Tensor(np.array(cora_features, dtype=np.float64))\n",
    "G_cora.ndata['label'] = torch.Tensor(np.array(cora_labels)).type(torch.int64)\n",
    "\n",
    "# 数据集划分\n",
    "train_size = int(0.8*len(cora_labels))\n",
    "val_size = int((len(cora_labels)-train_size)/2)\n",
    "\n",
    "all_d = set([i for i in range(len(cora_labels))])\n",
    "train_mask = set(random.sample(all_d, train_size))\n",
    "val_mask = set(random.sample(all_d-train_mask, val_size))\n",
    "test_mask = all_d-train_mask-val_mask\n",
    "\n",
    "G_cora.ndata['train_mask'] = torch.Tensor(np.array([True if i in train_mask else False for i in range(len(all_d))])).type(torch.bool)\n",
    "G_cora.ndata['val_mask'] = torch.Tensor(np.array([True if i in val_mask else False for i in range(len(all_d))])).type(torch.bool)\n",
    "G_cora.ndata['test_mask'] = torch.Tensor(np.array([True if i in test_mask else False for i in range(len(all_d))])).type(torch.bool)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/sihua.qi/my_env/mypy36/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3457: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# Process CiteSeer\n",
    "citeseer_dir = \"./datasets/citeseer/\"\n",
    "nodes_id_map = {}\n",
    "start_list, target_list = [], []\n",
    "start = 0\n",
    "node_data = pd.read_csv(os.path.join(citeseer_dir+\"citeseer.content\"), sep='\\t', header=None)\n",
    "node_data_id_set = set([str(i) for i in node_data[0].tolist()])\n",
    "with open(citeseer_dir+\"citeseer.cites\") as f:\n",
    "    for ln in f:\n",
    "        ln = ln.strip(\"\\n\").split(\"\\t\")\n",
    "        start_i, target_i = ln[1], ln[0]\n",
    "        if start_i not in node_data_id_set or target_i not in node_data_id_set:\n",
    "            continue\n",
    "        if start_i not in nodes_id_map:\n",
    "            nodes_id_map[start_i] = start\n",
    "            start += 1\n",
    "        if target_i not in nodes_id_map:\n",
    "            nodes_id_map[target_i] = start\n",
    "            start += 1 \n",
    "        start_list.append(nodes_id_map[start_i])\n",
    "        target_list.append(nodes_id_map[target_i])\n",
    "       \n",
    "citeseer_label_map = {\n",
    "    \"Agents\": 0,\n",
    "\t\"AI\": 1,\n",
    "\t\"DB\": 2,\n",
    "\t\"IR\": 3,\n",
    "\t\"ML\": 4,\n",
    "    \"HCI\": 5\n",
    "}\n",
    "\n",
    "\n",
    "citeseer_features = [None for _ in range(len(nodes_id_map))]\n",
    "citeseer_labels = [None for _ in range(len(nodes_id_map))]\n",
    "for i in range(node_data.shape[0]):\n",
    "    tmp_i = node_data.iloc[i].tolist()\n",
    "    feature_i, label_i = tmp_i[1:-1], citeseer_label_map[tmp_i[-1]]\n",
    "    node_index_i = nodes_id_map[str(tmp_i[0])]\n",
    "    citeseer_features[node_index_i] = feature_i\n",
    "    citeseer_labels[node_index_i] = label_i\n",
    "\n",
    "G_citeseer = dgl.DGLGraph()\n",
    "G_citeseer.add_edges(start_list, target_list)\n",
    "G_citeseer.ndata['feat'] = torch.Tensor(np.array(citeseer_features, dtype=np.float64))\n",
    "G_citeseer.ndata['label'] = torch.Tensor(np.array(citeseer_labels)).type(torch.int64)\n",
    "\n",
    "# 划分数据集（8:1:1）\n",
    "train_size = int(0.8*len(citeseer_labels))\n",
    "val_size = int((len(citeseer_labels)-train_size)/2)\n",
    "all_d = set([i for i in range(len(citeseer_labels))])\n",
    "train_mask = set(random.sample(all_d, train_size))\n",
    "val_mask = set(random.sample(all_d-train_mask, val_size))\n",
    "test_mask = all_d-train_mask-val_mask\n",
    "\n",
    "G_citeseer.ndata['train_mask'] = torch.Tensor(np.array([True if i in train_mask else False for i in range(len(all_d))])).type(torch.bool)\n",
    "G_citeseer.ndata['val_mask'] = torch.Tensor(np.array([True if i in val_mask else False for i in range(len(all_d))])).type(torch.bool)\n",
    "G_citeseer.ndata['test_mask'] = torch.Tensor(np.array([True if i in test_mask else False for i in range(len(all_d))])).type(torch.bool)\n",
    "\n",
    "\n",
    "G_citeseer_no_loop = dgl.DGLGraph()\n",
    "no_loop_start = []\n",
    "no_loop_target = []\n",
    "for i in range(len(start_list)):\n",
    "    if start_list[i] == target_list[i]:\n",
    "        continue\n",
    "    no_loop_start.append(start_list[i])\n",
    "    no_loop_target.append(target_list[i])\n",
    "\n",
    "G_citeseer_no_loop.add_edges(no_loop_start, no_loop_target)\n",
    "G_citeseer_no_loop.ndata['feat'] = torch.Tensor(np.array(citeseer_features, dtype=np.float64))\n",
    "G_citeseer_no_loop.ndata['label'] = torch.Tensor(np.array(citeseer_labels)).type(torch.int64)\n",
    "\n",
    "train_size = int(0.8*len(citeseer_labels))\n",
    "val_size = int((len(citeseer_labels)-train_size)/2)\n",
    "all_d = set([i for i in range(len(citeseer_labels))])\n",
    "train_mask = set(random.sample(all_d, train_size))\n",
    "val_mask = set(random.sample(all_d-train_mask, val_size))\n",
    "test_mask = all_d-train_mask-val_mask\n",
    "\n",
    "G_citeseer_no_loop.ndata['train_mask'] = torch.Tensor(np.array([True if i in train_mask else False for i in range(len(all_d))])).type(torch.bool)\n",
    "G_citeseer_no_loop.ndata['val_mask'] = torch.Tensor(np.array([True if i in val_mask else False for i in range(len(all_d))])).type(torch.bool)\n",
    "G_citeseer_no_loop.ndata['test_mask'] = torch.Tensor(np.array([True if i in test_mask else False for i in range(len(all_d))])).type(torch.bool)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process PPI\n",
    "ppi_dir = \"./datasets/ppi/\"\n",
    "\n",
    "ppi_class_map = json.load(open(ppi_dir+\"ppi-class_map.json\"))\n",
    "ppi_graph = json.load(open(ppi_dir+\"ppi-G.json\"))\n",
    "ppi_features = np.load(ppi_dir+\"ppi-feats.npy\")\n",
    "ppi_id_map = json.load(open(ppi_dir+\"ppi-id_map.json\"))\n",
    "\n",
    "ppi_labels = []\n",
    "start_list, target_list = [], []\n",
    "for i in ppi_graph[\"links\"]:\n",
    "    start_list.append(i[\"source\"])\n",
    "    target_list.append(i[\"target\"])\n",
    "for i in range(len(ppi_id_map)):\n",
    "    ppi_labels.append(ppi_class_map[str(i)])\n",
    "\n",
    "G_ppi = dgl.DGLGraph()\n",
    "G_ppi.add_edges(start_list, target_list)\n",
    "G_ppi.ndata['feat'] = torch.Tensor(np.array(ppi_features, dtype=np.float64))\n",
    "G_ppi.ndata['label'] = torch.Tensor(np.array(ppi_labels)).type(torch.float32)\n",
    "\n",
    "\n",
    "train_mask = [None for _ in range(len(ppi_id_map))]\n",
    "val_mask = [None for _ in range(len(ppi_id_map))]\n",
    "test_mask = [None for _ in range(len(ppi_id_map))]\n",
    "for i in ppi_graph[\"nodes\"]:\n",
    "    if i[\"test\"]:\n",
    "        test_mask[i[\"id\"]] = True\n",
    "    else:\n",
    "        test_mask[i[\"id\"]] = False\n",
    "    if i[\"val\"]:\n",
    "        val_mask[i[\"id\"]] = True\n",
    "    else:\n",
    "        val_mask[i[\"id\"]] = False\n",
    "    if not val_mask[i[\"id\"]] and not test_mask[i[\"id\"]]:\n",
    "        train_mask[i[\"id\"]] = True\n",
    "    else:\n",
    "        train_mask[i[\"id\"]] = False\n",
    "\n",
    "G_ppi.ndata['train_mask'] = torch.Tensor(np.array(train_mask)).type(torch.bool)\n",
    "G_ppi.ndata['val_mask'] = torch.Tensor(np.array(val_mask)).type(torch.bool)\n",
    "G_ppi.ndata['test_mask'] = torch.Tensor(np.array(test_mask)).type(torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.function import copy_src, sum as fn_sum\n",
    "from dgl.utils import expand_as_pair\n",
    "\n",
    "\n",
    "class GraphConv(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats, activation=None,):\n",
    "        super(GraphConv, self).__init__()\n",
    "        self._in_feats = in_feats\n",
    "        self._out_feats = out_feats\n",
    "        self.weight = nn.Parameter(torch.Tensor(in_feats, out_feats))\n",
    "        self.bias = nn.Parameter(torch.Tensor(out_feats))\n",
    "        torch.nn.init.xavier_uniform_(self.weight)\n",
    "        torch.nn.init.zeros_(self.bias)\n",
    "\n",
    "    def forward(self, graph, feat, weight=None):\n",
    "        with graph.local_scope():\n",
    "            aggregate_fn = copy_src('h', 'm')\n",
    "            feat_src, feat_dst = expand_as_pair(feat, graph) # 获取 source 节点特征/target 节点特征\n",
    "            degs = graph.out_degrees().float().clamp(min=1)   # 计算每个节点的出度，最小为1避免出现除0\n",
    "            norm = torch.pow(degs, -0.5)      # normalized\n",
    "            shp = norm.shape + (1,) * (feat_src.dim() - 1)\n",
    "            norm = torch.reshape(norm, shp)\n",
    "            feat_src = feat_src * norm\n",
    "            weight = self.weight\n",
    "\n",
    "            #按图结构进行卷积汇聚\n",
    "            feat_src = torch.matmul(feat_src, weight)\n",
    "            graph.srcdata['h'] = feat_src    # 存在图对象graph的srcdata属性中，属性名为'h'\n",
    "            graph.update_all(aggregate_fn, fn_sum(msg='m', out='h'))  # 聚合\n",
    "            rst = graph.dstdata['h']\n",
    "\n",
    "            degs = graph.in_degrees().float().clamp(min=1)\n",
    "            norm = torch.pow(degs, -0.5)\n",
    "            shp = norm.shape + (1,) * (feat_dst.dim() - 1)\n",
    "            norm = torch.reshape(norm, shp)\n",
    "            rst = rst * norm\n",
    "            rst = rst + self.bias\n",
    "\n",
    "            return rst \n",
    "\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes, layers=2, if_ppi=False, \n",
    "                 if_activate=True, if_normal=True, if_dropout=False):\n",
    "        super(GCN, self).__init__()\n",
    "        self.if_ppi = if_ppi\n",
    "        self.layers = layers\n",
    "        self.if_activate = if_activate\n",
    "        self.if_dropout = if_dropout\n",
    "        self.if_normal = if_normal\n",
    "        if layers>2:\n",
    "            self.linears = torch.nn.ModuleList([GraphConv(h_feats, h_feats) for _ in range(layers-2)])\n",
    "        self.conv1 = GraphConv(in_feats, h_feats)\n",
    "        self.conv2 = GraphConv(h_feats, num_classes)\n",
    "        self.dropout = torch.nn.Dropout(p=0.5, inplace=False)\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        if self.if_activate:\n",
    "            h = F.relu(h)\n",
    "        if self.layers > 2:\n",
    "            for i, l in enumerate(self.linears):\n",
    "                h = l(g, h)\n",
    "        if self.if_activate:\n",
    "            h = F.relu(h)\n",
    "        if self.if_dropout:\n",
    "            h = self.dropout(h)\n",
    "        if self.if_normal:\n",
    "            h = torch.nn.functional.normalize(h)\n",
    "        h = self.conv2(g, h)\n",
    "        if self.if_ppi:\n",
    "            h = torch.nn.Sigmoid()(h)\n",
    "        return h\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(g, model, epochs=50, print_epoch=5, lr=0.01, if_ppi=False, print_loss=True):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    best_val_acc = 0\n",
    "    best_test_acc = 0\n",
    "    all_loss = []\n",
    "    all_acc = []\n",
    "    features = g.ndata['feat']\n",
    "    labels = g.ndata['label']\n",
    "    train_mask = g.ndata['train_mask']\n",
    "    val_mask = g.ndata['val_mask']\n",
    "    test_mask = g.ndata['test_mask']\n",
    "    for e in range(epochs):\n",
    "        # Forward\n",
    "        logits = model(g, features)\n",
    "\n",
    "        # Compute prediction\n",
    "        if not if_ppi:\n",
    "            pred = logits.argmax(1)\n",
    "            # Compute loss\n",
    "            # Note that you should only compute the losses of the nodes in the training set.\n",
    "            loss = F.cross_entropy(logits[train_mask], labels[train_mask])\n",
    "\n",
    "            # Compute accuracy on training/validation/test\n",
    "        else:\n",
    "            loss = F.binary_cross_entropy(logits[train_mask], labels[train_mask])\n",
    "            pred = (logits>=0.5) * 1.0\n",
    "\n",
    "        all_loss.append(loss.detach().numpy())\n",
    "        train_acc = (pred[train_mask] == labels[train_mask]).float().mean()\n",
    "        val_acc = (pred[val_mask] == labels[val_mask]).float().mean()\n",
    "        test_acc = (pred[test_mask] == labels[test_mask]).float().mean()\n",
    "        all_acc.append(train_acc)  \n",
    "        # Save the best validation accuracy and the corresponding test accuracy.\n",
    "        if best_val_acc < val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_acc = test_acc\n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if e % print_epoch == 0:\n",
    "            print('In epoch {}, loss: {:.3f}, val acc: {:.3f} (best {:.3f}), test acc: {:.3f} (best {:.3f})'.format(\n",
    "                e, loss, val_acc, best_val_acc, test_acc, best_test_acc))\n",
    "    if print_loss:\n",
    "        plt.plot(all_loss, color=\"blue\")\n",
    "        plt.plot(all_acc, color=\"red\")\n",
    "        plt.show()  \n",
    "    return best_val_acc, best_test_acc\n",
    "# dataset = dgl.data.CoraGraphDataset(reverse_edge=False)\n",
    "# G = dataset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers 2 hidden_features 16 if_activate True if_normal True if_dropout True\n",
      "In epoch 0, loss: 1.946, val acc: 0.151 (best 0.151), test acc: 0.229 (best 0.229)\n",
      "In epoch 50, loss: 1.058, val acc: 0.686 (best 0.738), test acc: 0.727 (best 0.694)\n",
      "In epoch 100, loss: 0.736, val acc: 0.782 (best 0.797), test acc: 0.705 (best 0.694)\n",
      "\n",
      "layers 2 hidden_features 16 if_activate True if_normal True if_dropout False\n",
      "In epoch 0, loss: 1.920, val acc: 0.155 (best 0.155), test acc: 0.162 (best 0.162)\n",
      "In epoch 50, loss: 0.775, val acc: 0.819 (best 0.834), test acc: 0.793 (best 0.786)\n",
      "In epoch 100, loss: 0.465, val acc: 0.827 (best 0.834), test acc: 0.797 (best 0.786)\n",
      "\n",
      "layers 2 hidden_features 16 if_activate True if_normal False if_dropout True\n",
      "In epoch 0, loss: 1.961, val acc: 0.074 (best 0.074), test acc: 0.077 (best 0.077)\n",
      "In epoch 50, loss: 0.320, val acc: 0.819 (best 0.852), test acc: 0.801 (best 0.793)\n",
      "In epoch 100, loss: 0.214, val acc: 0.823 (best 0.856), test acc: 0.760 (best 0.815)\n",
      "\n",
      "layers 2 hidden_features 16 if_activate True if_normal False if_dropout False\n",
      "In epoch 0, loss: 1.953, val acc: 0.140 (best 0.140), test acc: 0.188 (best 0.188)\n",
      "In epoch 50, loss: 0.143, val acc: 0.867 (best 0.875), test acc: 0.827 (best 0.834)\n",
      "In epoch 100, loss: 0.066, val acc: 0.849 (best 0.875), test acc: 0.804 (best 0.834)\n",
      "\n",
      "layers 2 hidden_features 16 if_activate False if_normal True if_dropout True\n",
      "In epoch 0, loss: 1.968, val acc: 0.144 (best 0.144), test acc: 0.111 (best 0.111)\n",
      "In epoch 50, loss: 0.815, val acc: 0.808 (best 0.852), test acc: 0.775 (best 0.812)\n",
      "In epoch 100, loss: 0.496, val acc: 0.815 (best 0.852), test acc: 0.756 (best 0.812)\n",
      "\n",
      "layers 2 hidden_features 16 if_activate False if_normal True if_dropout False\n",
      "In epoch 0, loss: 2.022, val acc: 0.092 (best 0.092), test acc: 0.066 (best 0.066)\n",
      "In epoch 50, loss: 0.584, val acc: 0.852 (best 0.871), test acc: 0.808 (best 0.834)\n",
      "In epoch 100, loss: 0.319, val acc: 0.841 (best 0.871), test acc: 0.801 (best 0.834)\n",
      "\n",
      "layers 2 hidden_features 16 if_activate False if_normal False if_dropout True\n",
      "In epoch 0, loss: 1.937, val acc: 0.166 (best 0.166), test acc: 0.144 (best 0.144)\n",
      "In epoch 50, loss: 0.198, val acc: 0.852 (best 0.867), test acc: 0.823 (best 0.827)\n",
      "In epoch 100, loss: 0.121, val acc: 0.834 (best 0.875), test acc: 0.797 (best 0.793)\n",
      "\n",
      "layers 2 hidden_features 16 if_activate False if_normal False if_dropout False\n",
      "In epoch 0, loss: 1.965, val acc: 0.159 (best 0.159), test acc: 0.125 (best 0.125)\n",
      "In epoch 50, loss: 0.141, val acc: 0.867 (best 0.871), test acc: 0.808 (best 0.823)\n",
      "In epoch 100, loss: 0.067, val acc: 0.845 (best 0.871), test acc: 0.801 (best 0.823)\n",
      "\n",
      "layers 5 hidden_features 16 if_activate True if_normal True if_dropout True\n",
      "In epoch 0, loss: 1.942, val acc: 0.148 (best 0.148), test acc: 0.177 (best 0.177)\n",
      "In epoch 50, loss: 1.149, val acc: 0.616 (best 0.679), test acc: 0.675 (best 0.679)\n",
      "In epoch 100, loss: 0.820, val acc: 0.734 (best 0.760), test acc: 0.727 (best 0.723)\n",
      "\n",
      "layers 5 hidden_features 16 if_activate True if_normal True if_dropout False\n",
      "In epoch 0, loss: 2.008, val acc: 0.103 (best 0.103), test acc: 0.089 (best 0.089)\n",
      "In epoch 50, loss: 0.982, val acc: 0.738 (best 0.738), test acc: 0.756 (best 0.738)\n",
      "In epoch 100, loss: 0.566, val acc: 0.801 (best 0.819), test acc: 0.764 (best 0.779)\n",
      "\n",
      "layers 5 hidden_features 16 if_activate True if_normal False if_dropout True\n",
      "In epoch 0, loss: 1.950, val acc: 0.074 (best 0.074), test acc: 0.063 (best 0.063)\n",
      "In epoch 50, loss: 0.354, val acc: 0.815 (best 0.827), test acc: 0.756 (best 0.731)\n",
      "In epoch 100, loss: 0.241, val acc: 0.819 (best 0.838), test acc: 0.756 (best 0.775)\n",
      "\n",
      "layers 5 hidden_features 16 if_activate True if_normal False if_dropout False\n",
      "In epoch 0, loss: 1.944, val acc: 0.129 (best 0.129), test acc: 0.162 (best 0.162)\n",
      "In epoch 50, loss: 0.195, val acc: 0.834 (best 0.849), test acc: 0.812 (best 0.812)\n",
      "In epoch 100, loss: 0.102, val acc: 0.830 (best 0.852), test acc: 0.779 (best 0.808)\n",
      "\n",
      "layers 5 hidden_features 16 if_activate False if_normal True if_dropout True\n",
      "In epoch 0, loss: 1.995, val acc: 0.103 (best 0.103), test acc: 0.085 (best 0.085)\n",
      "In epoch 50, loss: 0.928, val acc: 0.782 (best 0.797), test acc: 0.764 (best 0.756)\n",
      "In epoch 100, loss: 0.600, val acc: 0.775 (best 0.830), test acc: 0.760 (best 0.756)\n",
      "\n",
      "layers 5 hidden_features 16 if_activate False if_normal True if_dropout False\n",
      "In epoch 0, loss: 1.992, val acc: 0.081 (best 0.081), test acc: 0.063 (best 0.063)\n",
      "In epoch 50, loss: 0.673, val acc: 0.815 (best 0.830), test acc: 0.771 (best 0.797)\n",
      "In epoch 100, loss: 0.391, val acc: 0.830 (best 0.841), test acc: 0.782 (best 0.793)\n",
      "\n",
      "layers 5 hidden_features 16 if_activate False if_normal False if_dropout True\n",
      "In epoch 0, loss: 1.971, val acc: 0.081 (best 0.081), test acc: 0.111 (best 0.111)\n",
      "In epoch 50, loss: 0.266, val acc: 0.827 (best 0.867), test acc: 0.808 (best 0.801)\n",
      "In epoch 100, loss: 0.177, val acc: 0.830 (best 0.867), test acc: 0.808 (best 0.801)\n",
      "\n",
      "layers 5 hidden_features 16 if_activate False if_normal False if_dropout False\n",
      "In epoch 0, loss: 1.955, val acc: 0.144 (best 0.144), test acc: 0.155 (best 0.155)\n",
      "In epoch 50, loss: 0.167, val acc: 0.863 (best 0.871), test acc: 0.830 (best 0.797)\n",
      "In epoch 100, loss: 0.084, val acc: 0.838 (best 0.871), test acc: 0.786 (best 0.797)\n",
      "\n",
      "layers 2 hidden_features 32 if_activate True if_normal True if_dropout True\n",
      "In epoch 0, loss: 1.956, val acc: 0.159 (best 0.159), test acc: 0.148 (best 0.148)\n",
      "In epoch 50, loss: 0.851, val acc: 0.786 (best 0.804), test acc: 0.771 (best 0.768)\n",
      "In epoch 100, loss: 0.523, val acc: 0.815 (best 0.841), test acc: 0.756 (best 0.786)\n",
      "\n",
      "layers 2 hidden_features 32 if_activate True if_normal True if_dropout False\n",
      "In epoch 0, loss: 1.912, val acc: 0.221 (best 0.221), test acc: 0.181 (best 0.181)\n",
      "In epoch 50, loss: 0.598, val acc: 0.845 (best 0.849), test acc: 0.804 (best 0.812)\n",
      "In epoch 100, loss: 0.327, val acc: 0.845 (best 0.852), test acc: 0.775 (best 0.786)\n",
      "\n",
      "layers 2 hidden_features 32 if_activate True if_normal False if_dropout True\n",
      "In epoch 0, loss: 1.946, val acc: 0.170 (best 0.170), test acc: 0.125 (best 0.125)\n",
      "In epoch 50, loss: 0.192, val acc: 0.863 (best 0.867), test acc: 0.823 (best 0.808)\n",
      "In epoch 100, loss: 0.114, val acc: 0.830 (best 0.867), test acc: 0.786 (best 0.808)\n",
      "\n",
      "layers 2 hidden_features 32 if_activate True if_normal False if_dropout False\n",
      "In epoch 0, loss: 1.939, val acc: 0.199 (best 0.199), test acc: 0.203 (best 0.203)\n",
      "In epoch 50, loss: 0.098, val acc: 0.860 (best 0.875), test acc: 0.812 (best 0.838)\n",
      "In epoch 100, loss: 0.045, val acc: 0.827 (best 0.875), test acc: 0.804 (best 0.838)\n",
      "\n",
      "layers 2 hidden_features 32 if_activate False if_normal True if_dropout True\n",
      "In epoch 0, loss: 1.939, val acc: 0.144 (best 0.144), test acc: 0.148 (best 0.148)\n",
      "In epoch 50, loss: 0.660, val acc: 0.827 (best 0.867), test acc: 0.771 (best 0.812)\n",
      "In epoch 100, loss: 0.364, val acc: 0.834 (best 0.867), test acc: 0.793 (best 0.812)\n",
      "\n",
      "layers 2 hidden_features 32 if_activate False if_normal True if_dropout False\n",
      "In epoch 0, loss: 1.985, val acc: 0.118 (best 0.118), test acc: 0.140 (best 0.140)\n",
      "In epoch 50, loss: 0.428, val acc: 0.856 (best 0.871), test acc: 0.804 (best 0.823)\n",
      "In epoch 100, loss: 0.221, val acc: 0.849 (best 0.871), test acc: 0.786 (best 0.823)\n",
      "\n",
      "layers 2 hidden_features 32 if_activate False if_normal False if_dropout True\n",
      "In epoch 0, loss: 1.946, val acc: 0.148 (best 0.148), test acc: 0.100 (best 0.100)\n",
      "In epoch 50, loss: 0.134, val acc: 0.863 (best 0.886), test acc: 0.804 (best 0.830)\n",
      "In epoch 100, loss: 0.072, val acc: 0.834 (best 0.886), test acc: 0.786 (best 0.830)\n",
      "\n",
      "layers 2 hidden_features 32 if_activate False if_normal False if_dropout False\n",
      "In epoch 0, loss: 1.954, val acc: 0.129 (best 0.129), test acc: 0.159 (best 0.159)\n",
      "In epoch 50, loss: 0.094, val acc: 0.863 (best 0.871), test acc: 0.790 (best 0.823)\n",
      "In epoch 100, loss: 0.043, val acc: 0.849 (best 0.871), test acc: 0.801 (best 0.823)\n",
      "\n",
      "layers 5 hidden_features 32 if_activate True if_normal True if_dropout True\n",
      "In epoch 0, loss: 1.964, val acc: 0.118 (best 0.118), test acc: 0.103 (best 0.103)\n",
      "In epoch 50, loss: 0.971, val acc: 0.771 (best 0.771), test acc: 0.738 (best 0.738)\n",
      "In epoch 100, loss: 0.595, val acc: 0.786 (best 0.812), test acc: 0.782 (best 0.771)\n",
      "\n",
      "layers 5 hidden_features 32 if_activate True if_normal True if_dropout False\n",
      "In epoch 0, loss: 1.990, val acc: 0.048 (best 0.048), test acc: 0.085 (best 0.085)\n",
      "In epoch 50, loss: 0.765, val acc: 0.782 (best 0.793), test acc: 0.786 (best 0.764)\n",
      "In epoch 100, loss: 0.393, val acc: 0.808 (best 0.823), test acc: 0.786 (best 0.819)\n",
      "\n",
      "layers 5 hidden_features 32 if_activate True if_normal False if_dropout True\n",
      "In epoch 0, loss: 1.951, val acc: 0.070 (best 0.070), test acc: 0.074 (best 0.074)\n",
      "In epoch 50, loss: 0.218, val acc: 0.834 (best 0.856), test acc: 0.786 (best 0.786)\n",
      "In epoch 100, loss: 0.129, val acc: 0.819 (best 0.856), test acc: 0.790 (best 0.786)\n",
      "\n",
      "layers 5 hidden_features 32 if_activate True if_normal False if_dropout False\n",
      "In epoch 0, loss: 1.932, val acc: 0.299 (best 0.299), test acc: 0.365 (best 0.365)\n",
      "In epoch 50, loss: 0.163, val acc: 0.863 (best 0.867), test acc: 0.808 (best 0.804)\n",
      "In epoch 100, loss: 0.124, val acc: 0.841 (best 0.867), test acc: 0.782 (best 0.804)\n",
      "\n",
      "layers 5 hidden_features 32 if_activate False if_normal True if_dropout True\n",
      "In epoch 0, loss: 1.960, val acc: 0.162 (best 0.162), test acc: 0.092 (best 0.092)\n",
      "In epoch 50, loss: 0.722, val acc: 0.838 (best 0.845), test acc: 0.790 (best 0.804)\n",
      "In epoch 100, loss: 0.429, val acc: 0.801 (best 0.845), test acc: 0.804 (best 0.804)\n",
      "\n",
      "layers 5 hidden_features 32 if_activate False if_normal True if_dropout False\n",
      "In epoch 0, loss: 1.957, val acc: 0.129 (best 0.129), test acc: 0.096 (best 0.096)\n",
      "In epoch 50, loss: 0.525, val acc: 0.838 (best 0.845), test acc: 0.801 (best 0.808)\n",
      "In epoch 100, loss: 0.286, val acc: 0.827 (best 0.849), test acc: 0.782 (best 0.804)\n",
      "\n",
      "layers 5 hidden_features 32 if_activate False if_normal False if_dropout True\n",
      "In epoch 0, loss: 1.941, val acc: 0.192 (best 0.192), test acc: 0.151 (best 0.151)\n",
      "In epoch 50, loss: 0.177, val acc: 0.871 (best 0.886), test acc: 0.797 (best 0.812)\n",
      "In epoch 100, loss: 0.123, val acc: 0.841 (best 0.886), test acc: 0.782 (best 0.812)\n",
      "\n",
      "layers 5 hidden_features 32 if_activate False if_normal False if_dropout False\n",
      "In epoch 0, loss: 1.951, val acc: 0.129 (best 0.129), test acc: 0.111 (best 0.111)\n",
      "In epoch 50, loss: 0.138, val acc: 0.863 (best 0.878), test acc: 0.815 (best 0.804)\n",
      "In epoch 100, loss: 0.068, val acc: 0.849 (best 0.878), test acc: 0.768 (best 0.804)\n",
      "\n",
      "layers 2 hidden_features 64 if_activate True if_normal True if_dropout True\n",
      "In epoch 0, loss: 1.948, val acc: 0.103 (best 0.103), test acc: 0.092 (best 0.092)\n",
      "In epoch 50, loss: 0.679, val acc: 0.830 (best 0.849), test acc: 0.797 (best 0.797)\n",
      "In epoch 100, loss: 0.369, val acc: 0.838 (best 0.849), test acc: 0.782 (best 0.797)\n",
      "\n",
      "layers 2 hidden_features 64 if_activate True if_normal True if_dropout False\n",
      "In epoch 0, loss: 1.958, val acc: 0.166 (best 0.166), test acc: 0.137 (best 0.137)\n",
      "In epoch 50, loss: 0.454, val acc: 0.849 (best 0.867), test acc: 0.793 (best 0.808)\n",
      "In epoch 100, loss: 0.231, val acc: 0.841 (best 0.867), test acc: 0.779 (best 0.808)\n",
      "\n",
      "layers 2 hidden_features 64 if_activate True if_normal False if_dropout True\n",
      "In epoch 0, loss: 1.924, val acc: 0.203 (best 0.203), test acc: 0.269 (best 0.269)\n",
      "In epoch 50, loss: 0.121, val acc: 0.860 (best 0.882), test acc: 0.797 (best 0.830)\n",
      "In epoch 100, loss: 0.069, val acc: 0.849 (best 0.882), test acc: 0.804 (best 0.830)\n",
      "\n",
      "layers 2 hidden_features 64 if_activate True if_normal False if_dropout False\n",
      "In epoch 0, loss: 1.935, val acc: 0.214 (best 0.214), test acc: 0.177 (best 0.177)\n",
      "In epoch 50, loss: 0.067, val acc: 0.849 (best 0.867), test acc: 0.790 (best 0.830)\n",
      "In epoch 100, loss: 0.029, val acc: 0.827 (best 0.867), test acc: 0.801 (best 0.830)\n",
      "\n",
      "layers 2 hidden_features 64 if_activate False if_normal True if_dropout True\n",
      "In epoch 0, loss: 1.946, val acc: 0.155 (best 0.155), test acc: 0.166 (best 0.166)\n",
      "In epoch 50, loss: 0.478, val acc: 0.849 (best 0.867), test acc: 0.808 (best 0.819)\n",
      "In epoch 100, loss: 0.245, val acc: 0.834 (best 0.867), test acc: 0.786 (best 0.819)\n",
      "\n",
      "layers 2 hidden_features 64 if_activate False if_normal True if_dropout False\n",
      "In epoch 0, loss: 1.957, val acc: 0.125 (best 0.125), test acc: 0.118 (best 0.118)\n",
      "In epoch 50, loss: 0.315, val acc: 0.856 (best 0.886), test acc: 0.808 (best 0.808)\n",
      "In epoch 100, loss: 0.157, val acc: 0.841 (best 0.886), test acc: 0.790 (best 0.808)\n",
      "\n",
      "layers 2 hidden_features 64 if_activate False if_normal False if_dropout True\n",
      "In epoch 0, loss: 1.981, val acc: 0.081 (best 0.081), test acc: 0.066 (best 0.066)\n",
      "In epoch 50, loss: 0.093, val acc: 0.860 (best 0.871), test acc: 0.808 (best 0.841)\n",
      "In epoch 100, loss: 0.048, val acc: 0.860 (best 0.875), test acc: 0.786 (best 0.797)\n",
      "\n",
      "layers 2 hidden_features 64 if_activate False if_normal False if_dropout False\n",
      "In epoch 0, loss: 1.947, val acc: 0.166 (best 0.166), test acc: 0.181 (best 0.181)\n",
      "In epoch 50, loss: 0.071, val acc: 0.860 (best 0.871), test acc: 0.797 (best 0.790)\n",
      "In epoch 100, loss: 0.032, val acc: 0.827 (best 0.871), test acc: 0.793 (best 0.790)\n",
      "\n",
      "layers 5 hidden_features 64 if_activate True if_normal True if_dropout True\n",
      "In epoch 0, loss: 1.950, val acc: 0.133 (best 0.133), test acc: 0.140 (best 0.140)\n",
      "In epoch 50, loss: 0.737, val acc: 0.812 (best 0.815), test acc: 0.782 (best 0.775)\n",
      "In epoch 100, loss: 0.409, val acc: 0.804 (best 0.830), test acc: 0.760 (best 0.753)\n",
      "\n",
      "layers 5 hidden_features 64 if_activate True if_normal True if_dropout False\n",
      "In epoch 0, loss: 1.935, val acc: 0.177 (best 0.177), test acc: 0.144 (best 0.144)\n",
      "In epoch 50, loss: 0.518, val acc: 0.823 (best 0.834), test acc: 0.801 (best 0.793)\n",
      "In epoch 100, loss: 0.278, val acc: 0.801 (best 0.834), test acc: 0.775 (best 0.793)\n",
      "\n",
      "layers 5 hidden_features 64 if_activate True if_normal False if_dropout True\n",
      "In epoch 0, loss: 1.946, val acc: 0.133 (best 0.133), test acc: 0.151 (best 0.151)\n",
      "In epoch 50, loss: 0.170, val acc: 0.860 (best 0.860), test acc: 0.801 (best 0.764)\n",
      "In epoch 100, loss: 0.094, val acc: 0.827 (best 0.860), test acc: 0.768 (best 0.764)\n",
      "\n",
      "layers 5 hidden_features 64 if_activate True if_normal False if_dropout False\n",
      "In epoch 0, loss: 1.939, val acc: 0.173 (best 0.173), test acc: 0.185 (best 0.185)\n",
      "In epoch 50, loss: 0.129, val acc: 0.860 (best 0.878), test acc: 0.797 (best 0.804)\n",
      "In epoch 100, loss: 0.067, val acc: 0.830 (best 0.878), test acc: 0.782 (best 0.804)\n",
      "\n",
      "layers 5 hidden_features 64 if_activate False if_normal True if_dropout True\n",
      "In epoch 0, loss: 1.933, val acc: 0.185 (best 0.185), test acc: 0.236 (best 0.236)\n",
      "In epoch 50, loss: 0.534, val acc: 0.838 (best 0.871), test acc: 0.786 (best 0.804)\n",
      "In epoch 100, loss: 0.297, val acc: 0.823 (best 0.871), test acc: 0.775 (best 0.804)\n",
      "\n",
      "layers 5 hidden_features 64 if_activate False if_normal True if_dropout False\n",
      "In epoch 0, loss: 1.928, val acc: 0.229 (best 0.229), test acc: 0.210 (best 0.210)\n",
      "In epoch 50, loss: 0.388, val acc: 0.856 (best 0.867), test acc: 0.790 (best 0.819)\n",
      "In epoch 100, loss: 0.224, val acc: 0.845 (best 0.867), test acc: 0.797 (best 0.819)\n",
      "\n",
      "layers 5 hidden_features 64 if_activate False if_normal False if_dropout True\n",
      "In epoch 0, loss: 1.954, val acc: 0.173 (best 0.173), test acc: 0.118 (best 0.118)\n",
      "In epoch 50, loss: 0.145, val acc: 0.838 (best 0.882), test acc: 0.812 (best 0.797)\n",
      "In epoch 100, loss: 0.089, val acc: 0.827 (best 0.882), test acc: 0.782 (best 0.797)\n",
      "\n",
      "layers 5 hidden_features 64 if_activate False if_normal False if_dropout False\n",
      "In epoch 0, loss: 1.946, val acc: 0.188 (best 0.188), test acc: 0.170 (best 0.170)\n",
      "In epoch 50, loss: 0.129, val acc: 0.849 (best 0.875), test acc: 0.801 (best 0.797)\n",
      "In epoch 100, loss: 0.075, val acc: 0.834 (best 0.875), test acc: 0.768 (best 0.797)\n",
      "\n",
      "Best Parameter\n",
      "{'loop': None, 'layers': 2, 'if_activate': False, 'if_normal': False, 'if_dropout': True, 'acc': tensor(0.8856)}\n",
      "In epoch 0, loss: 1.970, val acc: 0.125 (best 0.125), test acc: 0.125 (best 0.125)\n",
      "In epoch 25, loss: 0.182, val acc: 0.878 (best 0.878), test acc: 0.815 (best 0.815)\n",
      "In epoch 50, loss: 0.090, val acc: 0.871 (best 0.878), test acc: 0.808 (best 0.815)\n",
      "In epoch 75, loss: 0.061, val acc: 0.845 (best 0.878), test acc: 0.797 (best 0.815)\n",
      "In epoch 100, loss: 0.046, val acc: 0.838 (best 0.878), test acc: 0.797 (best 0.815)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAmjklEQVR4nO3de3RddZ338fc3TZqmTe9J09I7tFQKlsKEqzjghQIiMM7gDBUVL0zHZ2TEGZ1ndFyjPug8y1GXzqiM2ME+6DgDKCAWLFRUGFQuQ8pwaaFAKbRN2tL0kvSStrn0+/zxPcdzmibNSXpOTrrP57XWXidnX38nJ/ns3/7t397b3B0REUmusmIXQERECktBLyKScAp6EZGEU9CLiCScgl5EJOHKi12AntTU1PisWbOKXQwRkePGqlWrtrt7bU/ThmTQz5o1i4aGhmIXQ0TkuGFmG3qbpqYbEZGEU9CLiCRcn0FvZtPN7GEze8HM1pjZjT3MY2b2LTNbZ2bPmdmZWdOuM7NXUsN1+f4AIiJydLm00XcCn3L3p81sNLDKzB5y9xey5rkMmJsazgG+C5xjZhOALwD1gKeWXe7uu/L6KUREpFd91ujdfYu7P536eQ/wIjC122xXAT/08AQwzsymAJcAD7n7zlS4PwRcmtdPICIiR9WvNnozmwWcATzZbdJUYFPW+8bUuN7G97TuJWbWYGYNzc3N/SmWiIgcRc5Bb2bVwN3AJ919d74L4u5L3b3e3etra3vsCioiIgOQU9CbWQUR8v/h7vf0MEsTMD3r/bTUuN7G5507fPnLsHJlIdYuInL8yqXXjQHfB15092/0Mtty4IOp3jfnAq3uvgVYCSwys/FmNh5YlBqXd2bw9a/DihWFWLuIyPErl143bwE+ADxvZs+kxv09MAPA3W8BVgDvAtYBbcCHU9N2mtmXgKdSy93k7jvzVvpuamtBzfsiIofrM+jd/beA9TGPAx/vZdoyYNmAStdPkybBtm2DsSURkeNHoq6MVdCLiBwpUUFfW6ugFxHpLlFBP2kSbN8Ohw4VuyQiIkNH4oK+qwt26QYLIiK/l7igBzXfiIhkS1TQpy+oVRdLEZGMRAW9avQiIkdS0IuIJFyign7ixHhV042ISEaigr68PMJeNXoRkYxEBT3o6lgRke4SF/S6OlZE5HCJC/pJk9RGLyKSLZFBrxq9iEhG4oK+thZ27IDOzmKXRERkaEhc0Kf70u/YUdxyiIgMFYkNejXfiIiEPp8wZWbLgHcD29z9tB6m/y1wbdb6TgFqU48RfB3YA3QBne5en6+C9yZ9vxsFvYhIyKVGfxtwaW8T3f1r7r7Q3RcCnwX+q9tzYd+Wml7wkIdMjV49b0REQp9B7+6PArk+0HsxcPsxlegYqelGRORweWujN7ORRM3/7qzRDvzCzFaZ2ZI+ll9iZg1m1tB8DNXx8eNh2DAFvYhIWj5Pxl4B/K5bs80F7n4mcBnwcTP7w94Wdvel7l7v7vW16Yb2ASgrg5oaNd2IiKTlM+ivoVuzjbs3pV63AT8Fzs7j9nqli6ZERDLyEvRmNha4EPhZ1rhRZjY6/TOwCFidj+31Rfe7ERHJyKV75e3ARUCNmTUCXwAqANz9ltRs7wF+4e77shatA35qZunt/Ke7P5i/ovdu0iRoaBiMLYmIDH19Br27L85hntuIbpjZ49YDpw+0YMdCNzYTEclI3JWxEEHf2goHDxa7JCIixZfIoE932lGtXkQkoUGvq2NFRDISHfTqeSMiktCg143NREQyEhn0aroREclIZNCPGQPDh6tGLyICCQ16M6irgy1bil0SEZHiS2TQA0yfDps2FbsUIiLFl9ignzEDNm4sdilERIovsUE/fTo0NoJ7sUsiIlJciQ76gwfV80ZEJLFBP2NGvKr5RkRKXWKDfvr0eNUJWREpdQp6EZGES2zQ19TAiBEKehGRPoPezJaZ2TYz6/ExgGZ2kZm1mtkzqeHzWdMuNbOXzGydmX0mnwXvi1nU6tVGLyKlLpca/W3ApX3M8xt3X5gabgIws2HAzcBlwHxgsZnNP5bC9pcumhIRySHo3f1RYOcA1n02sM7d17t7O3AHcNUA1jNgCnoRkfy10Z9nZs+a2QNmdmpq3FQgO2YbU+MGzYwZsHkzdHYO5lZFRIaWfAT908BMdz8d+DZw70BWYmZLzKzBzBqa83SV0/TpcOhQhL2ISKk65qB3993uvjf18wqgwsxqgCZgetas01LjelvPUnevd/f62vSTQ46RuliKiOQh6M1ssplZ6uezU+vcATwFzDWz2WY2HLgGWH6s2+sPBb2ICJT3NYOZ3Q5cBNSYWSPwBaACwN1vAa4G/peZdQL7gWvc3YFOM7sBWAkMA5a5+5qCfIpepINeXSxFpJT1GfTuvriP6d8BvtPLtBXAioEV7diNGQNjx6pGLyKlLbFXxqapi6WIlLrEB/2MGQp6ESltiQ963QZBREpdSQT99u2wf3+xSyIiUhwlEfQQjxUUESlFiQ96PWlKREpd4oNeF02JSKlLfNBPmxavCnoRKVWJD/rKSqirU9ONiJSuxAc9RDu9gl5ESlVJBP3MmfD668UuhYhIcZRM0G/cCO7FLomIyOAriaCfNQsOHIBt24pdEhGRwVcSQT9zZrxu2FDccoiIFIOCXkQk4Uoq6HVCVkRKUUkE/dixMahGLyKlqM+gN7NlZrbNzFb3Mv1aM3vOzJ43s8fM7PSsaa+nxj9jZg35LHh/zZqloBeR0pRLjf424NKjTH8NuNDd3wx8CVjabfrb3H2hu9cPrIj5MXOmgl5ESlOfQe/ujwI7jzL9MXfflXr7BDAtT2XLq/RFU+pLLyKlJt9t9B8FHsh678AvzGyVmS052oJmtsTMGsysobm5Oc/FiqDfswdaWvK+ahGRIa08Xysys7cRQX9B1ugL3L3JzCYBD5nZ2tQRwhHcfSmpZp/6+vq817uzu1iOH5/vtYuIDF15qdGb2QLgVuAqd9+RHu/uTanXbcBPgbPzsb2BmDUrXtVOLyKl5piD3sxmAPcAH3D3l7PGjzKz0emfgUVAjz13BoP60otIqeqz6cbMbgcuAmrMrBH4AlAB4O63AJ8HJgL/amYAnakeNnXAT1PjyoH/dPcHC/AZclJTA1VVqtGLSOnpM+jdfXEf068Hru9h/Hrg9COXKA4zdbEUkdJUElfGpumiKREpRSUV9HoAiYiUopIL+h07YN++YpdERGTwlFzQg5pvRKS0KOhFRBKupII+fdGU2ulFpJSUVNBPmQIVFarRi0hpKamgLyuD6dNVoxeR0lJSQQ8wZw688kqxSyEiMnhKLujnzYOXX9Z96UWkdJRk0O/dC1u2FLskIiKDoySDHuCll4pbDhGRwVJyQX/yyfGqoBeRUlFyQT9tWtyuWEEvIqWi5IK+rCxq9S+/3Pe8IiJJUHJBD9FOrxq9iJSKkgz6k0+G116DgweLXRIRkcLLKejNbJmZbTOzHp/5auFbZrbOzJ4zszOzpl1nZq+khuvyVfBjMW8eHDoEr75a7JKIiBRerjX624BLjzL9MmBualgCfBfAzCYQz5g9Bzgb+IKZjR9oYfMl3cVS7fQiUgpyCnp3fxTYeZRZrgJ+6OEJYJyZTQEuAR5y953uvgt4iKPvMAaFuliKSCnp8+HgOZoKbMp635ga19v4I5jZEuJogBkzZuSpWD0bOxbq6hT0IkXR1QUtLXDgQAwA48bFP2Z5ebSrHjwI+/dn5unogGHDYnp5OYwYEUNFBbS3xzz798cj5JqbobU11ldTE+tua4tt7t4dy1VXw8iRsZ29e2HPnlhu61bYti3mqamJoaoqs93KyphWWRnvIe6n0tmZKatZpnxtbbHOrVsPf7TdyJHR13vatJgvPU9HB3zsY3n/lecr6I+Zuy8FlgLU19cX/E406nkjeXfgAKxbB7t2RZBUV0d4/Nd/wSOPRIDU18O558JJJ2WCpbU1EyDV1TB1agTAqFGwZg0880zcic8sEzZTpsQ8tbWxnsbGGNKBsX17rKumBiZOjHWNGAHDh0eobd8eoZgdShCB1dERoblnT4Tg8OERluPHZ9YzYkQEV3p7e/bEsp2dh99IqqoKJk+OmpV7nBhbvz7CuScVFbH9Yqquju+ys3Pwtz1hwpAO+iZgetb7aalxTcBF3cY/kqdtHpN58+CnPy12KWTA2tpg9Wp48cWoHdXURBB1dEQ47d2bqWG1tcEbb0QQbt4c4VZdHaHV2ZmZf+fOCMDt22N8uhY3cmQE3bhxsVw66NwzYbh5c3TlOnSo5/KedhqccALcfTfcemv/P+/UqXERSGdnhHBLy5HzTJgQ26irgzPPjHJt3x7Bmq4dt7fD6NHx+5owIZZrbY3fT1lZ5jNXVcUj2UaNit9pS0vM09aWqT1XVcUO501vinVWVMSyZVktwnv3xnKbNsXva/58uPLKKOfIkZnfY2trDG1tmd9vZWVsI11z7+qKz9/eHjXx9OdJ7ySrqmKnVlMTtfnW1vj86R3vuHFRzvb2KNe+fZmda3V17DTr6mI97lH737EjE/odHYcfPWR/1xUVmTJDZp4RI+J3NHlybMMspu/eDU1N8Td58GBmZ1hX1/+/jRzkK+iXAzeY2R3EiddWd99iZiuB/5t1AnYR8Nk8bfOYzJsXfwM7d2b+3iWP3OMfc+fOqJWuXg0bN2YOv7u6ooa7dWv80U+enKmhtrRkArelJYY9ezJB1NkZDxXoLVR7U1cXAWOWOVyvqIh//lGjIiROPjleKysz/9zpw/70kN3kMHp0/AP/wR/AtddG6NXURIjs2xdhdsEF8bnSv5dXXonfRV1dfO5x4zIBkh0Au3dHMC5YAGPGHP5Z9u+P+ZqbY91Tp0ZASX6Yxc5i7NjCrH/8+BhOO60w6+8mp6A3s9uJmnmNmTUSPWkqANz9FmAF8C5gHdAGfDg1baeZfQl4KrWqm9z9aCd1B032CdnzzituWYaMPXsyTQAQITR5cvzRZ7czpmt9u3fHofi6dfHYrvQ8u3ZFkHeXru10dsY600E3enTsCB54INZfWRnhNXFi/DOcdFLMk17WHT7wAVi4MIKwvT2z1x4+PFNbT9cYR4yI9Q0fPii/xqMyiz++9B9gWkVFZmcze3bf66mqiocrzJlTmHJKouQU9O6+uI/pDny8l2nLgGX9L1phZd/FMhFB39UVh8jpJodhwzIniTo6oga5dm184L17Yxn3qBG+/noMra0D2/bkyfFA3jlzovY6fnyEanl5BPSpp0bNpa4uc+jaE/c4jK2sPPp8ItIvQ+Zk7GCbPTty6LjqS3/oEDz+OPz851FzbmmJ2vOmTRHkuZzEGjny8MPRiRMjpN/61njO4rRpmfbgrVszN+5P1+6rqzNtpSNHRm27ujo/ny99YlBE8qpkg76iIjJq7doiFmLv3mjyeOONTFewCROiNlxREWH6wgvR6+LJJ+FnP4vgraiI2nH6BOFZZ8F73wszZhzetpzdHW3q1Gg/Toe4iJSMkg16iBaF558fpI3t2RPNJumudk8+Gc0muRo1Ci65BK6+Gi6//MiTcyIivSjpoD/99OhiuW9f5Ogx2b8fHnwwus899dThPUSamiLo004+Ga64AubOjWaTyZPjxGa6b3NHR6YP77x5cdJxzpyooYuI9FPJB7171OrPPbePmd2jr/SmTZludps3Ry197VpYtSr2GBMnwoUXRih3dsbrokXR9j1rFrzlLdHFT0RkkJR80AM8+2wvQf/GG/Dtb8PKlRHm6d4q2Wpqou37Qx+C97wnQr68pH+tIjLElHQizZwZTd3PPtttwsaN8JWvwLJl0Uf7oovgIx+JQJ81K7oPjhuX6estIjKElXTQm8VFh4cF/Z13wpIlcZXiddfBpz995MUtIiLHkZLvZ3f66fDcc3Bozz64/nq45projrN2LSxdqpAXkeNeSdfoIYL+4N522i9axIj/eRz+/u/hi1+MvuoiIgmgoD8dvs6nGfH0Y3D77VGjFxFJEDXdvHA7n+DbPHbu3yjkRSSRSjvo16yh8uPX01B1Ad+Y9JVil0ZEpCBKu+nmYx+D0aO59ew7efp5tcmLSDKVbo1+61b47W/hhhuYce4JvPZa3IVARCRpSjfof/7zeL3iit9fIfvcc8UrjohIoeQU9GZ2qZm9ZGbrzOwzPUz/ppk9kxpeNrOWrGldWdOW57Hsx+a+++L+6wsWsGBBjDriClkRkQTos43ezIYBNwMXA43AU2a23N1fSM/j7n+dNf9fAWdkrWK/uy/MW4nz4cABeOihuD+NGdOmxV0NVKMXkSTKpUZ/NrDO3de7eztwB3DVUeZfDNyej8IVzK9/HQ98vuIKIG6FsHAhPP10cYslIlIIuQT9VGBT1vvG1LgjmNlMYDbw66zRI8yswcyeMLM/GmhB8+q+++IG9Bdd9PtR550XD3JqaytaqURECiLfJ2OvAe5y966scTPdvR54H/DPZnZSTwua2ZLUDqGhuT9PXuovd7j//rhHfNbzSc8/P24f39BQuE2LiBRDLkHfBEzPej8tNa4n19Ct2cbdm1Kv64FHOLz9Pnu+pe5e7+71tbW1ORRrgJ55Bhobf99sk5a+H/1jjxVu0yIixZBL0D8FzDWz2WY2nAjzI3rPmNmbgPHA41njxptZZernGuAtwAvdlx1U990XjfKXX37Y6IkT43bzCnoRSZo+g97dO4EbgJXAi8CP3X2Nmd1kZldmzXoNcIe7e9a4U4AGM3sWeBj4SnZvnaJYsQLOOQcmTTpi0vnnR9Af9glERI5zOd0Cwd1XACu6jft8t/df7GG5x4A3H0P58uvQoehD+bGP9Tj5/PPjoVIvvxzP5BYRSYLSujJ2wwbYvx/mz+9x8vnnx6uab0QkSUor6F9ItRr1EvTz5sWFUwp6EUmS0gz6U07pcXJZWfSnV9CLSJKUXtBPmRLV9l6cf37MtmvXIJZLRKSASi/oe2m2SUu30z/xxCCUR0RkEJRO0LvnFPRnnQXDhqn5RkSSo3SCvrER9u7tM+irq+OB4b/97SCVS0SkwEon6PvocZPt7W+H3/1OT5wSkWRQ0PfgyiuhowNWrixwmUREBkFpBX1tLdTU9DnreefBhAmwfOg8D0tEZMBKK+hzqM0DlJfHPc9WrIhbF4uIHM9KI+hz7HGT7YorYOdO9b4RkeNfaQT91q3Q0tKvoL/kEqioiLsai4gcz0oj6PtxIjZtzJh40qDa6UXkeKegP4orr4xbFr/0UgHKJCIySEon6MePh7q6fi2Wftqgmm9E5HhWOkE/f348QrAfZs6EBQvg3nsLUywRkcGQU9Cb2aVm9pKZrTOzz/Qw/UNm1mxmz6SG67OmXWdmr6SG6/JZ+Jy4w5o1/W62SVu8OK6SXb06z+USERkkfQa9mQ0DbgYuA+YDi82sp9S8090XpoZbU8tOAL4AnAOcDXzBzHq/R3AhbNsGO3bAqacOaPE//3OoqoJ/+Zc8l0tEZJDkUqM/G1jn7uvdvR24A7gqx/VfAjzk7jvdfRfwEHDpwIo6QGvWxOsAg37iRHj/++FHP4Lt2/NYLhGRQZJL0E8FNmW9b0yN6+5PzOw5M7vLzKb3c1nMbImZNZhZQ3Nzcw7FytExBj3AjTfCgQOwdGmeyiQiMojydTL2PmCWuy8gau0/6O8K3H2pu9e7e31tbW2eikUE/fjxMHnygFdx6qnwznfCzTfHzc5ERI4nuQR9EzA96/201Ljfc/cd7n4w9fZW4A9yXbbg1qyJpO5nj5vuPvlJ2LwZ7rorP8USERksuQT9U8BcM5ttZsOBa4DDrhc1sylZb68EXkz9vBJYZGbjUydhF6XGDY50j5tjaLZJu+wymDsXvvGNWK2IyPGiz6B3907gBiKgXwR+7O5rzOwmM7syNdsnzGyNmT0LfAL4UGrZncCXiJ3FU8BNqXGDY+vWeMp3HoK+rAz+7u+goQHuuScPZRMRGSTmQ7B6Wl9f7w0NDce+ol/+Ei6+GH71q3hs1DHq6oKFC2H//rgGa/jwYy+iiEg+mNkqd6/vaVqyr4zNQ4+bbMOGwde+Bq++Ct/9bl5WKSJScMkP+okTYdKkvK3ykkviIOGmm6JVSERkqEt+0Oehx002s6jV79oF//iPeVutiEjBJDfo89jjprvTT4ePfCR64Pzwh3lfvYhIXpUXuwAFs3kztLYWJOgBvvUt2LABPvShOEn74Q8XZDMiIscsuTX6PJ+I7W7kyHj61MUXR+3+3/6tIJsRETlmCvpjUFUFP/tZXEz1F38BK1YUbFMiIgOW7KCvrY2hgEaMgJ/8JNrtFy/WYwdFZOhJdtAXsDafbdSoqNlXVsZzZltaBmWzIiI5SW7Qr10Lp5wyaJubMQPuvhvWr4+a/cGDfS8jIjIYkhn0ra1RrZ49e1A3+9a3xhWzDz4Il18Oe/YM6uZFRHqUzKDfsCFeZ84c9E1ffz384AfwyCNw0UXxJEMRkWJS0BfABz8YbfYvvgjnnw/PPluUYoiIAAr6grn88rhpZlsbnHNONOkMwRuFikgJSG7QV1bm9WZmA3HeefDMM/C2t8Ff/iX86Z/qRmgiMviSG/QzZsTTQops0iT4+c/hq1+Fe++FBQvg4YeLXSoRKSXFT8JC2LChqM023ZWVwd/+LTz+eNw64R3vgE99CrZsKXbJRKQU5BT0Znapmb1kZuvM7DM9TP8bM3vBzJ4zs1+Z2cysaV1m9kxqWN592YIYYkGfVl8PTz8NS5bEnS+nTYvbJ9x+O+zbV+zSiUhS9Rn0ZjYMuBm4DJgPLDaz+d1m+x+g3t0XAHcBX82att/dF6aGKym0AwfgjTeGZNBDXEV7yy1xq4TPfjYeSfi+90FdHbz//dHMs3dvsUspIkmSS43+bGCdu69393bgDuCq7Bnc/WF3b0u9fQKYlt9i9sPGjfE6RIM+7eST4ctfhtdeizb7a6+Nm6K9+90wdiyceSbceCM8/3yxSyoix7tcgn4qsCnrfWNqXG8+CjyQ9X6EmTWY2RNm9ke9LWRmS1LzNTQ3N+dQrF4Mga6V/VFWFhdWfe970Wa/ciV87nMwfnzc+njBguiq+eij6p4pIgOT1wePmNn7gXrgwqzRM929ycxOBH5tZs+7+6vdl3X3pcBSgPr6+oFH2nEW9NkqK2HRohgAdu6Em2+Oh5xceCGceCL8yZ/A1VfDWWfl9QmJIpJgudTom4DpWe+npcYdxszeCXwOuNLdf39LL3dvSr2uBx4BzjiG8vbt9dejmjz1aAcdx4cJE+Af/iH2Xd//fjT3fPObcQHWaafBd74Tt/URETmaXIL+KWCumc02s+HANcBhvWfM7Azge0TIb8saP97MKlM/1wBvAV7IV+F7tGFDhHxFRUE3M5hGjoynWD3wQNw759Zb46TuX/0VnHBCdNf89KfhRz+CrVuLXVoRGWr6bLpx904zuwFYCQwDlrn7GjO7CWhw9+XA14Bq4CcW7QkbUz1sTgG+Z2aHiJ3KV9y98EF/HDbb5Gr8ePjoR2NoaIDbboP//u+o3R88GM05F14If/ZncWXunDmxUxCR0mU+BM/w1dfXe0NDw8AWnjkz7hf8ox/lt1BDXGdn9NC59164887Dn3Q1ZQpccAH88R/Du94FY8YUrZgiUiBmtsrd63ualteTsUXX2QlNTTBrVrFLMujKy+GMM2L44hfjuSurV8Mrr8TPv/hFPPJw+PC4UKuiIoaTToojgAsvjB4+5cn6ixARkhb0TU3Q1ZXopptcmMXDtbIfsNXVFbdgWL48unF2dERTz/PPxy2VIYJ/zhyYNy/68b/jHdG7J0GnO0RKUrKC/jjuWllow4ZF880FFxw5rbEx+uk/91w0+axdG+H/+c/D6NGxzFvfGsMZZ6jNX+R4o6AXpk2L2zC8732ZcTt2xBW7v/xl7AQeyLoEbuzY6Ng0fXq0ks2eDW96U5z8LfKdoUWkB8kM+hkziluOBJg4MS7MuvrqeL99O/zud/HUrM2bo5Vs48bo+bNjR2a5OXOivf8974F3vjMuAhOR4kpe0E+aBFVVxS5J4tTUwFVXxdDd7t3R7PP447EzuOuuuMBr9Oh4lOLw4XHeYOzYuOr3sstiRyIigyNZ3SsXLYKWluhYLkXT3h6PUbznnrgt86FDMX7z5rjgq6wsruwdPjzu31NREc0/c+ZEk9DevfEkro6OOC/w9rfHRWMi0rujda9MVtDPmxd9BH/yk/wXSo7ZoUOwahXcfz889VSMM4s7S7/2WhyQpXcKZWVxArmjA0aMiPb/gwdjR7FnTzQPvfe9cV1A952Ae/QyUldRKSWl0Y/ePRqNr7ii2CWRXpSVRXfNs87qeXp7ewT56NExdHTEieD774fHHotx9fVxBLByJfz4x3FUkO4F5B47gwMH4ucZM6Kb6JlnxgnnCRPiyuLKytiJlJfHuClT1IVUki1ZQf+b38R/shyX0hdzpVVWwsUXx9BdV1emN9CBA4cvU1UVQb52bTQd3Xvv0bdrFqd2TjwxDgpPPjnGNzbGUFkZ0048MY4uWlpiGDUqmqDe/OZYfu/eONqoqIgHyejuojJUJKvpRqQHe/dCc3Pc9nnXrjhy6OqKC6m3b48eRI2N8OqrcR1B+lm+EybEOYODB6NpqaMj922OGhVXHc+eHd1Qp0+Pk9F798bJ6/b2uBXF2LGxY+rsjPWXlcWN6qZNg8mTY+dXXh7zqAeTHE1pNN2I9KK6OobZs3Obf8+eCNzsC8O6uuJk8oEDcdA4dmzcInr16ri6uKUlmpaqq2H//thpvPoqrFsHjzxy5O2ky8sj3Ptj9uw4gpgzJ3YYO3fGTmPUKBg3Lso1dWpcRnLCCYfv4KqqYp5x46IHVW1tDMOHZ9bvDm1tsc7y8lhvVZWOTJJANXqRQbBnTwTomDERoGZxpNDaGjuG8vJo8knvUBob49HHHR0x7N4d1zCsXg3r18d6JkyI17a22NHs3Nn/h8ynz1VUVEQ5uroOn15WFkcSlZWxU6iuzhyJjB2b+Tm9UxgxIl5HjcqcJG9tjWHYsMzRzQknxI5pzJj4XezZEzul/fvjc02cqCOY/lKNXqTI0ieYs40YEUN3J5wQJ50HoqUl+iQ0NcX2amsjOA8ejGarXbuiuaq5OYYDB2JH0tkZAT1mTCzX1RU7jb17Y56DB2PYty8T3Bs2ZH5ua4vp/VVWFjua9vYjp1VWxrSystgRpXceI0fGuHTPrNGjY2dTXX340Ud5eWb5/fuj7AcOxFFNXV3mkpv0fF1dmR3rhAnRfDZlSvxO16+PZxqNHBkn+WfOjPK4x7B7d+yYt6WexpHeWU2eHPNn9wxzj3K0t8fvrKIiylTIIycFvUiCpJtnFiw4clr2ie5COHQogisdqm1tMT5d8+/shE2bYtiyJXY6O3dGsKabkqqqYtyOHRGeXV2ZAG5ry6z30KEIzI6OOBpoaorXtHQX287OeE0fZYwYEdt9442edy6FUlMTYd/aGuVMdyNOKy/PdAj4zW/yv30FvYjkRVlZBGpVVdRoe3LqqTEUW7oWfvBg5kR4uglr2LDY0TQ1RTPauHFxfmTWrNiJbdgQw/79UQs3ix1ZXV0MEMvv2BE7tPT8Bw5kmrxGjco0h7W3x9HVtm2Fq9Ur6EWk5KRvydGbiRMz3WyzjRwZ08488+jrL/TRU3/l8sxYzOxSM3vJzNaZ2Wd6mF5pZnempj9pZrOypn02Nf4lM7skj2UXEZEc9Bn0ZjYMuBm4DJgPLDaz+d1m+yiwy93nAN8E/im17HziYeKnApcC/5pan4iIDJJcavRnA+vcfb27twN3AN3vYXgV8IPUz3cB77B4SvhVwB3uftDdXwPWpdYnIiKDJJegnwpsynrfmBrX4zzu3gm0AhNzXBYAM1tiZg1m1tDc3Jxb6UVEpE85tdEPBndf6u717l5fW1tb7OKIiCRGLkHfBEzPej8tNa7HecysHBgL7MhxWRERKaBcgv4pYK6ZzTaz4cTJ1eXd5lkOXJf6+Wrg1x73VlgOXJPqlTMbmAvoqSAiIoOoz3707t5pZjcAK4FhwDJ3X2NmNwEN7r4c+D7w72a2DthJ7AxIzfdj4AWgE/i4u3f1uCERESmIIXlTMzNrBjYMcPEaYHsei3M80GdOvlL7vKDP3F8z3b3HE5xDMuiPhZk19HYHt6TSZ06+Uvu8oM+cT0Om142IiBSGgl5EJOGSGPRLi12AItBnTr5S+7ygz5w3iWujFxGRwyWxRi8iIlkU9CIiCZeYoO/rnvlJYGbTzexhM3vBzNaY2Y2p8RPM7CEzeyX1Or7YZc03MxtmZv9jZven3s9OPftgXepZCMOLXcZ8MrNxZnaXma01sxfN7Lykf89m9tepv+vVZna7mY1I2vdsZsvMbJuZrc4a1+P3auFbqc/+nJn18biT3iUi6HO8Z34SdAKfcvf5wLnAx1Of8zPAr9x9LvCr1PukuRF4Mev9PwHfTD0DYRfxTIQk+RfgQXd/E3A68dkT+z2b2VTgE0C9u59GXIV/Dcn7nm8jns2Rrbfv9TLitjFzgSXAdwe60UQEPbndM/+45+5b3P3p1M97iH/+qRz+PIAfAH9UlAIWiJlNAy4Hbk29N+DtxLMPIGGf2czGAn9I3FoEd2939xYS/j0Tt2SpSt0YcSSwhYR9z+7+KHGbmGy9fa9XAT/08AQwzsymDGS7SQn6nO97nxSpxzWeATwJ1Ln7ltSkrUBdscpVIP8M/G/gUOr9RKAl9ewDSN73PRtoBv5fqrnqVjMbRYK/Z3dvAr4ObCQCvhVYRbK/57Tevte85VpSgr6kmFk1cDfwSXffnT0tddfQxPSZNbN3A9vcfVWxyzKIyoEzge+6+xnAPro10yTwex5P1GBnAycAoziyiSPxCvW9JiXoS+a+92ZWQYT8f7j7PanRb6QP6VKv24pVvgJ4C3Clmb1ONMm9nWi/Hpc6xIfkfd+NQKO7P5l6fxcR/En+nt8JvObuze7eAdxDfPdJ/p7Tevte85ZrSQn6XO6Zf9xLtU1/H3jR3b+RNSn7eQDXAT8b7LIVirt/1t2nufss4nv9tbtfCzxMPPsAkveZtwKbzGxeatQ7iFt9J/Z7JppszjWzkam/8/RnTuz3nKW373U58MFU75tzgdasJp7+cfdEDMC7gJeBV4HPFbs8BfqMFxCHdc8Bz6SGdxFt1r8CXgF+CUwodlkL9PkvAu5P/Xwi8RCbdcBPgMpily/Pn3Uh0JD6ru8Fxif9ewb+D7AWWA38O1CZtO8ZuJ04B9FBHLl9tLfvFTCiN+GrwPNEj6QBbVe3QBARSbikNN2IiEgvFPQiIgmnoBcRSTgFvYhIwinoRUQSTkEvIpJwCnoRkYT7/61pI5F7HCCfAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best test acc tensor(0.8155)\n"
     ]
    }
   ],
   "source": [
    "# Train Cora\n",
    "lr = 0.01\n",
    "layers = [2, 5]\n",
    "best_param_cora = {\"loop\": None, \"layers\": None, \"if_activate\": None, \"if_normal\": None, \"if_dropout\": None, \"acc\": 0.0}\n",
    "hidden_features = [16, 32, 64]\n",
    "if_activate = [True, False]\n",
    "if_normal = [True, False]\n",
    "if_dropout = [True, False]\n",
    "\n",
    "for h_f in hidden_features:\n",
    "    for l in layers:\n",
    "        for a in if_activate:\n",
    "            for n in if_normal:\n",
    "                for d in if_dropout:\n",
    "                    print(\"layers\", l, \"hidden_features\", h_f, \"if_activate\", a, \"if_normal\", n, \"if_dropout\", d)\n",
    "                    model = GCN(G_cora.ndata['feat'].shape[1], h_f, len(cora_label_map), layers=l, if_activate=a, if_normal=n, if_dropout=d)\n",
    "                    best_val_acc, _ = train(G_cora, model, epochs=101, print_epoch=50, lr=lr, print_loss=False)\n",
    "                    if best_val_acc > best_param_cora[\"acc\"]:\n",
    "                        best_param_cora[\"layers\"] = l\n",
    "                        best_param_cora[\"if_activate\"] = a\n",
    "                        best_param_cora[\"if_dropout\"] = d\n",
    "                        best_param_cora[\"if_normal\"] = n\n",
    "                        best_param_cora[\"acc\"] = best_val_acc\n",
    "                    print()\n",
    "\n",
    "\n",
    "# Best Param\n",
    "print(\"Best Parameter\")\n",
    "print(best_param_cora)\n",
    "l = best_param_cora[\"layers\"]\n",
    "a = best_param_cora[\"if_activate\"]\n",
    "n = best_param_cora[\"if_normal\"]\n",
    "d = best_param_cora[\"if_dropout\"]\n",
    "\n",
    "model = GCN(G_cora.ndata['feat'].shape[1], h_f, len(cora_label_map), layers=l, if_activate=a, if_normal=n, if_dropout=d)\n",
    "_, best_test_acc = train(G_cora, model, epochs=101, print_epoch=25, lr=lr)\n",
    "print(\"best test acc\", best_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers 2 hidden_features 16 if_activate True if_normal True if_dropout True loop True\n",
      "In epoch 0, loss: 1.820, val acc: 0.205 (best 0.205), test acc: 0.232 (best 0.232)\n",
      "In epoch 50, loss: 0.927, val acc: 0.695 (best 0.749), test acc: 0.693 (best 0.741)\n",
      "In epoch 100, loss: 0.664, val acc: 0.698 (best 0.749), test acc: 0.681 (best 0.741)\n",
      "\n",
      "layers 2 hidden_features 16 if_activate True if_normal True if_dropout False loop True\n",
      "In epoch 0, loss: 1.780, val acc: 0.199 (best 0.199), test acc: 0.244 (best 0.244)\n",
      "In epoch 50, loss: 0.648, val acc: 0.752 (best 0.764), test acc: 0.735 (best 0.744)\n",
      "In epoch 100, loss: 0.390, val acc: 0.737 (best 0.764), test acc: 0.714 (best 0.744)\n",
      "\n",
      "layers 2 hidden_features 16 if_activate True if_normal False if_dropout True loop True\n",
      "In epoch 0, loss: 1.800, val acc: 0.172 (best 0.172), test acc: 0.187 (best 0.187)\n",
      "In epoch 50, loss: 0.352, val acc: 0.713 (best 0.764), test acc: 0.702 (best 0.702)\n",
      "In epoch 100, loss: 0.217, val acc: 0.734 (best 0.764), test acc: 0.678 (best 0.702)\n",
      "\n",
      "layers 2 hidden_features 16 if_activate True if_normal False if_dropout False loop True\n",
      "In epoch 0, loss: 1.789, val acc: 0.154 (best 0.154), test acc: 0.211 (best 0.211)\n",
      "In epoch 50, loss: 0.119, val acc: 0.719 (best 0.782), test acc: 0.756 (best 0.759)\n",
      "In epoch 100, loss: 0.063, val acc: 0.716 (best 0.782), test acc: 0.735 (best 0.759)\n",
      "\n",
      "layers 2 hidden_features 16 if_activate False if_normal True if_dropout True loop True\n",
      "In epoch 0, loss: 1.817, val acc: 0.169 (best 0.169), test acc: 0.190 (best 0.190)\n",
      "In epoch 50, loss: 0.721, val acc: 0.737 (best 0.764), test acc: 0.729 (best 0.750)\n",
      "In epoch 100, loss: 0.435, val acc: 0.707 (best 0.764), test acc: 0.717 (best 0.750)\n",
      "\n",
      "layers 2 hidden_features 16 if_activate False if_normal True if_dropout False loop True\n",
      "In epoch 0, loss: 1.815, val acc: 0.163 (best 0.163), test acc: 0.181 (best 0.181)\n",
      "In epoch 50, loss: 0.481, val acc: 0.749 (best 0.773), test acc: 0.768 (best 0.750)\n",
      "In epoch 100, loss: 0.263, val acc: 0.704 (best 0.773), test acc: 0.717 (best 0.750)\n",
      "\n",
      "layers 2 hidden_features 16 if_activate False if_normal False if_dropout True loop True\n",
      "In epoch 0, loss: 1.813, val acc: 0.112 (best 0.112), test acc: 0.127 (best 0.127)\n",
      "In epoch 50, loss: 0.189, val acc: 0.719 (best 0.782), test acc: 0.726 (best 0.732)\n",
      "In epoch 100, loss: 0.115, val acc: 0.722 (best 0.782), test acc: 0.723 (best 0.732)\n",
      "\n",
      "layers 2 hidden_features 16 if_activate False if_normal False if_dropout False loop True\n",
      "In epoch 0, loss: 1.782, val acc: 0.205 (best 0.205), test acc: 0.196 (best 0.196)\n",
      "In epoch 50, loss: 0.107, val acc: 0.716 (best 0.789), test acc: 0.741 (best 0.741)\n",
      "In epoch 100, loss: 0.058, val acc: 0.701 (best 0.789), test acc: 0.732 (best 0.741)\n",
      "\n",
      "layers 5 hidden_features 16 if_activate True if_normal True if_dropout True loop True\n",
      "In epoch 0, loss: 1.817, val acc: 0.130 (best 0.130), test acc: 0.105 (best 0.105)\n",
      "In epoch 50, loss: 1.023, val acc: 0.692 (best 0.719), test acc: 0.651 (best 0.657)\n",
      "In epoch 100, loss: 0.717, val acc: 0.692 (best 0.719), test acc: 0.663 (best 0.657)\n",
      "\n",
      "layers 5 hidden_features 16 if_activate True if_normal True if_dropout False loop True\n",
      "In epoch 0, loss: 1.840, val acc: 0.136 (best 0.136), test acc: 0.123 (best 0.123)\n",
      "In epoch 50, loss: 0.752, val acc: 0.704 (best 0.731), test acc: 0.696 (best 0.720)\n",
      "In epoch 100, loss: 0.471, val acc: 0.689 (best 0.731), test acc: 0.660 (best 0.720)\n",
      "\n",
      "layers 5 hidden_features 16 if_activate True if_normal False if_dropout True loop True\n",
      "In epoch 0, loss: 1.787, val acc: 0.199 (best 0.199), test acc: 0.169 (best 0.169)\n",
      "In epoch 50, loss: 0.404, val acc: 0.665 (best 0.698), test acc: 0.639 (best 0.654)\n",
      "In epoch 100, loss: 0.318, val acc: 0.647 (best 0.698), test acc: 0.639 (best 0.654)\n",
      "\n",
      "layers 5 hidden_features 16 if_activate True if_normal False if_dropout False loop True\n",
      "In epoch 0, loss: 1.789, val acc: 0.202 (best 0.202), test acc: 0.205 (best 0.205)\n",
      "In epoch 50, loss: 0.201, val acc: 0.674 (best 0.743), test acc: 0.678 (best 0.699)\n",
      "In epoch 100, loss: 0.115, val acc: 0.656 (best 0.743), test acc: 0.657 (best 0.699)\n",
      "\n",
      "layers 5 hidden_features 16 if_activate False if_normal True if_dropout True loop True\n",
      "In epoch 0, loss: 1.827, val acc: 0.166 (best 0.166), test acc: 0.148 (best 0.148)\n",
      "In epoch 50, loss: 0.820, val acc: 0.692 (best 0.740), test acc: 0.684 (best 0.690)\n",
      "In epoch 100, loss: 0.521, val acc: 0.701 (best 0.740), test acc: 0.684 (best 0.690)\n",
      "\n",
      "layers 5 hidden_features 16 if_activate False if_normal True if_dropout False loop True\n",
      "In epoch 0, loss: 1.807, val acc: 0.166 (best 0.166), test acc: 0.151 (best 0.151)\n",
      "In epoch 50, loss: 0.611, val acc: 0.734 (best 0.743), test acc: 0.702 (best 0.699)\n",
      "In epoch 100, loss: 0.350, val acc: 0.701 (best 0.743), test acc: 0.684 (best 0.699)\n",
      "\n",
      "layers 5 hidden_features 16 if_activate False if_normal False if_dropout True loop True\n",
      "In epoch 0, loss: 1.784, val acc: 0.199 (best 0.199), test acc: 0.229 (best 0.229)\n",
      "In epoch 50, loss: 0.250, val acc: 0.695 (best 0.749), test acc: 0.672 (best 0.666)\n",
      "In epoch 100, loss: 0.194, val acc: 0.656 (best 0.749), test acc: 0.651 (best 0.666)\n",
      "\n",
      "layers 5 hidden_features 16 if_activate False if_normal False if_dropout False loop True\n",
      "In epoch 0, loss: 1.814, val acc: 0.112 (best 0.112), test acc: 0.099 (best 0.099)\n",
      "In epoch 50, loss: 0.179, val acc: 0.668 (best 0.761), test acc: 0.690 (best 0.714)\n",
      "In epoch 100, loss: 0.111, val acc: 0.668 (best 0.761), test acc: 0.648 (best 0.714)\n",
      "\n",
      "layers 2 hidden_features 16 if_activate True if_normal True if_dropout True loop False\n",
      "In epoch 0, loss: 1.795, val acc: 0.166 (best 0.166), test acc: 0.190 (best 0.190)\n",
      "In epoch 50, loss: 0.956, val acc: 0.637 (best 0.668), test acc: 0.654 (best 0.663)\n",
      "In epoch 100, loss: 0.694, val acc: 0.656 (best 0.689), test acc: 0.666 (best 0.657)\n",
      "\n",
      "layers 2 hidden_features 16 if_activate True if_normal True if_dropout False loop False\n",
      "In epoch 0, loss: 1.797, val acc: 0.193 (best 0.193), test acc: 0.166 (best 0.166)\n",
      "In epoch 50, loss: 0.691, val acc: 0.668 (best 0.668), test acc: 0.693 (best 0.696)\n",
      "In epoch 100, loss: 0.428, val acc: 0.671 (best 0.692), test acc: 0.696 (best 0.693)\n",
      "\n",
      "layers 2 hidden_features 16 if_activate True if_normal False if_dropout True loop False\n",
      "In epoch 0, loss: 1.783, val acc: 0.218 (best 0.218), test acc: 0.214 (best 0.214)\n",
      "In epoch 50, loss: 0.326, val acc: 0.671 (best 0.686), test acc: 0.663 (best 0.690)\n",
      "In epoch 100, loss: 0.231, val acc: 0.650 (best 0.701), test acc: 0.672 (best 0.669)\n",
      "\n",
      "layers 2 hidden_features 16 if_activate True if_normal False if_dropout False loop False\n",
      "In epoch 0, loss: 1.786, val acc: 0.181 (best 0.181), test acc: 0.190 (best 0.190)\n",
      "In epoch 50, loss: 0.138, val acc: 0.695 (best 0.722), test acc: 0.699 (best 0.735)\n",
      "In epoch 100, loss: 0.087, val acc: 0.689 (best 0.722), test acc: 0.705 (best 0.735)\n",
      "\n",
      "layers 2 hidden_features 16 if_activate False if_normal True if_dropout True loop False\n",
      "In epoch 0, loss: 1.840, val acc: 0.148 (best 0.148), test acc: 0.145 (best 0.145)\n",
      "In epoch 50, loss: 0.719, val acc: 0.698 (best 0.725), test acc: 0.690 (best 0.657)\n",
      "In epoch 100, loss: 0.454, val acc: 0.677 (best 0.725), test acc: 0.666 (best 0.657)\n",
      "\n",
      "layers 2 hidden_features 16 if_activate False if_normal True if_dropout False loop False\n",
      "In epoch 0, loss: 1.831, val acc: 0.151 (best 0.151), test acc: 0.169 (best 0.169)\n",
      "In epoch 50, loss: 0.519, val acc: 0.707 (best 0.722), test acc: 0.687 (best 0.726)\n",
      "In epoch 100, loss: 0.292, val acc: 0.665 (best 0.722), test acc: 0.684 (best 0.726)\n",
      "\n",
      "layers 2 hidden_features 16 if_activate False if_normal False if_dropout True loop False\n",
      "In epoch 0, loss: 1.799, val acc: 0.157 (best 0.157), test acc: 0.190 (best 0.190)\n",
      "In epoch 50, loss: 0.196, val acc: 0.680 (best 0.728), test acc: 0.693 (best 0.729)\n",
      "In epoch 100, loss: 0.136, val acc: 0.656 (best 0.728), test acc: 0.687 (best 0.729)\n",
      "\n",
      "layers 2 hidden_features 16 if_activate False if_normal False if_dropout False loop False\n",
      "In epoch 0, loss: 1.811, val acc: 0.097 (best 0.097), test acc: 0.102 (best 0.102)\n",
      "In epoch 50, loss: 0.135, val acc: 0.704 (best 0.713), test acc: 0.702 (best 0.726)\n",
      "In epoch 100, loss: 0.086, val acc: 0.683 (best 0.713), test acc: 0.699 (best 0.726)\n",
      "\n",
      "layers 5 hidden_features 16 if_activate True if_normal True if_dropout True loop False\n",
      "In epoch 0, loss: 1.802, val acc: 0.205 (best 0.205), test acc: 0.217 (best 0.217)\n",
      "In epoch 50, loss: 1.058, val acc: 0.607 (best 0.631), test acc: 0.633 (best 0.651)\n",
      "In epoch 100, loss: 0.715, val acc: 0.607 (best 0.640), test acc: 0.623 (best 0.645)\n",
      "\n",
      "layers 5 hidden_features 16 if_activate True if_normal True if_dropout False loop False\n",
      "In epoch 0, loss: 1.827, val acc: 0.145 (best 0.145), test acc: 0.163 (best 0.163)\n",
      "In epoch 50, loss: 0.819, val acc: 0.659 (best 0.680), test acc: 0.678 (best 0.702)\n",
      "In epoch 100, loss: 0.511, val acc: 0.659 (best 0.680), test acc: 0.687 (best 0.702)\n",
      "\n",
      "layers 5 hidden_features 16 if_activate True if_normal False if_dropout True loop False\n",
      "In epoch 0, loss: 1.795, val acc: 0.154 (best 0.154), test acc: 0.145 (best 0.145)\n",
      "In epoch 50, loss: 0.409, val acc: 0.619 (best 0.634), test acc: 0.672 (best 0.672)\n",
      "In epoch 100, loss: 0.328, val acc: 0.604 (best 0.653), test acc: 0.645 (best 0.645)\n",
      "\n",
      "layers 5 hidden_features 16 if_activate True if_normal False if_dropout False loop False\n",
      "In epoch 0, loss: 1.787, val acc: 0.224 (best 0.224), test acc: 0.265 (best 0.265)\n",
      "In epoch 50, loss: 0.224, val acc: 0.640 (best 0.686), test acc: 0.675 (best 0.690)\n",
      "In epoch 100, loss: 0.141, val acc: 0.622 (best 0.686), test acc: 0.654 (best 0.690)\n",
      "\n",
      "layers 5 hidden_features 16 if_activate False if_normal True if_dropout True loop False\n",
      "In epoch 0, loss: 1.787, val acc: 0.224 (best 0.224), test acc: 0.208 (best 0.208)\n",
      "In epoch 50, loss: 0.781, val acc: 0.653 (best 0.674), test acc: 0.648 (best 0.711)\n",
      "In epoch 100, loss: 0.505, val acc: 0.625 (best 0.674), test acc: 0.657 (best 0.711)\n",
      "\n",
      "layers 5 hidden_features 16 if_activate False if_normal True if_dropout False loop False\n",
      "In epoch 0, loss: 1.808, val acc: 0.142 (best 0.142), test acc: 0.157 (best 0.157)\n",
      "In epoch 50, loss: 0.634, val acc: 0.662 (best 0.686), test acc: 0.687 (best 0.702)\n",
      "In epoch 100, loss: 0.362, val acc: 0.644 (best 0.686), test acc: 0.687 (best 0.702)\n",
      "\n",
      "layers 5 hidden_features 16 if_activate False if_normal False if_dropout True loop False\n",
      "In epoch 0, loss: 1.784, val acc: 0.202 (best 0.202), test acc: 0.187 (best 0.187)\n",
      "In epoch 50, loss: 0.271, val acc: 0.619 (best 0.659), test acc: 0.651 (best 0.702)\n",
      "In epoch 100, loss: 0.211, val acc: 0.637 (best 0.659), test acc: 0.657 (best 0.702)\n",
      "\n",
      "layers 5 hidden_features 16 if_activate False if_normal False if_dropout False loop False\n",
      "In epoch 0, loss: 1.791, val acc: 0.118 (best 0.118), test acc: 0.114 (best 0.114)\n",
      "In epoch 50, loss: 0.192, val acc: 0.647 (best 0.704), test acc: 0.675 (best 0.690)\n",
      "In epoch 100, loss: 0.117, val acc: 0.634 (best 0.704), test acc: 0.633 (best 0.690)\n",
      "\n",
      "layers 2 hidden_features 32 if_activate True if_normal True if_dropout True loop True\n",
      "In epoch 0, loss: 1.815, val acc: 0.151 (best 0.151), test acc: 0.163 (best 0.163)\n",
      "In epoch 50, loss: 0.759, val acc: 0.737 (best 0.764), test acc: 0.732 (best 0.750)\n",
      "In epoch 100, loss: 0.468, val acc: 0.719 (best 0.767), test acc: 0.699 (best 0.753)\n",
      "\n",
      "layers 2 hidden_features 32 if_activate True if_normal True if_dropout False loop True\n",
      "In epoch 0, loss: 1.797, val acc: 0.218 (best 0.218), test acc: 0.193 (best 0.193)\n",
      "In epoch 50, loss: 0.515, val acc: 0.758 (best 0.776), test acc: 0.747 (best 0.756)\n",
      "In epoch 100, loss: 0.298, val acc: 0.737 (best 0.776), test acc: 0.723 (best 0.756)\n",
      "\n",
      "layers 2 hidden_features 32 if_activate True if_normal False if_dropout True loop True\n",
      "In epoch 0, loss: 1.800, val acc: 0.157 (best 0.157), test acc: 0.148 (best 0.148)\n",
      "In epoch 50, loss: 0.183, val acc: 0.728 (best 0.789), test acc: 0.717 (best 0.723)\n",
      "In epoch 100, loss: 0.116, val acc: 0.710 (best 0.789), test acc: 0.726 (best 0.723)\n",
      "\n",
      "layers 2 hidden_features 32 if_activate True if_normal False if_dropout False loop True\n",
      "In epoch 0, loss: 1.808, val acc: 0.148 (best 0.148), test acc: 0.120 (best 0.120)\n",
      "In epoch 50, loss: 0.085, val acc: 0.707 (best 0.798), test acc: 0.738 (best 0.759)\n",
      "In epoch 100, loss: 0.049, val acc: 0.701 (best 0.798), test acc: 0.732 (best 0.759)\n",
      "\n",
      "layers 2 hidden_features 32 if_activate False if_normal True if_dropout True loop True\n",
      "In epoch 0, loss: 1.803, val acc: 0.196 (best 0.196), test acc: 0.178 (best 0.178)\n",
      "In epoch 50, loss: 0.541, val acc: 0.734 (best 0.782), test acc: 0.747 (best 0.753)\n",
      "In epoch 100, loss: 0.302, val acc: 0.710 (best 0.782), test acc: 0.723 (best 0.753)\n",
      "\n",
      "layers 2 hidden_features 32 if_activate False if_normal True if_dropout False loop True\n",
      "In epoch 0, loss: 1.812, val acc: 0.154 (best 0.154), test acc: 0.166 (best 0.166)\n",
      "In epoch 50, loss: 0.374, val acc: 0.746 (best 0.785), test acc: 0.762 (best 0.771)\n",
      "In epoch 100, loss: 0.195, val acc: 0.716 (best 0.785), test acc: 0.699 (best 0.771)\n",
      "\n",
      "layers 2 hidden_features 32 if_activate False if_normal False if_dropout True loop True\n",
      "In epoch 0, loss: 1.796, val acc: 0.115 (best 0.115), test acc: 0.181 (best 0.181)\n",
      "In epoch 50, loss: 0.134, val acc: 0.731 (best 0.785), test acc: 0.738 (best 0.741)\n",
      "In epoch 100, loss: 0.082, val acc: 0.716 (best 0.785), test acc: 0.720 (best 0.741)\n",
      "\n",
      "layers 2 hidden_features 32 if_activate False if_normal False if_dropout False loop True\n",
      "In epoch 0, loss: 1.782, val acc: 0.215 (best 0.215), test acc: 0.217 (best 0.217)\n",
      "In epoch 50, loss: 0.079, val acc: 0.707 (best 0.776), test acc: 0.744 (best 0.753)\n",
      "In epoch 100, loss: 0.047, val acc: 0.704 (best 0.776), test acc: 0.726 (best 0.753)\n",
      "\n",
      "layers 5 hidden_features 32 if_activate True if_normal True if_dropout True loop True\n",
      "In epoch 0, loss: 1.779, val acc: 0.224 (best 0.224), test acc: 0.229 (best 0.229)\n",
      "In epoch 50, loss: 0.815, val acc: 0.704 (best 0.731), test acc: 0.717 (best 0.708)\n",
      "In epoch 100, loss: 0.510, val acc: 0.695 (best 0.731), test acc: 0.666 (best 0.708)\n",
      "\n",
      "layers 5 hidden_features 32 if_activate True if_normal True if_dropout False loop True\n",
      "In epoch 0, loss: 1.845, val acc: 0.160 (best 0.160), test acc: 0.087 (best 0.087)\n",
      "In epoch 50, loss: 0.596, val acc: 0.719 (best 0.749), test acc: 0.708 (best 0.711)\n",
      "In epoch 100, loss: 0.332, val acc: 0.683 (best 0.749), test acc: 0.678 (best 0.711)\n",
      "\n",
      "layers 5 hidden_features 32 if_activate True if_normal False if_dropout True loop True\n",
      "In epoch 0, loss: 1.792, val acc: 0.151 (best 0.151), test acc: 0.148 (best 0.148)\n",
      "In epoch 50, loss: 0.240, val acc: 0.692 (best 0.740), test acc: 0.687 (best 0.696)\n",
      "In epoch 100, loss: 0.163, val acc: 0.650 (best 0.740), test acc: 0.687 (best 0.696)\n",
      "\n",
      "layers 5 hidden_features 32 if_activate True if_normal False if_dropout False loop True\n",
      "In epoch 0, loss: 1.790, val acc: 0.157 (best 0.157), test acc: 0.136 (best 0.136)\n",
      "In epoch 50, loss: 0.174, val acc: 0.677 (best 0.758), test acc: 0.672 (best 0.693)\n",
      "In epoch 100, loss: 0.100, val acc: 0.674 (best 0.758), test acc: 0.645 (best 0.693)\n",
      "\n",
      "layers 5 hidden_features 32 if_activate False if_normal True if_dropout True loop True\n",
      "In epoch 0, loss: 1.807, val acc: 0.157 (best 0.157), test acc: 0.139 (best 0.139)\n",
      "In epoch 50, loss: 0.632, val acc: 0.713 (best 0.743), test acc: 0.699 (best 0.714)\n",
      "In epoch 100, loss: 0.369, val acc: 0.683 (best 0.743), test acc: 0.687 (best 0.714)\n",
      "\n",
      "layers 5 hidden_features 32 if_activate False if_normal True if_dropout False loop True\n",
      "In epoch 0, loss: 1.815, val acc: 0.193 (best 0.193), test acc: 0.166 (best 0.166)\n",
      "In epoch 50, loss: 0.456, val acc: 0.728 (best 0.755), test acc: 0.693 (best 0.714)\n",
      "In epoch 100, loss: 0.262, val acc: 0.677 (best 0.755), test acc: 0.681 (best 0.714)\n",
      "\n",
      "layers 5 hidden_features 32 if_activate False if_normal False if_dropout True loop True\n",
      "In epoch 0, loss: 1.795, val acc: 0.218 (best 0.218), test acc: 0.211 (best 0.211)\n",
      "In epoch 50, loss: 0.212, val acc: 0.692 (best 0.740), test acc: 0.696 (best 0.705)\n",
      "In epoch 100, loss: 0.162, val acc: 0.683 (best 0.740), test acc: 0.675 (best 0.705)\n",
      "\n",
      "layers 5 hidden_features 32 if_activate False if_normal False if_dropout False loop True\n",
      "In epoch 0, loss: 1.800, val acc: 0.118 (best 0.118), test acc: 0.127 (best 0.127)\n",
      "In epoch 50, loss: 0.146, val acc: 0.680 (best 0.752), test acc: 0.681 (best 0.705)\n",
      "In epoch 100, loss: 0.104, val acc: 0.662 (best 0.752), test acc: 0.642 (best 0.705)\n",
      "\n",
      "layers 2 hidden_features 32 if_activate True if_normal True if_dropout True loop False\n",
      "In epoch 0, loss: 1.798, val acc: 0.148 (best 0.148), test acc: 0.145 (best 0.145)\n",
      "In epoch 50, loss: 0.754, val acc: 0.692 (best 0.692), test acc: 0.684 (best 0.684)\n",
      "In epoch 100, loss: 0.489, val acc: 0.689 (best 0.695), test acc: 0.684 (best 0.687)\n",
      "\n",
      "layers 2 hidden_features 32 if_activate True if_normal True if_dropout False loop False\n",
      "In epoch 0, loss: 1.826, val acc: 0.160 (best 0.160), test acc: 0.130 (best 0.130)\n",
      "In epoch 50, loss: 0.536, val acc: 0.683 (best 0.701), test acc: 0.699 (best 0.717)\n",
      "In epoch 100, loss: 0.318, val acc: 0.692 (best 0.701), test acc: 0.687 (best 0.717)\n",
      "\n",
      "layers 2 hidden_features 32 if_activate True if_normal False if_dropout True loop False\n",
      "In epoch 0, loss: 1.785, val acc: 0.187 (best 0.187), test acc: 0.211 (best 0.211)\n",
      "In epoch 50, loss: 0.204, val acc: 0.695 (best 0.710), test acc: 0.702 (best 0.714)\n",
      "In epoch 100, loss: 0.132, val acc: 0.680 (best 0.710), test acc: 0.663 (best 0.714)\n",
      "\n",
      "layers 2 hidden_features 32 if_activate True if_normal False if_dropout False loop False\n",
      "In epoch 0, loss: 1.788, val acc: 0.218 (best 0.218), test acc: 0.154 (best 0.154)\n",
      "In epoch 50, loss: 0.106, val acc: 0.695 (best 0.740), test acc: 0.699 (best 0.696)\n",
      "In epoch 100, loss: 0.075, val acc: 0.683 (best 0.740), test acc: 0.696 (best 0.696)\n",
      "\n",
      "layers 2 hidden_features 32 if_activate False if_normal True if_dropout True loop False\n",
      "In epoch 0, loss: 1.803, val acc: 0.184 (best 0.184), test acc: 0.157 (best 0.157)\n",
      "In epoch 50, loss: 0.553, val acc: 0.722 (best 0.731), test acc: 0.717 (best 0.696)\n",
      "In epoch 100, loss: 0.320, val acc: 0.689 (best 0.731), test acc: 0.678 (best 0.696)\n",
      "\n",
      "layers 2 hidden_features 32 if_activate False if_normal True if_dropout False loop False\n",
      "In epoch 0, loss: 1.826, val acc: 0.163 (best 0.163), test acc: 0.184 (best 0.184)\n",
      "In epoch 50, loss: 0.378, val acc: 0.701 (best 0.725), test acc: 0.690 (best 0.714)\n",
      "In epoch 100, loss: 0.213, val acc: 0.665 (best 0.725), test acc: 0.687 (best 0.714)\n",
      "\n",
      "layers 2 hidden_features 32 if_activate False if_normal False if_dropout True loop False\n",
      "In epoch 0, loss: 1.811, val acc: 0.178 (best 0.178), test acc: 0.120 (best 0.120)\n",
      "In epoch 50, loss: 0.149, val acc: 0.704 (best 0.728), test acc: 0.681 (best 0.699)\n",
      "In epoch 100, loss: 0.107, val acc: 0.683 (best 0.728), test acc: 0.684 (best 0.699)\n",
      "\n",
      "layers 2 hidden_features 32 if_activate False if_normal False if_dropout False loop False\n",
      "In epoch 0, loss: 1.794, val acc: 0.118 (best 0.118), test acc: 0.130 (best 0.130)\n",
      "In epoch 50, loss: 0.103, val acc: 0.704 (best 0.716), test acc: 0.693 (best 0.717)\n",
      "In epoch 100, loss: 0.073, val acc: 0.686 (best 0.716), test acc: 0.702 (best 0.717)\n",
      "\n",
      "layers 5 hidden_features 32 if_activate True if_normal True if_dropout True loop False\n",
      "In epoch 0, loss: 1.782, val acc: 0.184 (best 0.184), test acc: 0.223 (best 0.223)\n",
      "In epoch 50, loss: 0.817, val acc: 0.619 (best 0.665), test acc: 0.654 (best 0.693)\n",
      "In epoch 100, loss: 0.514, val acc: 0.634 (best 0.665), test acc: 0.645 (best 0.693)\n",
      "\n",
      "layers 5 hidden_features 32 if_activate True if_normal True if_dropout False loop False\n",
      "In epoch 0, loss: 1.784, val acc: 0.163 (best 0.163), test acc: 0.181 (best 0.181)\n",
      "In epoch 50, loss: 0.626, val acc: 0.665 (best 0.695), test acc: 0.672 (best 0.696)\n",
      "In epoch 100, loss: 0.354, val acc: 0.637 (best 0.695), test acc: 0.654 (best 0.696)\n",
      "\n",
      "layers 5 hidden_features 32 if_activate True if_normal False if_dropout True loop False\n",
      "In epoch 0, loss: 1.790, val acc: 0.151 (best 0.151), test acc: 0.145 (best 0.145)\n",
      "In epoch 50, loss: 0.275, val acc: 0.647 (best 0.689), test acc: 0.666 (best 0.678)\n",
      "In epoch 100, loss: 0.189, val acc: 0.631 (best 0.689), test acc: 0.648 (best 0.678)\n",
      "\n",
      "layers 5 hidden_features 32 if_activate True if_normal False if_dropout False loop False\n",
      "In epoch 0, loss: 1.794, val acc: 0.154 (best 0.154), test acc: 0.148 (best 0.148)\n",
      "In epoch 50, loss: 0.175, val acc: 0.647 (best 0.686), test acc: 0.672 (best 0.687)\n",
      "In epoch 100, loss: 0.114, val acc: 0.628 (best 0.686), test acc: 0.648 (best 0.687)\n",
      "\n",
      "layers 5 hidden_features 32 if_activate False if_normal True if_dropout True loop False\n",
      "In epoch 0, loss: 1.787, val acc: 0.215 (best 0.215), test acc: 0.217 (best 0.217)\n",
      "In epoch 50, loss: 0.616, val acc: 0.644 (best 0.701), test acc: 0.672 (best 0.699)\n",
      "In epoch 100, loss: 0.378, val acc: 0.625 (best 0.701), test acc: 0.654 (best 0.699)\n",
      "\n",
      "layers 5 hidden_features 32 if_activate False if_normal True if_dropout False loop False\n",
      "In epoch 0, loss: 1.807, val acc: 0.181 (best 0.181), test acc: 0.169 (best 0.169)\n",
      "In epoch 50, loss: 0.458, val acc: 0.656 (best 0.686), test acc: 0.672 (best 0.687)\n",
      "In epoch 100, loss: 0.275, val acc: 0.628 (best 0.686), test acc: 0.654 (best 0.687)\n",
      "\n",
      "layers 5 hidden_features 32 if_activate False if_normal False if_dropout True loop False\n",
      "In epoch 0, loss: 1.807, val acc: 0.133 (best 0.133), test acc: 0.117 (best 0.117)\n",
      "In epoch 50, loss: 0.227, val acc: 0.631 (best 0.692), test acc: 0.660 (best 0.669)\n",
      "In epoch 100, loss: 0.178, val acc: 0.634 (best 0.692), test acc: 0.654 (best 0.669)\n",
      "\n",
      "layers 5 hidden_features 32 if_activate False if_normal False if_dropout False loop False\n",
      "In epoch 0, loss: 1.801, val acc: 0.091 (best 0.091), test acc: 0.093 (best 0.093)\n",
      "In epoch 50, loss: 0.179, val acc: 0.637 (best 0.707), test acc: 0.672 (best 0.696)\n",
      "In epoch 100, loss: 0.114, val acc: 0.637 (best 0.707), test acc: 0.639 (best 0.696)\n",
      "\n",
      "layers 2 hidden_features 64 if_activate True if_normal True if_dropout True loop True\n",
      "In epoch 0, loss: 1.797, val acc: 0.239 (best 0.239), test acc: 0.160 (best 0.160)\n",
      "In epoch 50, loss: 0.585, val acc: 0.752 (best 0.767), test acc: 0.738 (best 0.762)\n",
      "In epoch 100, loss: 0.328, val acc: 0.737 (best 0.767), test acc: 0.738 (best 0.762)\n",
      "\n",
      "layers 2 hidden_features 64 if_activate True if_normal True if_dropout False loop True\n",
      "In epoch 0, loss: 1.800, val acc: 0.139 (best 0.139), test acc: 0.154 (best 0.154)\n",
      "In epoch 50, loss: 0.393, val acc: 0.743 (best 0.773), test acc: 0.747 (best 0.771)\n",
      "In epoch 100, loss: 0.216, val acc: 0.728 (best 0.773), test acc: 0.723 (best 0.771)\n",
      "\n",
      "layers 2 hidden_features 64 if_activate True if_normal False if_dropout True loop True\n",
      "In epoch 0, loss: 1.793, val acc: 0.145 (best 0.145), test acc: 0.151 (best 0.151)\n",
      "In epoch 50, loss: 0.130, val acc: 0.716 (best 0.776), test acc: 0.741 (best 0.732)\n",
      "In epoch 100, loss: 0.075, val acc: 0.728 (best 0.776), test acc: 0.714 (best 0.732)\n",
      "\n",
      "layers 2 hidden_features 64 if_activate True if_normal False if_dropout False loop True\n",
      "In epoch 0, loss: 1.810, val acc: 0.133 (best 0.133), test acc: 0.081 (best 0.081)\n",
      "In epoch 50, loss: 0.067, val acc: 0.710 (best 0.795), test acc: 0.735 (best 0.750)\n",
      "In epoch 100, loss: 0.043, val acc: 0.710 (best 0.795), test acc: 0.732 (best 0.750)\n",
      "\n",
      "layers 2 hidden_features 64 if_activate False if_normal True if_dropout True loop True\n",
      "In epoch 0, loss: 1.806, val acc: 0.130 (best 0.130), test acc: 0.157 (best 0.157)\n",
      "In epoch 50, loss: 0.409, val acc: 0.737 (best 0.776), test acc: 0.738 (best 0.735)\n",
      "In epoch 100, loss: 0.213, val acc: 0.716 (best 0.776), test acc: 0.699 (best 0.735)\n",
      "\n",
      "layers 2 hidden_features 64 if_activate False if_normal True if_dropout False loop True\n",
      "In epoch 0, loss: 1.832, val acc: 0.100 (best 0.100), test acc: 0.096 (best 0.096)\n",
      "In epoch 50, loss: 0.277, val acc: 0.737 (best 0.779), test acc: 0.750 (best 0.762)\n",
      "In epoch 100, loss: 0.141, val acc: 0.704 (best 0.779), test acc: 0.705 (best 0.762)\n",
      "\n",
      "layers 2 hidden_features 64 if_activate False if_normal False if_dropout True loop True\n",
      "In epoch 0, loss: 1.810, val acc: 0.175 (best 0.175), test acc: 0.205 (best 0.205)\n",
      "In epoch 50, loss: 0.097, val acc: 0.716 (best 0.795), test acc: 0.735 (best 0.768)\n",
      "In epoch 100, loss: 0.068, val acc: 0.710 (best 0.795), test acc: 0.738 (best 0.768)\n",
      "\n",
      "layers 2 hidden_features 64 if_activate False if_normal False if_dropout False loop True\n",
      "In epoch 0, loss: 1.805, val acc: 0.109 (best 0.109), test acc: 0.160 (best 0.160)\n",
      "In epoch 50, loss: 0.065, val acc: 0.710 (best 0.792), test acc: 0.738 (best 0.747)\n",
      "In epoch 100, loss: 0.042, val acc: 0.698 (best 0.792), test acc: 0.735 (best 0.747)\n",
      "\n",
      "layers 5 hidden_features 64 if_activate True if_normal True if_dropout True loop True\n",
      "In epoch 0, loss: 1.788, val acc: 0.205 (best 0.205), test acc: 0.169 (best 0.169)\n",
      "In epoch 50, loss: 0.618, val acc: 0.716 (best 0.746), test acc: 0.687 (best 0.696)\n",
      "In epoch 100, loss: 0.366, val acc: 0.683 (best 0.746), test acc: 0.663 (best 0.696)\n",
      "\n",
      "layers 5 hidden_features 64 if_activate True if_normal True if_dropout False loop True\n",
      "In epoch 0, loss: 1.794, val acc: 0.178 (best 0.178), test acc: 0.175 (best 0.175)\n",
      "In epoch 50, loss: 0.438, val acc: 0.698 (best 0.749), test acc: 0.699 (best 0.705)\n",
      "In epoch 100, loss: 0.247, val acc: 0.656 (best 0.749), test acc: 0.654 (best 0.705)\n",
      "\n",
      "layers 5 hidden_features 64 if_activate True if_normal False if_dropout True loop True\n",
      "In epoch 0, loss: 1.791, val acc: 0.193 (best 0.193), test acc: 0.238 (best 0.238)\n",
      "In epoch 50, loss: 0.211, val acc: 0.680 (best 0.749), test acc: 0.696 (best 0.681)\n",
      "In epoch 100, loss: 0.125, val acc: 0.671 (best 0.749), test acc: 0.654 (best 0.681)\n",
      "\n",
      "layers 5 hidden_features 64 if_activate True if_normal False if_dropout False loop True\n",
      "In epoch 0, loss: 1.792, val acc: 0.202 (best 0.202), test acc: 0.196 (best 0.196)\n",
      "In epoch 50, loss: 0.160, val acc: 0.692 (best 0.755), test acc: 0.672 (best 0.720)\n",
      "In epoch 100, loss: 0.096, val acc: 0.677 (best 0.755), test acc: 0.666 (best 0.720)\n",
      "\n",
      "layers 5 hidden_features 64 if_activate False if_normal True if_dropout True loop True\n",
      "In epoch 0, loss: 1.799, val acc: 0.199 (best 0.199), test acc: 0.199 (best 0.199)\n",
      "In epoch 50, loss: 0.480, val acc: 0.710 (best 0.749), test acc: 0.699 (best 0.714)\n",
      "In epoch 100, loss: 0.278, val acc: 0.677 (best 0.749), test acc: 0.663 (best 0.714)\n",
      "\n",
      "layers 5 hidden_features 64 if_activate False if_normal True if_dropout False loop True\n",
      "In epoch 0, loss: 1.787, val acc: 0.172 (best 0.172), test acc: 0.154 (best 0.154)\n",
      "In epoch 50, loss: 0.356, val acc: 0.710 (best 0.755), test acc: 0.696 (best 0.711)\n",
      "In epoch 100, loss: 0.206, val acc: 0.668 (best 0.755), test acc: 0.666 (best 0.711)\n",
      "\n",
      "layers 5 hidden_features 64 if_activate False if_normal False if_dropout True loop True\n",
      "In epoch 0, loss: 1.794, val acc: 0.136 (best 0.136), test acc: 0.133 (best 0.133)\n",
      "In epoch 50, loss: 0.194, val acc: 0.689 (best 0.752), test acc: 0.684 (best 0.705)\n",
      "In epoch 100, loss: 0.143, val acc: 0.665 (best 0.752), test acc: 0.633 (best 0.705)\n",
      "\n",
      "layers 5 hidden_features 64 if_activate False if_normal False if_dropout False loop True\n",
      "In epoch 0, loss: 1.802, val acc: 0.160 (best 0.160), test acc: 0.142 (best 0.142)\n",
      "In epoch 50, loss: 0.188, val acc: 0.680 (best 0.749), test acc: 0.675 (best 0.702)\n",
      "In epoch 100, loss: 0.106, val acc: 0.662 (best 0.749), test acc: 0.651 (best 0.702)\n",
      "\n",
      "layers 2 hidden_features 64 if_activate True if_normal True if_dropout True loop False\n",
      "In epoch 0, loss: 1.800, val acc: 0.127 (best 0.127), test acc: 0.136 (best 0.136)\n",
      "In epoch 50, loss: 0.594, val acc: 0.704 (best 0.713), test acc: 0.711 (best 0.711)\n",
      "In epoch 100, loss: 0.351, val acc: 0.707 (best 0.722), test acc: 0.684 (best 0.690)\n",
      "\n",
      "layers 2 hidden_features 64 if_activate True if_normal True if_dropout False loop False\n",
      "In epoch 0, loss: 1.774, val acc: 0.224 (best 0.224), test acc: 0.208 (best 0.208)\n",
      "In epoch 50, loss: 0.413, val acc: 0.707 (best 0.716), test acc: 0.687 (best 0.702)\n",
      "In epoch 100, loss: 0.240, val acc: 0.698 (best 0.716), test acc: 0.693 (best 0.702)\n",
      "\n",
      "layers 2 hidden_features 64 if_activate True if_normal False if_dropout True loop False\n",
      "In epoch 0, loss: 1.794, val acc: 0.157 (best 0.157), test acc: 0.160 (best 0.160)\n",
      "In epoch 50, loss: 0.140, val acc: 0.683 (best 0.707), test acc: 0.699 (best 0.696)\n",
      "In epoch 100, loss: 0.102, val acc: 0.686 (best 0.707), test acc: 0.699 (best 0.696)\n",
      "\n",
      "layers 2 hidden_features 64 if_activate True if_normal False if_dropout False loop False\n",
      "In epoch 0, loss: 1.806, val acc: 0.139 (best 0.139), test acc: 0.123 (best 0.123)\n",
      "In epoch 50, loss: 0.089, val acc: 0.701 (best 0.719), test acc: 0.696 (best 0.723)\n",
      "In epoch 100, loss: 0.069, val acc: 0.677 (best 0.719), test acc: 0.690 (best 0.723)\n",
      "\n",
      "layers 2 hidden_features 64 if_activate False if_normal True if_dropout True loop False\n",
      "In epoch 0, loss: 1.801, val acc: 0.166 (best 0.166), test acc: 0.172 (best 0.172)\n",
      "In epoch 50, loss: 0.428, val acc: 0.713 (best 0.740), test acc: 0.693 (best 0.708)\n",
      "In epoch 100, loss: 0.237, val acc: 0.662 (best 0.740), test acc: 0.681 (best 0.708)\n",
      "\n",
      "layers 2 hidden_features 64 if_activate False if_normal True if_dropout False loop False\n",
      "In epoch 0, loss: 1.800, val acc: 0.166 (best 0.166), test acc: 0.169 (best 0.169)\n",
      "In epoch 50, loss: 0.294, val acc: 0.701 (best 0.734), test acc: 0.681 (best 0.732)\n",
      "In epoch 100, loss: 0.166, val acc: 0.668 (best 0.734), test acc: 0.684 (best 0.732)\n",
      "\n",
      "layers 2 hidden_features 64 if_activate False if_normal False if_dropout True loop False\n",
      "In epoch 0, loss: 1.802, val acc: 0.181 (best 0.181), test acc: 0.172 (best 0.172)\n",
      "In epoch 50, loss: 0.119, val acc: 0.692 (best 0.734), test acc: 0.690 (best 0.693)\n",
      "In epoch 100, loss: 0.097, val acc: 0.698 (best 0.734), test acc: 0.699 (best 0.693)\n",
      "\n",
      "layers 2 hidden_features 64 if_activate False if_normal False if_dropout False loop False\n",
      "In epoch 0, loss: 1.800, val acc: 0.178 (best 0.178), test acc: 0.157 (best 0.157)\n",
      "In epoch 50, loss: 0.088, val acc: 0.698 (best 0.716), test acc: 0.696 (best 0.705)\n",
      "In epoch 100, loss: 0.068, val acc: 0.689 (best 0.716), test acc: 0.678 (best 0.705)\n",
      "\n",
      "layers 5 hidden_features 64 if_activate True if_normal True if_dropout True loop False\n",
      "In epoch 0, loss: 1.801, val acc: 0.181 (best 0.181), test acc: 0.163 (best 0.163)\n",
      "In epoch 50, loss: 0.651, val acc: 0.650 (best 0.677), test acc: 0.660 (best 0.687)\n",
      "In epoch 100, loss: 0.379, val acc: 0.644 (best 0.677), test acc: 0.663 (best 0.687)\n",
      "\n",
      "layers 5 hidden_features 64 if_activate True if_normal True if_dropout False loop False\n",
      "In epoch 0, loss: 1.792, val acc: 0.205 (best 0.205), test acc: 0.202 (best 0.202)\n",
      "In epoch 50, loss: 0.468, val acc: 0.665 (best 0.689), test acc: 0.678 (best 0.708)\n",
      "In epoch 100, loss: 0.268, val acc: 0.647 (best 0.689), test acc: 0.657 (best 0.708)\n",
      "\n",
      "layers 5 hidden_features 64 if_activate True if_normal False if_dropout True loop False\n",
      "In epoch 0, loss: 1.790, val acc: 0.190 (best 0.190), test acc: 0.208 (best 0.208)\n",
      "In epoch 50, loss: 0.199, val acc: 0.634 (best 0.677), test acc: 0.657 (best 0.687)\n",
      "In epoch 100, loss: 0.153, val acc: 0.628 (best 0.677), test acc: 0.657 (best 0.687)\n",
      "\n",
      "layers 5 hidden_features 64 if_activate True if_normal False if_dropout False loop False\n",
      "In epoch 0, loss: 1.782, val acc: 0.260 (best 0.260), test acc: 0.229 (best 0.229)\n",
      "In epoch 50, loss: 0.207, val acc: 0.634 (best 0.695), test acc: 0.663 (best 0.693)\n",
      "In epoch 100, loss: 0.193, val acc: 0.628 (best 0.695), test acc: 0.630 (best 0.693)\n",
      "\n",
      "layers 5 hidden_features 64 if_activate False if_normal True if_dropout True loop False\n",
      "In epoch 0, loss: 1.806, val acc: 0.151 (best 0.151), test acc: 0.154 (best 0.154)\n",
      "In epoch 50, loss: 0.499, val acc: 0.644 (best 0.692), test acc: 0.678 (best 0.699)\n",
      "In epoch 100, loss: 0.311, val acc: 0.637 (best 0.692), test acc: 0.666 (best 0.699)\n",
      "\n",
      "layers 5 hidden_features 64 if_activate False if_normal True if_dropout False loop False\n",
      "In epoch 0, loss: 1.793, val acc: 0.211 (best 0.211), test acc: 0.154 (best 0.154)\n",
      "In epoch 50, loss: 0.367, val acc: 0.637 (best 0.680), test acc: 0.672 (best 0.696)\n",
      "In epoch 100, loss: 0.229, val acc: 0.613 (best 0.680), test acc: 0.678 (best 0.696)\n",
      "\n",
      "layers 5 hidden_features 64 if_activate False if_normal False if_dropout True loop False\n",
      "In epoch 0, loss: 1.795, val acc: 0.136 (best 0.136), test acc: 0.166 (best 0.166)\n",
      "In epoch 50, loss: 0.210, val acc: 0.653 (best 0.686), test acc: 0.669 (best 0.702)\n",
      "In epoch 100, loss: 0.166, val acc: 0.628 (best 0.686), test acc: 0.654 (best 0.702)\n",
      "\n",
      "layers 5 hidden_features 64 if_activate False if_normal False if_dropout False loop False\n",
      "In epoch 0, loss: 1.795, val acc: 0.175 (best 0.175), test acc: 0.178 (best 0.178)\n",
      "In epoch 50, loss: 0.215, val acc: 0.634 (best 0.692), test acc: 0.669 (best 0.711)\n",
      "In epoch 100, loss: 0.124, val acc: 0.628 (best 0.692), test acc: 0.648 (best 0.711)\n",
      "\n",
      "Best Parameter\n",
      "{'loop': True, 'layers': 2, 'if_activate': True, 'if_normal': False, 'if_dropout': False, 'acc': tensor(0.7976)}\n",
      "In epoch 0, loss: 1.796, val acc: 0.160 (best 0.160), test acc: 0.169 (best 0.169)\n",
      "In epoch 50, loss: 0.064, val acc: 0.704 (best 0.798), test acc: 0.735 (best 0.747)\n",
      "In epoch 100, loss: 0.042, val acc: 0.710 (best 0.798), test acc: 0.735 (best 0.747)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best test acc tensor(0.7470)\n"
     ]
    }
   ],
   "source": [
    "# Train Citeseer\n",
    "lr = 0.01\n",
    "layers = [2, 5]\n",
    "Gs = [G_citeseer, G_citeseer_no_loop]\n",
    "hidden_features = [16, 32, 64]\n",
    "if_activate = [True, False]\n",
    "if_normal = [True, False]\n",
    "if_dropout = [True, False]\n",
    "best_param_citeseer = {\"loop\": None, \"layers\": None, \"if_activate\": None, \"if_normal\": None, \"if_dropout\": None, \"acc\": 0.0}\n",
    "\n",
    "\n",
    "for h_f in hidden_features:\n",
    "    for g_tmp in Gs:\n",
    "        if g_tmp == G_citeseer:\n",
    "            loop = True\n",
    "        else:\n",
    "            loop = False             \n",
    "        for l in layers:\n",
    "            for a in if_activate:\n",
    "                for n in if_normal:\n",
    "                    for d in if_dropout:\n",
    "                        print(\"layers\", l, \"hidden_features\", h_f, \"if_activate\", a, \"if_normal\", n, \"if_dropout\", d, \"loop\", loop)\n",
    "                        model = GCN(g_tmp.ndata['feat'].shape[1], h_f, len(citeseer_label_map), layers=l, if_activate=a, if_normal=n, if_dropout=d)\n",
    "                        best_val_acc, _ = train(g_tmp, model, epochs=101, print_epoch=50, lr=lr, print_loss=False)\n",
    "                        if best_val_acc > best_param_citeseer[\"acc\"]:\n",
    "                            best_param_citeseer[\"layers\"] = l\n",
    "                            best_param_citeseer[\"if_activate\"] = a\n",
    "                            best_param_citeseer[\"if_dropout\"] = d\n",
    "                            best_param_citeseer[\"if_normal\"] = n\n",
    "                            best_param_citeseer[\"acc\"] = best_val_acc\n",
    "                            best_param_citeseer[\"loop\"] = loop\n",
    "                            best_g = g_tmp\n",
    "                        print()\n",
    "\n",
    "# Best Param\n",
    "print(\"Best Parameter\")\n",
    "print(best_param_citeseer)\n",
    "l = best_param_citeseer[\"layers\"]\n",
    "a = best_param_citeseer[\"if_activate\"]\n",
    "n = best_param_citeseer[\"if_normal\"]\n",
    "d = best_param_citeseer[\"if_dropout\"]\n",
    "model = GCN(best_g.ndata['feat'].shape[1], h_f, len(citeseer_label_map), layers=l, if_activate=a, if_normal=n, if_dropout=d)\n",
    "_, best_test_acc = train(best_g, model, epochs=101, print_epoch=50, lr=lr, print_loss=True)\n",
    "print(\"best test acc\", best_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers 2 hidden_features 16 if_activate True if_normal True if_dropout True\n",
      "In epoch 0, loss: 0.693, val acc: 0.487 (best 0.487), test acc: 0.489 (best 0.489)\n",
      "In epoch 50, loss: 0.583, val acc: 0.749 (best 0.749), test acc: 0.746 (best 0.746)\n",
      "In epoch 100, loss: 0.566, val acc: 0.749 (best 0.750), test acc: 0.746 (best 0.746)\n",
      "\n",
      "layers 2 hidden_features 16 if_activate True if_normal True if_dropout False\n",
      "In epoch 0, loss: 0.695, val acc: 0.446 (best 0.446), test acc: 0.449 (best 0.449)\n",
      "In epoch 50, loss: 0.583, val acc: 0.749 (best 0.749), test acc: 0.746 (best 0.746)\n",
      "In epoch 100, loss: 0.566, val acc: 0.750 (best 0.750), test acc: 0.747 (best 0.747)\n",
      "\n",
      "layers 2 hidden_features 16 if_activate True if_normal False if_dropout True\n",
      "In epoch 0, loss: 0.693, val acc: 0.441 (best 0.441), test acc: 0.445 (best 0.445)\n",
      "In epoch 50, loss: 0.585, val acc: 0.748 (best 0.749), test acc: 0.746 (best 0.746)\n",
      "In epoch 100, loss: 0.567, val acc: 0.749 (best 0.749), test acc: 0.746 (best 0.746)\n",
      "\n",
      "layers 2 hidden_features 16 if_activate True if_normal False if_dropout False\n",
      "In epoch 0, loss: 0.693, val acc: 0.467 (best 0.467), test acc: 0.468 (best 0.468)\n",
      "In epoch 50, loss: 0.584, val acc: 0.749 (best 0.749), test acc: 0.746 (best 0.746)\n",
      "In epoch 100, loss: 0.566, val acc: 0.750 (best 0.750), test acc: 0.746 (best 0.746)\n",
      "\n",
      "layers 2 hidden_features 16 if_activate False if_normal True if_dropout True\n",
      "In epoch 0, loss: 0.693, val acc: 0.480 (best 0.480), test acc: 0.481 (best 0.481)\n",
      "In epoch 50, loss: 0.583, val acc: 0.749 (best 0.749), test acc: 0.746 (best 0.746)\n",
      "In epoch 100, loss: 0.565, val acc: 0.750 (best 0.750), test acc: 0.747 (best 0.747)\n",
      "\n",
      "layers 2 hidden_features 16 if_activate False if_normal True if_dropout False\n",
      "In epoch 0, loss: 0.693, val acc: 0.471 (best 0.471), test acc: 0.475 (best 0.475)\n",
      "In epoch 50, loss: 0.582, val acc: 0.749 (best 0.749), test acc: 0.746 (best 0.746)\n",
      "In epoch 100, loss: 0.563, val acc: 0.750 (best 0.750), test acc: 0.747 (best 0.747)\n",
      "\n",
      "layers 2 hidden_features 16 if_activate False if_normal False if_dropout True\n",
      "In epoch 0, loss: 0.693, val acc: 0.470 (best 0.470), test acc: 0.470 (best 0.470)\n",
      "In epoch 50, loss: 0.585, val acc: 0.749 (best 0.749), test acc: 0.746 (best 0.746)\n",
      "In epoch 100, loss: 0.567, val acc: 0.749 (best 0.749), test acc: 0.746 (best 0.746)\n",
      "\n",
      "layers 2 hidden_features 16 if_activate False if_normal False if_dropout False\n",
      "In epoch 0, loss: 0.693, val acc: 0.453 (best 0.453), test acc: 0.456 (best 0.456)\n",
      "In epoch 50, loss: 0.585, val acc: 0.749 (best 0.749), test acc: 0.746 (best 0.746)\n",
      "In epoch 100, loss: 0.566, val acc: 0.750 (best 0.750), test acc: 0.747 (best 0.747)\n",
      "\n",
      "layers 5 hidden_features 16 if_activate True if_normal True if_dropout True\n",
      "In epoch 0, loss: 0.694, val acc: 0.477 (best 0.477), test acc: 0.477 (best 0.477)\n",
      "In epoch 50, loss: 0.584, val acc: 0.749 (best 0.749), test acc: 0.746 (best 0.746)\n",
      "In epoch 100, loss: 0.566, val acc: 0.750 (best 0.750), test acc: 0.746 (best 0.746)\n",
      "\n",
      "layers 5 hidden_features 16 if_activate True if_normal True if_dropout False\n",
      "In epoch 0, loss: 0.695, val acc: 0.474 (best 0.474), test acc: 0.475 (best 0.475)\n",
      "In epoch 50, loss: 0.583, val acc: 0.749 (best 0.749), test acc: 0.746 (best 0.746)\n",
      "In epoch 100, loss: 0.566, val acc: 0.750 (best 0.750), test acc: 0.747 (best 0.747)\n",
      "\n",
      "layers 5 hidden_features 16 if_activate True if_normal False if_dropout True\n",
      "In epoch 0, loss: 0.693, val acc: 0.464 (best 0.464), test acc: 0.470 (best 0.470)\n",
      "In epoch 50, loss: 0.582, val acc: 0.749 (best 0.749), test acc: 0.746 (best 0.746)\n",
      "In epoch 100, loss: 0.565, val acc: 0.750 (best 0.750), test acc: 0.747 (best 0.747)\n",
      "\n",
      "layers 5 hidden_features 16 if_activate True if_normal False if_dropout False\n",
      "In epoch 0, loss: 0.693, val acc: 0.471 (best 0.471), test acc: 0.475 (best 0.475)\n",
      "In epoch 50, loss: 0.582, val acc: 0.749 (best 0.749), test acc: 0.746 (best 0.746)\n",
      "In epoch 100, loss: 0.564, val acc: 0.750 (best 0.750), test acc: 0.747 (best 0.747)\n",
      "\n",
      "layers 5 hidden_features 16 if_activate False if_normal True if_dropout True\n",
      "In epoch 0, loss: 0.691, val acc: 0.517 (best 0.517), test acc: 0.516 (best 0.516)\n",
      "In epoch 50, loss: 0.583, val acc: 0.749 (best 0.749), test acc: 0.746 (best 0.746)\n",
      "In epoch 100, loss: 0.566, val acc: 0.750 (best 0.750), test acc: 0.747 (best 0.747)\n",
      "\n",
      "layers 5 hidden_features 16 if_activate False if_normal True if_dropout False\n",
      "In epoch 0, loss: 0.697, val acc: 0.434 (best 0.434), test acc: 0.440 (best 0.440)\n",
      "In epoch 50, loss: 0.582, val acc: 0.749 (best 0.749), test acc: 0.746 (best 0.746)\n",
      "In epoch 100, loss: 0.565, val acc: 0.750 (best 0.750), test acc: 0.747 (best 0.747)\n",
      "\n",
      "layers 5 hidden_features 16 if_activate False if_normal False if_dropout True\n",
      "In epoch 0, loss: 0.693, val acc: 0.452 (best 0.452), test acc: 0.455 (best 0.455)\n",
      "In epoch 50, loss: 0.582, val acc: 0.749 (best 0.749), test acc: 0.746 (best 0.746)\n",
      "In epoch 100, loss: 0.566, val acc: 0.749 (best 0.750), test acc: 0.746 (best 0.746)\n",
      "\n",
      "layers 5 hidden_features 16 if_activate False if_normal False if_dropout False\n",
      "In epoch 0, loss: 0.693, val acc: 0.452 (best 0.452), test acc: 0.454 (best 0.454)\n",
      "In epoch 50, loss: 0.581, val acc: 0.749 (best 0.749), test acc: 0.746 (best 0.746)\n",
      "In epoch 100, loss: 0.565, val acc: 0.749 (best 0.749), test acc: 0.746 (best 0.746)\n",
      "\n",
      "layers 2 hidden_features 32 if_activate True if_normal True if_dropout True\n",
      "In epoch 0, loss: 0.694, val acc: 0.460 (best 0.460), test acc: 0.462 (best 0.462)\n",
      "In epoch 50, loss: 0.583, val acc: 0.749 (best 0.749), test acc: 0.746 (best 0.746)\n",
      "In epoch 100, loss: 0.565, val acc: 0.750 (best 0.750), test acc: 0.747 (best 0.747)\n",
      "\n",
      "layers 2 hidden_features 32 if_activate True if_normal True if_dropout False\n",
      "In epoch 0, loss: 0.694, val acc: 0.458 (best 0.458), test acc: 0.460 (best 0.460)\n",
      "In epoch 50, loss: 0.583, val acc: 0.749 (best 0.749), test acc: 0.746 (best 0.746)\n",
      "In epoch 100, loss: 0.563, val acc: 0.750 (best 0.750), test acc: 0.747 (best 0.747)\n",
      "\n",
      "layers 2 hidden_features 32 if_activate True if_normal False if_dropout True\n",
      "In epoch 0, loss: 0.693, val acc: 0.463 (best 0.463), test acc: 0.462 (best 0.462)\n",
      "In epoch 50, loss: 0.584, val acc: 0.749 (best 0.749), test acc: 0.746 (best 0.746)\n",
      "In epoch 100, loss: 0.564, val acc: 0.750 (best 0.750), test acc: 0.747 (best 0.747)\n",
      "\n",
      "layers 2 hidden_features 32 if_activate True if_normal False if_dropout False\n",
      "In epoch 0, loss: 0.693, val acc: 0.469 (best 0.469), test acc: 0.470 (best 0.470)\n",
      "In epoch 50, loss: 0.584, val acc: 0.749 (best 0.749), test acc: 0.746 (best 0.746)\n",
      "In epoch 100, loss: 0.564, val acc: 0.750 (best 0.750), test acc: 0.747 (best 0.747)\n",
      "\n",
      "layers 2 hidden_features 32 if_activate False if_normal True if_dropout True\n",
      "In epoch 0, loss: 0.693, val acc: 0.488 (best 0.488), test acc: 0.490 (best 0.490)\n",
      "In epoch 50, loss: 0.582, val acc: 0.749 (best 0.749), test acc: 0.746 (best 0.746)\n",
      "In epoch 100, loss: 0.564, val acc: 0.750 (best 0.750), test acc: 0.747 (best 0.747)\n",
      "\n",
      "layers 2 hidden_features 32 if_activate False if_normal True if_dropout False\n",
      "In epoch 0, loss: 0.694, val acc: 0.459 (best 0.459), test acc: 0.461 (best 0.461)\n",
      "In epoch 50, loss: 0.581, val acc: 0.749 (best 0.749), test acc: 0.746 (best 0.746)\n",
      "In epoch 100, loss: 0.562, val acc: 0.751 (best 0.751), test acc: 0.748 (best 0.748)\n",
      "\n",
      "layers 2 hidden_features 32 if_activate False if_normal False if_dropout True\n",
      "In epoch 0, loss: 0.693, val acc: 0.470 (best 0.470), test acc: 0.472 (best 0.472)\n",
      "In epoch 50, loss: 0.584, val acc: 0.749 (best 0.749), test acc: 0.746 (best 0.746)\n",
      "In epoch 100, loss: 0.565, val acc: 0.750 (best 0.750), test acc: 0.747 (best 0.747)\n",
      "\n",
      "layers 2 hidden_features 32 if_activate False if_normal False if_dropout False\n",
      "In epoch 0, loss: 0.693, val acc: 0.471 (best 0.471), test acc: 0.473 (best 0.473)\n",
      "In epoch 50, loss: 0.583, val acc: 0.749 (best 0.749), test acc: 0.746 (best 0.746)\n",
      "In epoch 100, loss: 0.564, val acc: 0.750 (best 0.750), test acc: 0.747 (best 0.747)\n",
      "\n",
      "layers 5 hidden_features 32 if_activate True if_normal True if_dropout True\n",
      "In epoch 0, loss: 0.692, val acc: 0.486 (best 0.486), test acc: 0.489 (best 0.489)\n",
      "In epoch 50, loss: 0.583, val acc: 0.749 (best 0.749), test acc: 0.746 (best 0.746)\n",
      "In epoch 100, loss: 0.565, val acc: 0.750 (best 0.750), test acc: 0.747 (best 0.747)\n",
      "\n",
      "layers 5 hidden_features 32 if_activate True if_normal True if_dropout False\n",
      "In epoch 0, loss: 0.694, val acc: 0.478 (best 0.478), test acc: 0.479 (best 0.479)\n",
      "In epoch 50, loss: 0.582, val acc: 0.749 (best 0.749), test acc: 0.747 (best 0.747)\n",
      "In epoch 100, loss: 0.564, val acc: 0.750 (best 0.750), test acc: 0.747 (best 0.747)\n",
      "\n",
      "layers 5 hidden_features 32 if_activate True if_normal False if_dropout True\n",
      "In epoch 0, loss: 0.693, val acc: 0.484 (best 0.484), test acc: 0.487 (best 0.487)\n",
      "In epoch 50, loss: 0.580, val acc: 0.749 (best 0.749), test acc: 0.746 (best 0.746)\n",
      "In epoch 100, loss: 0.564, val acc: 0.750 (best 0.750), test acc: 0.747 (best 0.747)\n",
      "\n",
      "layers 5 hidden_features 32 if_activate True if_normal False if_dropout False\n",
      "In epoch 0, loss: 0.693, val acc: 0.452 (best 0.452), test acc: 0.453 (best 0.453)\n",
      "In epoch 50, loss: 0.580, val acc: 0.749 (best 0.749), test acc: 0.746 (best 0.746)\n",
      "In epoch 100, loss: 0.562, val acc: 0.750 (best 0.751), test acc: 0.748 (best 0.748)\n",
      "\n",
      "layers 5 hidden_features 32 if_activate False if_normal True if_dropout True\n",
      "In epoch 0, loss: 0.693, val acc: 0.480 (best 0.480), test acc: 0.480 (best 0.480)\n",
      "In epoch 50, loss: 0.582, val acc: 0.749 (best 0.749), test acc: 0.746 (best 0.746)\n",
      "In epoch 100, loss: 0.565, val acc: 0.750 (best 0.750), test acc: 0.747 (best 0.747)\n",
      "\n",
      "layers 5 hidden_features 32 if_activate False if_normal True if_dropout False\n",
      "In epoch 0, loss: 0.694, val acc: 0.470 (best 0.470), test acc: 0.476 (best 0.476)\n",
      "In epoch 50, loss: 0.581, val acc: 0.750 (best 0.750), test acc: 0.747 (best 0.747)\n",
      "In epoch 100, loss: 0.565, val acc: 0.750 (best 0.750), test acc: 0.747 (best 0.747)\n",
      "\n",
      "layers 5 hidden_features 32 if_activate False if_normal False if_dropout True\n",
      "In epoch 0, loss: 0.693, val acc: 0.469 (best 0.469), test acc: 0.472 (best 0.472)\n",
      "In epoch 50, loss: 0.580, val acc: 0.749 (best 0.749), test acc: 0.746 (best 0.746)\n",
      "In epoch 100, loss: 0.564, val acc: 0.749 (best 0.749), test acc: 0.747 (best 0.746)\n",
      "\n",
      "layers 5 hidden_features 32 if_activate False if_normal False if_dropout False\n",
      "In epoch 0, loss: 0.693, val acc: 0.500 (best 0.500), test acc: 0.505 (best 0.505)\n",
      "In epoch 50, loss: 0.580, val acc: 0.749 (best 0.749), test acc: 0.746 (best 0.746)\n",
      "In epoch 100, loss: 0.563, val acc: 0.750 (best 0.750), test acc: 0.747 (best 0.747)\n",
      "\n",
      "layers 2 hidden_features 64 if_activate True if_normal True if_dropout True\n",
      "In epoch 0, loss: 0.693, val acc: 0.476 (best 0.476), test acc: 0.477 (best 0.477)\n",
      "In epoch 50, loss: 0.582, val acc: 0.749 (best 0.749), test acc: 0.746 (best 0.746)\n",
      "In epoch 100, loss: 0.563, val acc: 0.750 (best 0.750), test acc: 0.747 (best 0.747)\n",
      "\n",
      "layers 2 hidden_features 64 if_activate True if_normal True if_dropout False\n",
      "In epoch 0, loss: 0.693, val acc: 0.489 (best 0.489), test acc: 0.491 (best 0.491)\n",
      "In epoch 50, loss: 0.582, val acc: 0.749 (best 0.749), test acc: 0.746 (best 0.746)\n",
      "In epoch 100, loss: 0.559, val acc: 0.752 (best 0.752), test acc: 0.749 (best 0.749)\n",
      "\n",
      "layers 2 hidden_features 64 if_activate True if_normal False if_dropout True\n",
      "In epoch 0, loss: 0.693, val acc: 0.501 (best 0.501), test acc: 0.502 (best 0.502)\n",
      "In epoch 50, loss: 0.582, val acc: 0.749 (best 0.749), test acc: 0.746 (best 0.746)\n",
      "In epoch 100, loss: 0.562, val acc: 0.750 (best 0.750), test acc: 0.747 (best 0.747)\n",
      "\n",
      "layers 2 hidden_features 64 if_activate True if_normal False if_dropout False\n",
      "In epoch 0, loss: 0.693, val acc: 0.490 (best 0.490), test acc: 0.492 (best 0.492)\n",
      "In epoch 50, loss: 0.582, val acc: 0.749 (best 0.749), test acc: 0.746 (best 0.746)\n",
      "In epoch 100, loss: 0.562, val acc: 0.751 (best 0.751), test acc: 0.748 (best 0.748)\n",
      "\n",
      "layers 2 hidden_features 64 if_activate False if_normal True if_dropout True\n",
      "In epoch 0, loss: 0.693, val acc: 0.466 (best 0.466), test acc: 0.471 (best 0.471)\n",
      "In epoch 50, loss: 0.582, val acc: 0.749 (best 0.749), test acc: 0.746 (best 0.746)\n",
      "In epoch 100, loss: 0.562, val acc: 0.751 (best 0.751), test acc: 0.747 (best 0.747)\n",
      "\n",
      "layers 2 hidden_features 64 if_activate False if_normal True if_dropout False\n",
      "In epoch 0, loss: 0.693, val acc: 0.479 (best 0.479), test acc: 0.480 (best 0.480)\n",
      "In epoch 50, loss: 0.581, val acc: 0.749 (best 0.749), test acc: 0.746 (best 0.746)\n",
      "In epoch 100, loss: 0.560, val acc: 0.752 (best 0.752), test acc: 0.749 (best 0.749)\n",
      "\n",
      "layers 2 hidden_features 64 if_activate False if_normal False if_dropout True\n",
      "In epoch 0, loss: 0.693, val acc: 0.467 (best 0.467), test acc: 0.470 (best 0.470)\n",
      "In epoch 50, loss: 0.582, val acc: 0.749 (best 0.749), test acc: 0.746 (best 0.746)\n",
      "In epoch 100, loss: 0.561, val acc: 0.750 (best 0.751), test acc: 0.748 (best 0.748)\n",
      "\n",
      "layers 2 hidden_features 64 if_activate False if_normal False if_dropout False\n",
      "In epoch 0, loss: 0.693, val acc: 0.471 (best 0.471), test acc: 0.475 (best 0.475)\n",
      "In epoch 50, loss: 0.581, val acc: 0.749 (best 0.749), test acc: 0.746 (best 0.746)\n",
      "In epoch 100, loss: 0.561, val acc: 0.751 (best 0.751), test acc: 0.748 (best 0.748)\n",
      "\n",
      "layers 5 hidden_features 64 if_activate True if_normal True if_dropout True\n",
      "In epoch 0, loss: 0.693, val acc: 0.475 (best 0.475), test acc: 0.478 (best 0.478)\n",
      "In epoch 50, loss: 0.582, val acc: 0.749 (best 0.749), test acc: 0.746 (best 0.746)\n",
      "In epoch 100, loss: 0.565, val acc: 0.750 (best 0.750), test acc: 0.747 (best 0.747)\n",
      "\n",
      "layers 5 hidden_features 64 if_activate True if_normal True if_dropout False\n",
      "In epoch 0, loss: 0.696, val acc: 0.449 (best 0.449), test acc: 0.450 (best 0.450)\n",
      "In epoch 50, loss: 0.581, val acc: 0.750 (best 0.750), test acc: 0.747 (best 0.747)\n",
      "In epoch 100, loss: 0.564, val acc: 0.750 (best 0.750), test acc: 0.747 (best 0.747)\n",
      "\n",
      "layers 5 hidden_features 64 if_activate True if_normal False if_dropout True\n",
      "In epoch 0, loss: 0.693, val acc: 0.478 (best 0.478), test acc: 0.485 (best 0.485)\n",
      "In epoch 50, loss: 0.579, val acc: 0.749 (best 0.750), test acc: 0.747 (best 0.746)\n",
      "In epoch 100, loss: 0.562, val acc: 0.750 (best 0.750), test acc: 0.747 (best 0.747)\n",
      "\n",
      "layers 5 hidden_features 64 if_activate True if_normal False if_dropout False\n",
      "In epoch 0, loss: 0.693, val acc: 0.464 (best 0.464), test acc: 0.463 (best 0.463)\n",
      "In epoch 50, loss: 0.579, val acc: 0.749 (best 0.750), test acc: 0.747 (best 0.747)\n",
      "In epoch 100, loss: 0.560, val acc: 0.751 (best 0.751), test acc: 0.748 (best 0.748)\n",
      "\n",
      "layers 5 hidden_features 64 if_activate False if_normal True if_dropout True\n",
      "In epoch 0, loss: 0.692, val acc: 0.487 (best 0.487), test acc: 0.489 (best 0.489)\n",
      "In epoch 50, loss: 0.581, val acc: 0.750 (best 0.750), test acc: 0.746 (best 0.746)\n",
      "In epoch 100, loss: 0.564, val acc: 0.750 (best 0.750), test acc: 0.747 (best 0.747)\n",
      "\n",
      "layers 5 hidden_features 64 if_activate False if_normal True if_dropout False\n",
      "In epoch 0, loss: 0.693, val acc: 0.481 (best 0.481), test acc: 0.481 (best 0.481)\n",
      "In epoch 50, loss: 0.581, val acc: 0.750 (best 0.750), test acc: 0.747 (best 0.747)\n",
      "In epoch 100, loss: 0.563, val acc: 0.751 (best 0.751), test acc: 0.748 (best 0.747)\n",
      "\n",
      "layers 5 hidden_features 64 if_activate False if_normal False if_dropout True\n",
      "In epoch 0, loss: 0.693, val acc: 0.466 (best 0.466), test acc: 0.470 (best 0.470)\n",
      "In epoch 50, loss: 0.579, val acc: 0.749 (best 0.749), test acc: 0.746 (best 0.746)\n",
      "In epoch 100, loss: 0.561, val acc: 0.750 (best 0.750), test acc: 0.747 (best 0.747)\n",
      "\n",
      "layers 5 hidden_features 64 if_activate False if_normal False if_dropout False\n",
      "In epoch 0, loss: 0.693, val acc: 0.442 (best 0.442), test acc: 0.447 (best 0.447)\n",
      "In epoch 50, loss: 0.580, val acc: 0.749 (best 0.749), test acc: 0.746 (best 0.746)\n",
      "In epoch 100, loss: 0.564, val acc: 0.749 (best 0.750), test acc: 0.746 (best 0.747)\n",
      "\n",
      "Best Parameter\n",
      "{'loop': False, 'layers': 2, 'if_activate': False, 'if_normal': True, 'if_dropout': False, 'acc': tensor(0.7521)}\n",
      "In epoch 0, loss: 0.693, val acc: 0.480 (best 0.480), test acc: 0.482 (best 0.482)\n",
      "In epoch 50, loss: 0.581, val acc: 0.749 (best 0.749), test acc: 0.746 (best 0.746)\n",
      "In epoch 100, loss: 0.560, val acc: 0.752 (best 0.752), test acc: 0.749 (best 0.749)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best test acc tensor(0.7488)\n"
     ]
    }
   ],
   "source": [
    "# Train PPI\n",
    "lr = 0.01\n",
    "layers = [2, 5]\n",
    "hidden_features = [16, 32, 64]\n",
    "if_activate = [True, False]\n",
    "if_normal = [True, False]\n",
    "if_dropout = [True, False]\n",
    "best_param_ppi = {\"loop\": None, \"layers\": None, \"if_activate\": None, \"if_normal\": None, \"if_dropout\": None, \"acc\": 0.0}\n",
    "\n",
    "\n",
    "for h_f in hidden_features:\n",
    "    for l in layers:\n",
    "        for a in if_activate:\n",
    "            for n in if_normal:\n",
    "                for d in if_dropout:\n",
    "                    print(\"layers\", l, \"hidden_features\", h_f, \"if_activate\", a, \"if_normal\", n, \"if_dropout\", d)\n",
    "                    model = GCN(G_ppi.ndata['feat'].shape[1], h_f, len(ppi_labels[0]), layers=l, if_activate=a, if_normal=n, if_dropout=d, if_ppi=True)\n",
    "                    best_val_acc, _ = train(G_ppi, model, epochs=101, print_epoch=50, lr=lr, print_loss=False, if_ppi=True)\n",
    "                    if best_val_acc > best_param_ppi[\"acc\"]:\n",
    "                        best_param_ppi[\"layers\"] = l\n",
    "                        best_param_ppi[\"if_activate\"] = a\n",
    "                        best_param_ppi[\"if_dropout\"] = d\n",
    "                        best_param_ppi[\"if_normal\"] = n\n",
    "                        best_param_ppi[\"acc\"] = best_val_acc\n",
    "                        best_param_ppi[\"loop\"] = loop\n",
    "                    print()\n",
    "                        \n",
    "# Best Param\n",
    "print(\"Best Parameter\")\n",
    "print(best_param_ppi)\n",
    "l = best_param_ppi[\"layers\"]\n",
    "a = best_param_ppi[\"if_activate\"]\n",
    "n = best_param_ppi[\"if_normal\"]\n",
    "d = best_param_ppi[\"if_dropout\"]\n",
    "model = GCN(G_ppi.ndata['feat'].shape[1], h_f, len(ppi_labels[0]), layers=l, if_activate=a, if_normal=n, if_dropout=d, if_ppi=True)\n",
    "_, best_test_acc = train(G_ppi, model, epochs=101, print_epoch=50, lr=lr, print_loss=True, if_ppi=True)\n",
    "print(\"best test acc\", best_test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4eb7214627cf817111b71af72ee0298630c114535c582e979b91450e4d37bfbb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
